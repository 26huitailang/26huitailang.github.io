[{"content":"tmux 终端服用软件，session可以保存在tmux server中，就算iterm等终端关闭也可以恢复，远程连接的时候避免掉线（类似的功能的软件还有，screen）。\n参考  十分钟学会 tmux Tmux - Linux从业者必备利器 * cheatsheet 优雅地使用命令行：Tmux 终端复用 Tmux使用手册  本机，cheatsheet-tmux  安装 brew install tmux  基于参考第二篇文章，配置：\n$ cd $ rm -rf .tmux $ git clone https://github.com/gpakosz/.tmux.git $ ln -s -f .tmux/.tmux.conf $ cp .tmux/.tmux.conf.local . 概念  session，不同的会话 window，不同的窗口，物理划分，一个session可以有多个window pane，窗格，一个window可以用过 %/\u0026quot; 划分为多个窗格  tmux操作  tmux ls，查看打开的session tmux a，恢复 tmux a -t SESSION,恢复指定session  C-b操作  前缀快捷键，^b % 左右平分出两个pane \u0026quot; 上下平分出两个pane x 关闭当前窗格 { 当前窗格前移 } 当前窗格后移 ; 选择上次使用的窗格 o 选择下一个窗格，也可以使用上下左右方向键来选择 space 切换窗格布局，tmux 内置了五种窗格布局，也可以通过 ⌥1 至 ⌥5来切换 z 最大化当前窗格，再次执行可恢复原来大小 q 显示所有窗格的序号，在序号出现期间按下对应的数字，即可跳转至对应的窗格  resize pane  C-b :resize-pane -D/U/R/L 20  修改配置  ~/.tmux.conf.local ~/.tmux.conf  source file\nC-b :source-file ~/.tmux.conf.local  修改复制模式为vi模式，.tmux.conf.local\nset-option -g mode-keys vi 复制 修改vi模式后\n C-b + [ 进去复制模式 空格开始选择 Enter 结束 C-b + ] 粘贴  插件 恢复会话 Tmux Resurrect   安装\n cd ~/.tmux mkdir plugins git clone https://github.com/tmux-plugins/tmux-resurrect.git 修改 ~/.tmux.conf.local  run-shell ~/.tmux/plugins/tmux-resurrect/resurrect.tmux   prefix + r 重载配置    保存，prefix + Ctrl + s\n 保存位置，~/.tmux/resurrect，可以手动清理这里的历史记录    恢复，prefix + Ctrl + r\n  自动恢复 Tmux Continuum 先用手动，后续试试这个自动\n","permalink":"http://localhost:8000/posts/devenv/tmux/","summary":"tmux 终端服用软件，session可以保存在tmux server中，就算iterm等终端关闭也可以恢复，远程连接的时候避免掉线（类似的功能的软件还有，screen）。\n参考  十分钟学会 tmux Tmux - Linux从业者必备利器 * cheatsheet 优雅地使用命令行：Tmux 终端复用 Tmux使用手册  本机，cheatsheet-tmux  安装 brew install tmux  基于参考第二篇文章，配置：\n$ cd $ rm -rf .tmux $ git clone https://github.com/gpakosz/.tmux.git $ ln -s -f .tmux/.tmux.conf $ cp .tmux/.tmux.conf.local . 概念  session，不同的会话 window，不同的窗口，物理划分，一个session可以有多个window pane，窗格，一个window可以用过 %/\u0026quot; 划分为多个窗格  tmux操作  tmux ls，查看打开的session tmux a，恢复 tmux a -t SESSION,恢复指定session  C-b操作  前缀快捷键，^b % 左右平分出两个pane \u0026quot; 上下平分出两个pane x 关闭当前窗格 { 当前窗格前移 } 当前窗格后移 ; 选择上次使用的窗格 o 选择下一个窗格，也可以使用上下左右方向键来选择 space 切换窗格布局，tmux 内置了五种窗格布局，也可以通过 ⌥1 至 ⌥5来切换 z 最大化当前窗格，再次执行可恢复原来大小 q 显示所有窗格的序号，在序号出现期间按下对应的数字，即可跳转至对应的窗格  resize pane  C-b :resize-pane -D/U/R/L 20  修改配置  ~/.","title":"tmux"},{"content":"nginx [toc]\n常用命令 nginx -s stop nginx -s reload 简介 反向代理 一句话：\n 什么是正向代理？代理的是客户端 什么是反向代理？代理的是服务器，客户端是无感知的  nginx反向代理配置\n正常情况： client —(send request)—\u0026gt; server 代理情况： client —(send request)—\u0026gt; clinet proxy –(send request)—\u0026gt; server 反向代理： client -(send request)-\u0026gt; server proxy -(send request)-\u0026gt; other server  可以看到反向代理并不是真的反过来，而是代理人的身份由客户端转向了服务端，也因为代理是在服务端，所以客户端是对此无感知的。\n负载均衡 将原先集中请求到单个服务器的请求分发到多个服务器上，目的是为了支持服务横向扩展。\n动静分离 配置 全局 配置文件开始到events之间的内容，主要是设置一些影响nginx运行的配置指令，比如：\n 用户（组） worker process数量 进程pid存放路径 日志存放路径和类型 配置文件的引入  events 配置nginx服务器与用户的网络连接，此部分对性能影响较大，应根据实际情况处理，比如：\n 是否开启对多worker process下的网络连接进行序列化 是否允许同时接受多个网络连接 选取处理连接的事件驱动模型 每个worker 支持的最大连接数等  http  全局配置 server配置  全局 location配置    server 配置和匹配规则 一个http服务可以有多个server，而对server的路径匹配，反向代理都是在这里配置的。\n在server中最重要的一项配置：server_name的配置。server_name决定了来了一个url，到底是哪个server处理该请求。nginx会依次找和url配置的第一次出现的server。server_name可以使用通配符，也可以使用正则表达式。而且一个server的server_name可以多个，以空格分隔。更详细的关于server_name匹配规则，参看这里\nUnix-domain socket(Unix域套接字) Python实例浅谈之九使用本地socket文件\nUnix domain socket 或者 IPC socket是一种终端，可以使同一台操作系统上的两个或多个进程进行数据通信。与管道相比，Unix domain sockets 既可以使用字节流，又可以使用数据队列，而管道通信则只能使用字节流。Unix domain sockets的接口和Internet socket很像，但它不使用网络底层协议来通信。Unix domain socket 的功能是POSIX操作系统里的一种组件。\nUnix domain sockets 使用系统文件的地址来作为自己的身份。它可以被系统进程引用。所以两个进程可以同时打开一个Unix domain sockets来进行通信。不过这种通信方式是发生在系统内核里而不会在网络里传播。\n部署应用的时候，利用unix domain socket，可以防止端口冲突，启动程序的时候要将这个socket文件绑定到Gunicorn。\n这个是用于进程间通信的方式，那么网络socket是什么？ 文章或文档链接  搭建nginx反向代理用做内网域名转发 WEB请求处理二：Nginx请求反向代理 使用 Nginx 和 Gunicorn 部署 Django 博客  ","permalink":"http://localhost:8000/posts/nginx/nginx/","summary":"nginx [toc]\n常用命令 nginx -s stop nginx -s reload 简介 反向代理 一句话：\n 什么是正向代理？代理的是客户端 什么是反向代理？代理的是服务器，客户端是无感知的  nginx反向代理配置\n正常情况： client —(send request)—\u0026gt; server 代理情况： client —(send request)—\u0026gt; clinet proxy –(send request)—\u0026gt; server 反向代理： client -(send request)-\u0026gt; server proxy -(send request)-\u0026gt; other server  可以看到反向代理并不是真的反过来，而是代理人的身份由客户端转向了服务端，也因为代理是在服务端，所以客户端是对此无感知的。\n负载均衡 将原先集中请求到单个服务器的请求分发到多个服务器上，目的是为了支持服务横向扩展。\n动静分离 配置 全局 配置文件开始到events之间的内容，主要是设置一些影响nginx运行的配置指令，比如：\n 用户（组） worker process数量 进程pid存放路径 日志存放路径和类型 配置文件的引入  events 配置nginx服务器与用户的网络连接，此部分对性能影响较大，应根据实际情况处理，比如：\n 是否开启对多worker process下的网络连接进行序列化 是否允许同时接受多个网络连接 选取处理连接的事件驱动模型 每个worker 支持的最大连接数等  http  全局配置 server配置  全局 location配置    server 配置和匹配规则 一个http服务可以有多个server，而对server的路径匹配，反向代理都是在这里配置的。","title":"Nginx"},{"content":"Pandoc 开始  install pandoc install miktext build  中文要选择合适的字体否则无法成功创建 fc-list  mac: brew install fontconfig fc-list :lang-zh \u0026gt; fonts.txt fc-list -f \u0026ldquo;%{family}\\n\u0026rdquo; :lang=zh   参数解释  -o: 输出文件 \u0026ndash;from: 输入文件类型 \u0026ndash;template: 模版文件 \u0026ndash;listings: 列表 \u0026ndash;pdf-engine: pdf生成用的引擎 -V: 参数  CJKmainfont: 中文文字字体        pandoc \u0026#34;README.md\u0026#34; -o \u0026#34;document.pdf\u0026#34; --from markdown --template \u0026#34;./template.latex\u0026#34; --listings --pdf-engine \u0026#34;xelatex\u0026#34; -V CJKmainfont=\u0026#34;PingFang SC\u0026#34; \u0026amp;\u0026amp; open document.pdf data-dir DATADIR\nmacos: ~/.local/share/pandoc\nwindows: C:\\Users\\USERNAME\\AppData\\Roaming\\pandoc\ndefaults $DATADIR/defaults/docker.yaml，可以为不同的文档设置自己的defaults，避免后面重复操作，仅需使用pandoc --defaults docker即可打包文档\nfrom: markdown # reader: may be used instead of from: to: pdf # writer: may be used instead of to: # leave blank for output to stdout: output-file: docker.pdf # leave blank for input from stdin, use [] for no input: input-files: - 阿里云仓库.md - 管理工具.md - 加速.md - 扩容.md - 清理.md - 容器导出和导入.md - 私有registry.md - debian-docker-install.md - env.md - logs.md - usage.md # or you may use input-file: with a single value # pdf-engine: wkhtmltopdf pdf-engine: xelatex self-contained: false standalone: true metadata: author: - Peter titlepage: true toc-own-page: true toc: true number-sections: true # code block wrap listings: true variables: CJKmainfont: KaiTi template: eisvogel verbosity: ERROR log-file: log.json filters: - mermaid-filter.cmd from: markdown # reader: may be used instead of from: to: pdf # writer: may be used instead of to: # leave blank for output to stdout: output-file: docker.pdf # leave blank for input from stdin, use [] for no input: input-files: - 阿里云仓库.md - 管理工具.md - 加速.md - 扩容.md - 清理.md - 容器导出和导入.md - 私有registry.md - debian-docker-install.md - env.md - logs.md - usage.md # or you may use input-file: with a single value # pdf-engine: wkhtmltopdf pdf-engine: xelatex self-contained: false standalone: true metadata: author: - Peter titlepage: true toc-own-page: true toc: true number-sections: true # code block wrap listings: true variables: CJKmainfont: KaiTi template: eisvogel verbosity: ERROR log-file: log.json filters: - mermaid-filter.cmd template 设置为系统配置，eisvogel.latex，github\nmacos: mkdir -p ~/.local/share/pandoc/templates windows: mkdir -p C:\\Users\\USERNAME\\AppData\\Roaming\\pandoc\\templates cp ./eisvogel.latex ~/.local/share/pandoc/templates/ pandoc \u0026quot;README.md\u0026quot; -o \u0026quot;document.pdf\u0026quot; --from markdown --template eisvogel --listings --pdf-engine \u0026quot;xelatex\u0026quot; -V CJKmainfont=\u0026quot;PingFang SC\u0026quot; \u0026amp;\u0026amp; open document.pdf 多个md文件输入  使用系统路径下的模版 eisvogel \u0026ndash;number-sections 为各个标题编码 toc 标题 toc-own-page 标题页之后从新页开始内容 titlepage 封面   ```markdown --- title: 前端组IT手册 date: 2021-11-12 author: 前端组 titlepage: true toc: true toc-own-page: true --- \u0026gt; pandoc *.md -o \u0026#34;前端IT手册.pdf\u0026#34; --from markdown --template eisvogel --listings --number-sections --pdf-engine \u0026#34;xelatex\u0026#34; -V CJKmainfont=\u0026#34;PingFang SC\u0026#34; \u0026amp;\u0026amp; open \u0026#34;前端IT手册.pdf\u0026#34; 支持mermaid 使用filter特性，首先安装对应的filter\nnpm install --global mermaid-filter 设置全局的npm安装位置到$PATH里面，否则无法识别filter。\n在defaults对应的文件中添加filters：\nfilters: - mermaid-filter.cmd (windows) - mermaid-filter.sh 在cli中添加 \u0026ndash;filter参数：\npandoc --defaults docker --filter mermaid-filter 制作一个pandoc镜像 https://github.com/26huitailang/pandoc-demo\n","permalink":"http://localhost:8000/posts/markdown/pandoc/","summary":"Pandoc 开始  install pandoc install miktext build  中文要选择合适的字体否则无法成功创建 fc-list  mac: brew install fontconfig fc-list :lang-zh \u0026gt; fonts.txt fc-list -f \u0026ldquo;%{family}\\n\u0026rdquo; :lang=zh   参数解释  -o: 输出文件 \u0026ndash;from: 输入文件类型 \u0026ndash;template: 模版文件 \u0026ndash;listings: 列表 \u0026ndash;pdf-engine: pdf生成用的引擎 -V: 参数  CJKmainfont: 中文文字字体        pandoc \u0026#34;README.md\u0026#34; -o \u0026#34;document.pdf\u0026#34; --from markdown --template \u0026#34;./template.latex\u0026#34; --listings --pdf-engine \u0026#34;xelatex\u0026#34; -V CJKmainfont=\u0026#34;PingFang SC\u0026#34; \u0026amp;\u0026amp; open document.pdf data-dir DATADIR\nmacos: ~/.","title":"Pandoc"},{"content":"README 初次使用  podman root用户和非root用户的images和container是分开的 非root用户使用podman generate systemd命令生成的文件，拷贝到~/.config/systemd/user/下面，使用systemctl --user执行  流程演示\npodman pull docker.io/nginx:latest podman create --name nginx -p 8080:80 nginx:latest mkdir -p ~/.config/systemd/user cd ~/.config/systemd/user podman generate systemd --files --name nginx systemctl --user enable container-nginx systemctl --user start container-nginx curl http://127.0.0.1:8080 ","permalink":"http://localhost:8000/posts/podman/readme/","summary":"README 初次使用  podman root用户和非root用户的images和container是分开的 非root用户使用podman generate systemd命令生成的文件，拷贝到~/.config/systemd/user/下面，使用systemctl --user执行  流程演示\npodman pull docker.io/nginx:latest podman create --name nginx -p 8080:80 nginx:latest mkdir -p ~/.config/systemd/user cd ~/.config/systemd/user podman generate systemd --files --name nginx systemctl --user enable container-nginx systemctl --user start container-nginx curl http://127.0.0.1:8080 ","title":"Podman"},{"content":"Upgrade debian main version update $ apt-get update \u0026amp;\u0026amp; apt-get upgrade backup sources.list $ cp /etc/apt/sources.list /etc/apt/sources.list.bak replace `stretch` to `buster` of `/etc/apt/sources.list` $ sed -i \u0026#39;s/stretch/buster/g\u0026#39; /etc/apt/sources.list run upgrade $ apt-get update \u0026amp;\u0026amp; apt-get upgrade run dist upgrade $ apt-get dist-upgrade $ reboot $ lsb_release -a clean: $ apt-get autoremove ","permalink":"http://localhost:8000/posts/linux/debian/upgrade/","summary":"Upgrade debian main version update $ apt-get update \u0026amp;\u0026amp; apt-get upgrade backup sources.list $ cp /etc/apt/sources.list /etc/apt/sources.list.bak replace `stretch` to `buster` of `/etc/apt/sources.list` $ sed -i \u0026#39;s/stretch/buster/g\u0026#39; /etc/apt/sources.list run upgrade $ apt-get update \u0026amp;\u0026amp; apt-get upgrade run dist upgrade $ apt-get dist-upgrade $ reboot $ lsb_release -a clean: $ apt-get autoremove ","title":"Upgrade debian main version"},{"content":"Gitlab CI/CD For the development environment.\nInstall with docker Read the official documentation for how to install docker.\nI installed docker on the MacOS.\ngitlab documentation\nsudo docker run --detach \\  --hostname 192.168.8.226 \\  --publish 443:443 --publish 80:80 --publish 8022:22 \\  --name gitlab \\  --restart always \\  --volume ~/gitlab/config:/etc/gitlab \\  --volume ~/gitlab/logs:/var/log/gitlab \\  --volume ~/gitlab/data:/var/opt/gitlab \\  gitlab/gitlab-ce:latest gitlab-runner Order of initialization:\n install register custom config  documentation\nThere is no difficulty to install gitlab and gitlab-runner in docker.\nsudo docker run -d --name gitlab-runner --restart always \\  -v ~/gitlab-runner/config:/etc/gitlab-runner \\  -v /var/run/docker.sock:/var/run/docker.sock \\  gitlab/gitlab-runner:latest I was confused with the config of gitlab-runner, so I wrote these down.\nregister:\n docker run --rm -t -i -v ~/gitlab-runner/config:/etc/gitlab-runner gitlab/gitlab-runner register, cmd for register a runner.  the register info will record in the ~/gitlab-runner/config/config.toml url is the url of the gitlab token is from your gitlab, the project runner and shared runner is different. You can registe it for shared runner and enable for the specified project. executor choose docker, I use the image python:3.7 for my python project. manual operation to edit the config.toml:  pull_policy = \u0026quot;if-not-present\u0026quot; default value is always for every time pull the image. network_mode = \u0026quot;host\u0026quot; default value is bridge that runner cannot connect other machines in the same net.      for non-interactive register:\ndocker run --rm -v /srv/gitlab-runner/config:/etc/gitlab-runner gitlab/gitlab-runner register \\  --non-interactive \\  --executor \u0026#34;docker\u0026#34; \\  --docker-image alpine:latest \\  --url \u0026#34;https://gitlab.com/\u0026#34; \\  --registration-token \u0026#34;PROJECT_REGISTRATION_TOKEN\u0026#34; \\  --description \u0026#34;docker-runner\u0026#34; \\  --tag-list \u0026#34;docker,aws\u0026#34; \\  --run-untagged=\u0026#34;true\u0026#34; \\  --locked=\u0026#34;false\u0026#34; \\  --access-level=\u0026#34;not_protected\u0026#34; config.toml privileged 如果遇到mkdir permission denied，设为true，可以解决\n[[runners]] name = \u0026#34;python3.7\u0026#34; url = \u0026#34;http://192.168.8.226/\u0026#34; token = \u0026#34;xxxxxx\u0026#34; executor = \u0026#34;docker\u0026#34; [runners.custom_build_dir] [runners.docker] tls_verify = false image = \u0026#34;python:3.7\u0026#34; privileged = true disable_entrypoint_overwrite = false oom_kill_disable = false disable_cache = false volumes = [\u0026#34;/cache\u0026#34;] shm_size = 0 pull_policy = \u0026#34;if-not-present\u0026#34; network_mode = \u0026#34;host\u0026#34; [runners.cache] [runners.cache.s3] [runners.cache.gcs] [runners.custom] run_exec = \u0026#34;\u0026#34; cache with local files. Npm example:\nvolumes = [\u0026quot;/opt/gitlab-runner/cache:/cache\u0026quot;] ls /opt/gitlab-runner/cache/GROUP/PROJECT_NAME/builds/GROUP/PROJECT_NAME cache.zip cache.zip is the node_modules.zip file.\n.gitlab-ci.yml  Use the ssh connect development machine and run the shell command to update the project. cache after the CI. The runner will cache the pip and venv packages.  # This file is a template, and might need editing before it works on your project. image: python:3.7 # This folder is cached between builds # http://docs.gitlab.com/ce/ci/yaml/README.html#cache cache: paths: - .cache/pip - venv/ before_script: ## ## Install ssh-agent if not already installed, it is required by Docker. ## (change apt-get to yum if you use an RPM-based image) ## - \u0026#39;which ssh-agent || ( apt-get update -y \u0026amp;\u0026amp; apt-get install openssh-client -y )\u0026#39; ## ## Run ssh-agent (inside the build environment) ## - eval $(ssh-agent -s) ## ## Add the SSH key stored in SSH_PRIVATE_KEY variable to the agent store ## We\u0026#39;re using tr to fix line endings which makes ed25519 keys work ## without extra base64 encoding. ## https://gitlab.com/gitlab-examples/ssh-private-key/issues/1#note_48526556 ## - echo \u0026#34;$SSH_PRIVATE_KEY\u0026#34; \u0026gt; deploy.key - chmod 0600 deploy.key - ssh-add deploy.key - mkdir -p ~/.ssh - chmod 700 ~/.ssh - \u0026#39;[[ -f /.dockerenv ]] \u0026amp;\u0026amp; echo -e \u0026#34;Host *\\n\\tStrictHostKeyChecking no\\n\\n\u0026#34; \u0026gt; ~/.ssh/config\u0026#39; ## ## Optionally, if you will be using any Git commands, set the user name and ## and email. ## #- git config --global user.email \u0026#34;user@example.com\u0026#34; #- git config --global user.name \u0026#34;User name\u0026#34; - python -V  # Print out python version for debugging test: script: - python -m venv ./venv - source venv/bin/activate - pip install -U -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple/ - cd lq_end # - cp -f config/ci.py config/config.py # - python manage.py devops drop_and_recreate_ci_database # - flask db upgrade # - flask init-db - python -m pytest --cov=. - ssh root@192.168.8.109 \u0026#34;cd /root/test-project \u0026amp;\u0026amp; ./script.sh\u0026#34; #pep8: # script: # - python -m venv ./venv # - source venv/bin/activate # - pip install -U flake8 # - cd projectpath # - flake8 ","permalink":"http://localhost:8000/posts/devops/gitlab/gitlab-ci-cd/","summary":"Gitlab CI/CD For the development environment.\nInstall with docker Read the official documentation for how to install docker.\nI installed docker on the MacOS.\ngitlab documentation\nsudo docker run --detach \\  --hostname 192.168.8.226 \\  --publish 443:443 --publish 80:80 --publish 8022:22 \\  --name gitlab \\  --restart always \\  --volume ~/gitlab/config:/etc/gitlab \\  --volume ~/gitlab/logs:/var/log/gitlab \\  --volume ~/gitlab/data:/var/opt/gitlab \\  gitlab/gitlab-ce:latest gitlab-runner Order of initialization:\n install register custom config  documentation","title":"Gitlab CI/CD"},{"content":"Apache Bench Test   GET\nab -c 10 -n 40 http://127.0.0.1:8000/api/v1/mzitu/tags/\n  POST, https://blog.csdn.net/chenggong2dm/article/details/51850923\nab -n 1 -c 1 -p f:/postdata.txt -T application/x-www-form-urlencoded \u0026ldquo;http://127.0.0.1/abpost\u0026rdquo; ab -n 100 -c 10 -p data.json -T application/json http://127.0.0.1/api\n  // postdata.txt ","permalink":"http://localhost:8000/posts/test/ab-test/","summary":"Apache Bench Test   GET\nab -c 10 -n 40 http://127.0.0.1:8000/api/v1/mzitu/tags/\n  POST, https://blog.csdn.net/chenggong2dm/article/details/51850923\nab -n 1 -c 1 -p f:/postdata.txt -T application/x-www-form-urlencoded \u0026ldquo;http://127.0.0.1/abpost\u0026rdquo; ab -n 100 -c 10 -p data.json -T application/json http://127.0.0.1/api\n  // postdata.txt ","title":"Apache Bench Test"},{"content":"Prometheus 简介 概念  prometheus server exporter，用于server采集数据，有官方提供的node-exporter，也可以通过各种SDK自定义导出内容，暴露一个类似/metrics的路径用于采集  注意，exporter在多进程（gunicorn 多进程）模式下使用会有限制，参考文档   数据模型，和influxdb类似，是时序数据库，以metric为名称，多个label（key-value形式）组成：\u0026lt;metric name\u0026gt;{\u0026lt;label name\u0026gt;=\u0026lt;label value\u0026gt;, ...}  重载配置 Yes, sending SIGHUP to the Prometheus process or an HTTP POST request to the /-/reload endpoint will reload and apply the configuration file. The various components attempt to handle failing changes gracefully.\n","permalink":"http://localhost:8000/posts/k3s/prometheus/","summary":"Prometheus 简介 概念  prometheus server exporter，用于server采集数据，有官方提供的node-exporter，也可以通过各种SDK自定义导出内容，暴露一个类似/metrics的路径用于采集  注意，exporter在多进程（gunicorn 多进程）模式下使用会有限制，参考文档   数据模型，和influxdb类似，是时序数据库，以metric为名称，多个label（key-value形式）组成：\u0026lt;metric name\u0026gt;{\u0026lt;label name\u0026gt;=\u0026lt;label value\u0026gt;, ...}  重载配置 Yes, sending SIGHUP to the Prometheus process or an HTTP POST request to the /-/reload endpoint will reload and apply the configuration file. The various components attempt to handle failing changes gracefully.","title":"Prometheus"},{"content":"PyCharm 使用 Docker pycharm use docker for development and stage\nDevelopment  使用windows和virtualbox，没有打开hyper-v所以无法使用docker，在虚拟机中使用docker并打开tcp，但是由于volume只能挂载宿主机，所以要先用pycharmm将文件拷贝到远程的映射目录，再使用。  此方法适合还没有准备开发环境和需要使用docker作为开发环境，但是windows本机没有docker的情况 我已使用虚拟机和pycharm远程同步功能达到同样的效果   在宿主机中开发时，可以很方便的将docker配置集成到configuration中  Stage PyCharm的docker也支持修改registry，如果有远程仓库需要的，也可以方便分发镜像\n","permalink":"http://localhost:8000/posts/pycharm/docker/","summary":"PyCharm 使用 Docker pycharm use docker for development and stage\nDevelopment  使用windows和virtualbox，没有打开hyper-v所以无法使用docker，在虚拟机中使用docker并打开tcp，但是由于volume只能挂载宿主机，所以要先用pycharmm将文件拷贝到远程的映射目录，再使用。  此方法适合还没有准备开发环境和需要使用docker作为开发环境，但是windows本机没有docker的情况 我已使用虚拟机和pycharm远程同步功能达到同样的效果   在宿主机中开发时，可以很方便的将docker配置集成到configuration中  Stage PyCharm的docker也支持修改registry，如果有远程仓库需要的，也可以方便分发镜像","title":"PyCharm Docker"},{"content":"Django打开gzip导致文件流content-length丢失 code GZipMiddleware\nuse gzip middleware will del response['Content-Length'] if response.streaming. nginx gzip is the same problem.\nIf file feature is important. You\u0026rsquo;d better be independent from the api or system.\n","permalink":"http://localhost:8000/posts/django/gzip/","summary":"Django打开gzip导致文件流content-length丢失 code GZipMiddleware\nuse gzip middleware will del response['Content-Length'] if response.streaming. nginx gzip is the same problem.\nIf file feature is important. You\u0026rsquo;d better be independent from the api or system.","title":"Django打开gzip导致文件流content-length丢失"},{"content":"k3s 初次使用 multipass 环境准备  quick-start 参考1 参考2  # k3s1 node for master 192.168.64.5 multipass launch -v --name k3s1 20.04 multipass shell k3s1 curl -sfL https://get.k3s.io | sh - # default config sudo cat /etc/rancher/k3s/k3s.yaml # node-token sudo cat /var/lib/rancher/k3s/server/node-token # Check for Ready node, takes maybe 30 seconds sudo kubectl get nodes # k3s2 node 192.168.64.6 multipass launch -v --name k3s2 20.04 multipass shell k3s2 # add node to cluster # token in master cat /var/lib/rancher/k3s/server/node-token # K3S_NODE_NAME for unique hostname export K3S_TOKEN=x export K3S_URL=https://192.168.1.21:6443 curl -sfL https://get.k3s.io | K3S_URL=${K3S_URL} K3S_TOKEN=${K3S_TOKEN} sh - # if not register successfully, 查看日志可能是因为之前有重复node hostname # 原因：https://github.com/rancher/k3s/issues/802 移除node没有一同移除密码 sudo vim /var/lib/rancher/k3s/server/cred/node-passwd 查看节点状态：\nsudo kubectl get nodes  dashboard kube-dashboard\ninstall\nGITHUB_URL=https://github.com/kubernetes/dashboard/releases VERSION_KUBE_DASHBOARD=$(curl -w \u0026#39;%{url_effective}\u0026#39; -I -L -s -S ${GITHUB_URL}/latest -o /dev/null | sed -e \u0026#39;s|.*/||\u0026#39;) sudo k3s kubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/${VERSION_KUBE_DASHBOARD}/aio/deploy/recommended.yaml Dashboard RBAC Configuration\ndashboard.admin-user.yml\napiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kubernetes-dashboard dashboard.admin-user-role.yml\napiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: admin-user roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: admin-user namespace: kubernetes-dashboard sudo k3s kubectl create -f dashboard.admin-user.yml -f dashboard.admin-user-role.yml Obtain the Bearer Token, 用于token登录dashboard\nsudo k3s kubectl -n kubernetes-dashboard describe secret admin-user-token | grep ^token access\nhttp://192.168.64.5:6443/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/  ingress k3s 默认使用的是traefik，k8s推荐的是GCE和ingress-nginx。\n但是traefik默认配置: /var/lib/rancher/k3s/server/manifests/traefik.yaml 没有开启dashboard。尝试打开：\n查看当前配置：\nkubectl describe deploy traefik -n kube-system  得知配置是使用的 /config 的volume：\nkubectl describe configmap traefik -n kube-system  添加set部分内容：\nset: dashboard.enabled: \u0026quot;true\u0026quot;  traefik.yml\nroot@k3s1:/var/lib/rancher/k3s/server/manifests# cat traefik.yaml  apiVersion: helm.cattle.io/v1 kind: HelmChart metadata: name: traefik namespace: kube-system spec: chart: https://%{KUBERNETES_API}%/static/charts/traefik-1.81.0.tgz set: dashboard.enabled: \u0026#34;true\u0026#34; valuesContent: |-rbac: enabled: true ssl: enabled: true metrics: prometheus: enabled: true kubernetes: ingressEndpoint: useDefaultPublishedService: true image: \u0026#34;rancher/library-traefik\u0026#34; tolerations: - key: \u0026#34;CriticalAddonsOnly\u0026#34; operator: \u0026#34;Exists\u0026#34; - key: \u0026#34;node-role.kubernetes.io/master\u0026#34; operator: \u0026#34;Exists\u0026#34; effect: \u0026#34;NoSchedule\u0026#34; 如何配置ingress，配合一个django的sample\napiVersion: extensions/v1beta1 kind: Ingress metadata: name: my-server spec: rules: - host: my-server.192.168.1.22.xip.io http: paths: - path: /jobs backend: serviceName: web servicePort: 8080 - path: /static backend: serviceName: web servicePort: 8080 cheat sheet cheatsheet\nnginx demo in k3s2 machine\nmkdir ~/controllers cat \u0026gt; nginx-deployment.yaml \u0026lt;\u0026lt;EOL apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment labels: app: nginx spec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80 EOL 问题  vagrant nat 10.0.2.15网络问题，server/agent 选择对应的网络启动，不然默认选中第一个  sudo vim /etc/systemd/system/k3s-agent.service sudo vim /etc/systemd/system/k3s.service ExecStart=/usr/local/bin/k3s \\ server --flannel-iface=enp0s8 \\  镜像 docker.io 加速，在containerd的config中加入地址，http://www.zzfly.net/k3s-installation-and-containerd-registry/  [plugins.cri.registry.mirrors] [plugins.cri.registry.mirrors.\u0026#34;docker.io\u0026#34;] endpoint = [\u0026#34;https://docker.mirrors.ustc.edu.cn\u0026#34;] root@k3s1:/vagrant/samples-master/django# cd /var/lib/rancher/k3s/agent/etc/containerd/ root@k3s1:/var/lib/rancher/k3s/agent/etc/containerd# ls config.toml root@k3s1:/var/lib/rancher/k3s/agent/etc/containerd# cp config.toml config.toml.tmpl root@k3s1:/var/lib/rancher/k3s/agent/etc/containerd# vim config.toml.tmpl root@k3s1:/var/lib/rancher/k3s/agent/etc/containerd# systemctl restart k3s root@k3s1:/var/lib/rancher/k3s/agent/etc/containerd# crictl info | grep registry -C 10 } }, \u0026quot;noPivot\u0026quot;: false }, \u0026quot;cni\u0026quot;: { \u0026quot;binDir\u0026quot;: \u0026quot;/var/lib/rancher/k3s/data/572dcee7aa63e8f11e61142e4b0fc4f7ce33a0a6fed6a72924c6f6be85781b10/bin\u0026quot;, \u0026quot;confDir\u0026quot;: \u0026quot;/var/lib/rancher/k3s/agent/etc/cni/net.d\u0026quot;, \u0026quot;maxConfNum\u0026quot;: 1, \u0026quot;confTemplate\u0026quot;: \u0026quot;\u0026quot; }, \u0026quot;registry\u0026quot;: { \u0026quot;mirrors\u0026quot;: { \u0026quot;docker.io\u0026quot;: { \u0026quot;endpoint\u0026quot;: [ \u0026quot;https://docker.mirrors.ustc.edu.cn\u0026quot; ] } }, \u0026quot;configs\u0026quot;: null, \u0026quot;auths\u0026quot;: null }, ","permalink":"http://localhost:8000/posts/k3s/k3s/","summary":"k3s 初次使用 multipass 环境准备  quick-start 参考1 参考2  # k3s1 node for master 192.168.64.5 multipass launch -v --name k3s1 20.04 multipass shell k3s1 curl -sfL https://get.k3s.io | sh - # default config sudo cat /etc/rancher/k3s/k3s.yaml # node-token sudo cat /var/lib/rancher/k3s/server/node-token # Check for Ready node, takes maybe 30 seconds sudo kubectl get nodes # k3s2 node 192.168.64.6 multipass launch -v --name k3s2 20.04 multipass shell k3s2 # add node to cluster # token in master cat /var/lib/rancher/k3s/server/node-token # K3S_NODE_NAME for unique hostname export K3S_TOKEN=x export K3S_URL=https://192.","title":"k3s"},{"content":"Golang 搭建环境 Golang 开发环境准备和工具选择\n参考Alikhll/golang-developer-roadmap。\n更多关于golang的分享，参考Awesome-go\n环境准备  加速/私有模块  开发编辑器/IDE  vim vscode goland  软件选择  CLI工具开发  cobra   Web  Gin🍺 Echo🍺 Beego go-swagger Iris   ORM  Gorm🍺 Xorm   DB  PG🍺 Redis🍺 MongoDB   Log  Zap Logrus   Websocket  gorilla/websocket   Task schedule  Gron    CI/CD  gitlab CI/CD githu actions teamcity  部署选择  docker supervisor  ","permalink":"http://localhost:8000/posts/golang/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/","summary":"Golang 搭建环境 Golang 开发环境准备和工具选择\n参考Alikhll/golang-developer-roadmap。\n更多关于golang的分享，参考Awesome-go\n环境准备  加速/私有模块  开发编辑器/IDE  vim vscode goland  软件选择  CLI工具开发  cobra   Web  Gin🍺 Echo🍺 Beego go-swagger Iris   ORM  Gorm🍺 Xorm   DB  PG🍺 Redis🍺 MongoDB   Log  Zap Logrus   Websocket  gorilla/websocket   Task schedule  Gron    CI/CD  gitlab CI/CD githu actions teamcity  部署选择  docker supervisor  ","title":"golang 大奖环境"},{"content":"multipass to set development environment 官网\n指定配置 $ multipass launch --name XXX -c 2 -d 20G -m 2G  删除 $ multipass delete --purge XXXXX  问题  macos下面使用virtualbox暂时拿不到ip，只能使用NAT，最好使用hyperkit windows下面也不行，尝试添加第二个网络(gui操作 or vboxmanager)，我这里使用了桥接，之后修改/etc/network/interfaces填写相关信息，重启之后查看网卡能获得ip  # ubuntu 18.04 allow-hotplug enp0s8 iface enp0s8 inet static address 10.200.242.200 netmask 255.0.0.0 gateway 10.0.0.3  ubuntu20.04操作:  修改 /etc/netplan/50-cloud-init.yaml 应用 sudo netplan apply 重启 sudo reboot    # ubuntu 20.04 /etc/netplan/50-cloud-init.yaml network: ethernets: enp0s3: dhcp4: true match: macaddress: 08:00:27:bc:97:36 set-name: enp0s3 version: 2 # change like following part network: ethernets: enp0s3: dhcp4: false addresses: [10.200.242.200/8] gateway4: 10.0.0.3 nameservers: addresses: [8.8.8.8, 8.8.4.4] match: macaddress: 08:00:27:bc:97:36 set-name: enp0s3 version: 2 ","permalink":"http://localhost:8000/posts/linux/ubuntu/multipass/","summary":"multipass to set development environment 官网\n指定配置 $ multipass launch --name XXX -c 2 -d 20G -m 2G  删除 $ multipass delete --purge XXXXX  问题  macos下面使用virtualbox暂时拿不到ip，只能使用NAT，最好使用hyperkit windows下面也不行，尝试添加第二个网络(gui操作 or vboxmanager)，我这里使用了桥接，之后修改/etc/network/interfaces填写相关信息，重启之后查看网卡能获得ip  # ubuntu 18.04 allow-hotplug enp0s8 iface enp0s8 inet static address 10.200.242.200 netmask 255.0.0.0 gateway 10.0.0.3  ubuntu20.04操作:  修改 /etc/netplan/50-cloud-init.yaml 应用 sudo netplan apply 重启 sudo reboot    # ubuntu 20.04 /etc/netplan/50-cloud-init.yaml network: ethernets: enp0s3: dhcp4: true match: macaddress: 08:00:27:bc:97:36 set-name: enp0s3 version: 2 # change like following part network: ethernets: enp0s3: dhcp4: false addresses: [10.","title":"Multipass"},{"content":"利用proxy 解决 Django Vue 开发环境中的跨域问题 最近使用 Django+Vue的组合快速的做一个项目，前段之前有看过，但是只是👀会了，这次实际操作，在前后端分离后的开发环境中踩了坑。\n环境  Django + DRF Django Channels，主要是websocket vue-admin-template，一个开源的项目，很多东西都有实现，新手可以用来改改就用，还能学习  开发环境：\n wsgi, 8000 asgi, 8001 vue, 9528  问题  想像在使用nginx一样的透明的使用开发环境 django已经配置了corsheaders middleware了 尝试 axios显示指定地址和端口到8000的服务上，解决了axios实例的访问，但是使用 el-upload的表单时，发现就不好使了，localhost和其他不同域，拿不到 cookie中的csrftoken，导致被 django拒绝  解决 在查看了各种文档后，最有效的方案是devServer的proxy，这是webpack提供的功能，使用的是http-proxy-middleware这个中间件，文档很详细，可以看看。\n目标：\n 代理 /api的请求到8000端口的wsgi server 代理 /ws的请求到8001的asgi server   /api ---\u0026gt; localhost:8000/api localhost:9528 (cookie) -- /ws ---\u0026gt; localhost:8001/ws vue.conf.js\ndevServer: { ... proxy: { [process.env.VUE_APP_BASE_API]: { target: \u0026#39;http://127.0.0.1:8000\u0026#39;, changeOrigin: true, ws: false, pathRewrite: { [\u0026#39;^\u0026#39; + process.env.VUE_APP_BASE_API]: \u0026#39;\u0026#39; }, cookieDomainRewrite: { \u0026#39;*\u0026#39;: \u0026#39;localhost\u0026#39; } }, \u0026#39;/ws\u0026#39;: { target: \u0026#39;ws://127.0.0.1:8001\u0026#39;, // changeOrigin: true,  secure: false, ws: true } } ... } 说明：\n proxy里面的key表示要代理的path，我这里写的是变量代表的值，是从其他地方看到的，可以根据这个值来判断，比如 /api-prod /api-dev等，这里可以根据自己项目实际的命名规则，一般是/api即可 target：表示要代理的请求目标 changeOrigin：表示修改请求header中的origin ws：表示是否代理websockets pathRewrite：根据正则匹配来重写url，根据实际需要来写 cookieDomainRewrite，{ '*': 'localhost' }表示所有重写到localhost，这样所有的cookie都会同步过来，因为我使用了django session和crsftoken，所以这里得同步一下，不然会有前面说的axios header中有X-CRSFToken，而直接请求的form表单中没有，因为cookie不同，取不到csrftoken的值  ","permalink":"http://localhost:8000/posts/vue/cors/","summary":"利用proxy 解决 Django Vue 开发环境中的跨域问题 最近使用 Django+Vue的组合快速的做一个项目，前段之前有看过，但是只是👀会了，这次实际操作，在前后端分离后的开发环境中踩了坑。\n环境  Django + DRF Django Channels，主要是websocket vue-admin-template，一个开源的项目，很多东西都有实现，新手可以用来改改就用，还能学习  开发环境：\n wsgi, 8000 asgi, 8001 vue, 9528  问题  想像在使用nginx一样的透明的使用开发环境 django已经配置了corsheaders middleware了 尝试 axios显示指定地址和端口到8000的服务上，解决了axios实例的访问，但是使用 el-upload的表单时，发现就不好使了，localhost和其他不同域，拿不到 cookie中的csrftoken，导致被 django拒绝  解决 在查看了各种文档后，最有效的方案是devServer的proxy，这是webpack提供的功能，使用的是http-proxy-middleware这个中间件，文档很详细，可以看看。\n目标：\n 代理 /api的请求到8000端口的wsgi server 代理 /ws的请求到8001的asgi server   /api ---\u0026gt; localhost:8000/api localhost:9528 (cookie) -- /ws ---\u0026gt; localhost:8001/ws vue.conf.js\ndevServer: { ... proxy: { [process.env.VUE_APP_BASE_API]: { target: \u0026#39;http://127.0.0.1:8000\u0026#39;, changeOrigin: true, ws: false, pathRewrite: { [\u0026#39;^\u0026#39; + process.","title":"vue cors"},{"content":"docker env file 在docker-compose 中使用以下方式导入.envfile。\nweb: build: . restart: always working_dir: /deploy/mysite command: ./service_web.sh env_file: - .env # environments .env\nDOCKER=1 HOME=/deploy 想用shell script动态获取环境的CPU count 如果直接在.env 中写如下的内容，会报语法错误：\nCPU_NUM=$(cat /proc/cpuinfo |grep processor|wc -l)  所以，在web服务的command: ./service_web.sh脚本中export一个变量，并在gunicorn中使用：\n#!/bin/bash sleep 5 export CPU_NUM=$(cat /proc/cpuinfo |grep processor|wc -l) python manage.py collectstatic -v0 --noinput python manage.py migrate --noinput /usr/local/bin/gunicorn -w $((2*$CPU_NUM+1)) -b unix:/deploy/running/handle/django-tutorial-server.sock mysite.wsgi:application --log-level info ","permalink":"http://localhost:8000/posts/docker/env/","summary":"docker env file 在docker-compose 中使用以下方式导入.envfile。\nweb: build: . restart: always working_dir: /deploy/mysite command: ./service_web.sh env_file: - .env # environments .env\nDOCKER=1 HOME=/deploy 想用shell script动态获取环境的CPU count 如果直接在.env 中写如下的内容，会报语法错误：\nCPU_NUM=$(cat /proc/cpuinfo |grep processor|wc -l)  所以，在web服务的command: ./service_web.sh脚本中export一个变量，并在gunicorn中使用：\n#!/bin/bash sleep 5 export CPU_NUM=$(cat /proc/cpuinfo |grep processor|wc -l) python manage.py collectstatic -v0 --noinput python manage.py migrate --noinput /usr/local/bin/gunicorn -w $((2*$CPU_NUM+1)) -b unix:/deploy/running/handle/django-tutorial-server.sock mysite.wsgi:application --log-level info ","title":"docker env file"},{"content":"docker 使用 zsh插件支持docker和docker-compose，gui工具在mac和win下有kitemactic。\nDockfile 用于构建image的文件。\ndocker-compose.yml 管理和使用docker服务的工具，可以类似vagrant的配置，可以很快的编排需要的services以及networks并启动。\n docker-compose -f YML-CONF-FILE up，可以指定配置文件启动，这样可以区别正式环境和开发环境的docker  up可以是别没有的服务并重新build，也可以用\u0026ndash;build强制    重新build镜像 不使用缓存重新build。修改配置后。\ndocker build . --no-cache  ","permalink":"http://localhost:8000/posts/docker/usage/","summary":"docker 使用 zsh插件支持docker和docker-compose，gui工具在mac和win下有kitemactic。\nDockfile 用于构建image的文件。\ndocker-compose.yml 管理和使用docker服务的工具，可以类似vagrant的配置，可以很快的编排需要的services以及networks并启动。\n docker-compose -f YML-CONF-FILE up，可以指定配置文件启动，这样可以区别正式环境和开发环境的docker  up可以是别没有的服务并重新build，也可以用\u0026ndash;build强制    重新build镜像 不使用缓存重新build。修改配置后。\ndocker build . --no-cache  ","title":"docker 使用"},{"content":"docker 加速 mac  ~/.docker/daemon.json 添加如下配置  { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://registry.docker-cn.com\u0026#34;] } ","permalink":"http://localhost:8000/posts/docker/%E5%8A%A0%E9%80%9F/","summary":"docker 加速 mac  ~/.docker/daemon.json 添加如下配置  { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://registry.docker-cn.com\u0026#34;] } ","title":"docker 加速"},{"content":"docker 容器导出和导入 在一个地方build后导入到其他地方使用\nhttps://yeasy.gitbooks.io/docker_practice/container/import_export.html\n导出 $ docker container ls -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 7691a814370e ubuntu:18.04 \u0026quot;/bin/bash\u0026quot; 36 hours ago Exited (0) 21 hours ago test $ docker export 7691a814370e \u0026gt; ubuntu.tar  导入 $ cat ubuntu.tar | docker import - test/ubuntu:v1.0 $ docker image ls REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE test/ubuntu v1.0 9d37a6082e97 About a minute ago 171.3 MB  此外，也可以通过指定 URL 或者某个目录来导入，例如\n$ docker import http://example.com/exampleimage.tgz example/imagerepo  注：用户既可以使用 docker load 来导入镜像存储文件到本地镜像库，也可以使用 docker import 来导入一个容器快照到本地镜像库。这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也要大。此外，从容器快照文件导入时可以重新指定标签等元数据信息。\n","permalink":"http://localhost:8000/posts/docker/%E5%AE%B9%E5%99%A8%E5%AF%BC%E5%87%BA%E5%92%8C%E5%AF%BC%E5%85%A5/","summary":"docker 容器导出和导入 在一个地方build后导入到其他地方使用\nhttps://yeasy.gitbooks.io/docker_practice/container/import_export.html\n导出 $ docker container ls -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 7691a814370e ubuntu:18.04 \u0026quot;/bin/bash\u0026quot; 36 hours ago Exited (0) 21 hours ago test $ docker export 7691a814370e \u0026gt; ubuntu.tar  导入 $ cat ubuntu.tar | docker import - test/ubuntu:v1.0 $ docker image ls REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE test/ubuntu v1.0 9d37a6082e97 About a minute ago 171.3 MB  此外，也可以通过指定 URL 或者某个目录来导入，例如","title":"docker 容器导出和导入"},{"content":"docker 快速扩容 以celery worker为例。当启动docker-compose up后，可以看到有一个celery-worker容器在运行。\n如果要临时增加，可以使用--scale参数配合up指令，接受多个容器传递：\ndocker-compose up --scale web=2 celery-worker=3  经测试，多个worker都获得了发送过来的任务。\n","permalink":"http://localhost:8000/posts/docker/%E6%89%A9%E5%AE%B9/","summary":"docker 快速扩容 以celery worker为例。当启动docker-compose up后，可以看到有一个celery-worker容器在运行。\n如果要临时增加，可以使用--scale参数配合up指令，接受多个容器传递：\ndocker-compose up --scale web=2 celery-worker=3  经测试，多个worker都获得了发送过来的任务。","title":"docker 快速扩容"},{"content":"docker 日志 后台运行docker的时候，怎么查看日志？\ndocker logs SERVICE_NAME  ","permalink":"http://localhost:8000/posts/docker/logs/","summary":"docker 日志 后台运行docker的时候，怎么查看日志？\ndocker logs SERVICE_NAME  ","title":"docker 日志"},{"content":"docker 清理   怎么清理不用的容器和镜像？\n  docker占用过多的磁盘空间？\n  如何清理Docker占用的磁盘空间?\n  查看 使用docker system命令。查看磁盘使用情况：\n$ docker system df  清理 docker rmi $(docker images --filter \u0026quot;dangling=true\u0026quot; -q)  清理磁盘，删除关闭的容器、无用的数据卷、网络，以及dangling镜像（无tag的镜像）。\n$ docker system prune  更彻底的删除，将没有容器使用的镜像删除：\n$ docker system prune -a  删除none镜像 $ docker rmi $(docker images | grep \u0026quot;none\u0026quot; | awk '{print $3}') //删除镜像  限制容器大小 如nginx，限制该容器的日志文件大小，可以在docker-compose中写入选项max-size:\nnginx: image: nginx:1.12.1 restart: always logging: driver: \u0026#34;json-file\u0026#34; options: max-size: \u0026#34;5g\u0026#34; ","permalink":"http://localhost:8000/posts/docker/%E6%B8%85%E7%90%86/","summary":"docker 清理   怎么清理不用的容器和镜像？\n  docker占用过多的磁盘空间？\n  如何清理Docker占用的磁盘空间?\n  查看 使用docker system命令。查看磁盘使用情况：\n$ docker system df  清理 docker rmi $(docker images --filter \u0026quot;dangling=true\u0026quot; -q)  清理磁盘，删除关闭的容器、无用的数据卷、网络，以及dangling镜像（无tag的镜像）。\n$ docker system prune  更彻底的删除，将没有容器使用的镜像删除：\n$ docker system prune -a  删除none镜像 $ docker rmi $(docker images | grep \u0026quot;none\u0026quot; | awk '{print $3}') //删除镜像  限制容器大小 如nginx，限制该容器的日志文件大小，可以在docker-compose中写入选项max-size:\nnginx: image: nginx:1.12.1 restart: always logging: driver: \u0026#34;json-file\u0026#34; options: max-size: \u0026#34;5g\u0026#34; ","title":"docker 清理"},{"content":"docker 管理工具 kitematic 可以上dockerhub，但是UI不是很好，容器名字看不全，不能拖动界面\nPortainer web服务\ndocker volume create portainer_data docker run -d -p 9000:9000 --name portainer --restart always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer  ","permalink":"http://localhost:8000/posts/docker/%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/","summary":"docker 管理工具 kitematic 可以上dockerhub，但是UI不是很好，容器名字看不全，不能拖动界面\nPortainer web服务\ndocker volume create portainer_data docker run -d -p 9000:9000 --name portainer --restart always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer  ","title":"docker 管理工具"},{"content":"docker 阿里云仓库 登录阿里云Docker Registry $ sudo docker login --username=26huitailang@gmail.com registry.cn-hangzhou.aliyuncs.com  用于登录的用户名为阿里云账号全名，密码为开通服务时设置的密码。\n您可以在产品控制台首页修改登录密码。\n遇到无法登录问题：\nError saving credentials: error storing credentials - err: exit status 1, out: `The name org.freedesktop.secrets was not provided by any .service files sudo apt install gnupg2 pass 从Registry中拉取镜像 $ sudo docker pull registry.cn-hangzhou.aliyuncs.com/26huitailang/golang-web:[镜像版本号]\n将镜像推送到Registry $ sudo docker login --username=26huitailang@gmail.com registry.cn-hangzhou.aliyuncs.com $ sudo docker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/26huitailang/golang-web:[镜像版本号] $ sudo docker push registry.cn-hangzhou.aliyuncs.com/26huitailang/golang-web:[镜像版本号]  请根据实际镜像信息替换示例中的[ImageId]和[镜像版本号]参数。\n选择合适的镜像仓库地址 从ECS推送镜像时，可以选择使用镜像仓库内网地址。推送速度将得到提升并且将不会损耗您的公网流量。\n如果您使用的机器位于VPC网络，请使用 registry-vpc.cn-hangzhou.aliyuncs.com 作为Registry的域名登录，并作为镜像命名空间前缀。\n示例 使用\u0026quot;docker tag\u0026quot;命令重命名镜像，并将它通过专有网络地址推送至Registry。\n$ sudo docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE registry.aliyuncs.com/acs/agent 0.7-dfb6816 37bb9c63c8b2 7 days ago 37.89 MB $ sudo docker tag 37bb9c63c8b2 registry-vpc.cn-hangzhou.aliyuncs.com/acs/agent:0.7-dfb6816  使用\u0026quot;docker images\u0026quot;命令找到镜像，将该镜像名称中的域名部分变更为Registry专有网络地址。\n$ sudo docker push registry-vpc.cn-hangzhou.aliyuncs.com/acs/agent:0.7-dfb6816 ","permalink":"http://localhost:8000/posts/docker/%E9%98%BF%E9%87%8C%E4%BA%91%E4%BB%93%E5%BA%93/","summary":"docker 阿里云仓库 登录阿里云Docker Registry $ sudo docker login --username=26huitailang@gmail.com registry.cn-hangzhou.aliyuncs.com  用于登录的用户名为阿里云账号全名，密码为开通服务时设置的密码。\n您可以在产品控制台首页修改登录密码。\n遇到无法登录问题：\nError saving credentials: error storing credentials - err: exit status 1, out: `The name org.freedesktop.secrets was not provided by any .service files sudo apt install gnupg2 pass 从Registry中拉取镜像 $ sudo docker pull registry.cn-hangzhou.aliyuncs.com/26huitailang/golang-web:[镜像版本号]\n将镜像推送到Registry $ sudo docker login --username=26huitailang@gmail.com registry.cn-hangzhou.aliyuncs.com $ sudo docker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/26huitailang/golang-web:[镜像版本号] $ sudo docker push registry.cn-hangzhou.aliyuncs.com/26huitailang/golang-web:[镜像版本号]  请根据实际镜像信息替换示例中的[ImageId]和[镜像版本号]参数。\n选择合适的镜像仓库地址 从ECS推送镜像时，可以选择使用镜像仓库内网地址。推送速度将得到提升并且将不会损耗您的公网流量。\n如果您使用的机器位于VPC网络，请使用 registry-vpc.","title":"docker 阿里云仓库"},{"content":"Cheatsheet for package manager  go mod pip apt ubuntu 20.04  pip pip install -i https://pypi.tuna.tsinghua.edu.cn/simple some-package\n升级 pip 到最新的版本 (\u0026gt;=10.0.0) 后进行配置：\npip install pip -U pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n如果您到 pip 默认源的网络连接较差，临时使用本镜像站来升级 pip：\npip install -i https://pypi.tuna.tsinghua.edu.cn/simple pip -U\napt ubuntu 20.04\n# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse # 预发布软件源，不建议启用 # deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse go mod GOPROXY=https://goproxy.io,direct\ngo mod init github.com/26huitailang/\u0026lt;PROJECTNAME\u0026gt; go mod vendor ","permalink":"http://localhost:8000/posts/cheatsheet/pkg-manager/","summary":"Cheatsheet for package manager  go mod pip apt ubuntu 20.04  pip pip install -i https://pypi.tuna.tsinghua.edu.cn/simple some-package\n升级 pip 到最新的版本 (\u0026gt;=10.0.0) 后进行配置：\npip install pip -U pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n如果您到 pip 默认源的网络连接较差，临时使用本镜像站来升级 pip：\npip install -i https://pypi.tuna.tsinghua.edu.cn/simple pip -U\napt ubuntu 20.04\n# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse # deb-src https://mirrors.","title":"Cheatsheet for pkg manager"},{"content":"Cobra 命令行 因为之前写 Django，python manage.py这个命令非常好用，想看看能不能实现类似的效果。搜索之后发现了更强的cobra，看简介中使用的项目就知道非常不错。代码组织参考的frp的。\nPATH/frp/cmd，frpc和fprs分别是客户端和服务端\n├───frpc │ │ main.go │ │ │ └───sub │ http.go │ https.go │ reload.go │ root.go │ status.go │ stcp.go │ sudp.go │ tcp.go │ tcpmux.go │ udp.go │ xtcp.go │ └───frps main.go root.go 添加 go get -u github.com/spf13/cobra/cobra 在项目目录中执行，appname mycli，其中cmd中 rootCmd 的名称是mycli，这里建议和appname一样，后面可以直接go install之后使用mycli即可。\nmkdir cmd \u0026amp;\u0026amp; cd cmd cobra init mycli --pkg-name mycli cmd └───mycli │ LICENSE │ main.go │ └───cmd root.go 模板代码 import错误，重新按照自己项目的组织方式重写 import即可。\npackage main import \u0026#34;mycli/cmd\u0026#34; func main() { cmd.Execute() } 测试使用：\ngo run main.go 测试完后，可以go install到系统的路径里，然后使用即可，单个二进制文件发布也非常方便。\n嵌套命令行 mycli CMD SUBCMD 增加第一级命令\n\u0026gt; cobra add user \u0026gt; go run . user user called 增加user下的其他指令\n\u0026gt; cobra add userAdd --parent userCmd \u0026gt; go run . user userAdd userAdd called 现在代码的结构\nmycli │ LICENSE │ main.go │ └───cmd root.go user.go userAdd.go 每一次cobra add都会生成一个文件，--parent指定命令属于哪一个，默认是添加到rootCmd：\n 可以将cobra生成的文件自己重构，移动到对应文件中 userAdd这个是文件名，也是命令名，在cmd的Use属性中可以修改为add，这样使用时mycli user add [flags]  结合到已有系统中 以web server为例，都会设计一个NewServer方法，然后封装一个执行方法，以命令为入口执行即可：\nmycli server  // serverCmd represents the server command var serverCmd = \u0026amp;cobra.Command{ Use: \u0026#34;server\u0026#34;, Short: \u0026#34;A brief description of your command\u0026#34;, Long: `A longer description that spans multiple lines and likely contains examples and usage of using your command. For example: Cobra is a CLI library for Go that empowers applications. This application is a tool to generate the needed files to quickly create a Cobra application.`, Run: func(cmd *cobra.Command, args []string) { runServer() fmt.Println(\u0026#34;server called\u0026#34;) }, } func init() { rootCmd.AddCommand(serverCmd) // Here you will define your flags and configuration settings.  // Cobra supports Persistent Flags which will work for this command \t// and all subcommands, e.g.: \t// serverCmd.PersistentFlags().String(\u0026#34;foo\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;A help for foo\u0026#34;)  // Cobra supports local flags which will only run when this command \t// is called directly, e.g.: \t// serverCmd.Flags().BoolP(\u0026#34;toggle\u0026#34;, \u0026#34;t\u0026#34;, false, \u0026#34;Help message for toggle\u0026#34;) } func runServer() { e := server.NewServer() e.Logger.Fatal(e.Start(config.Config.Port)) } ","permalink":"http://localhost:8000/posts/golang/cobra/","summary":"Cobra 命令行 因为之前写 Django，python manage.py这个命令非常好用，想看看能不能实现类似的效果。搜索之后发现了更强的cobra，看简介中使用的项目就知道非常不错。代码组织参考的frp的。\nPATH/frp/cmd，frpc和fprs分别是客户端和服务端\n├───frpc │ │ main.go │ │ │ └───sub │ http.go │ https.go │ reload.go │ root.go │ status.go │ stcp.go │ sudp.go │ tcp.go │ tcpmux.go │ udp.go │ xtcp.go │ └───frps main.go root.go 添加 go get -u github.com/spf13/cobra/cobra 在项目目录中执行，appname mycli，其中cmd中 rootCmd 的名称是mycli，这里建议和appname一样，后面可以直接go install之后使用mycli即可。\nmkdir cmd \u0026amp;\u0026amp; cd cmd cobra init mycli --pkg-name mycli cmd └───mycli │ LICENSE │ main.go │ └───cmd root.go 模板代码 import错误，重新按照自己项目的组织方式重写 import即可。","title":"Cobra 命令行"},{"content":"docker install install docker on Debian/Ubuntu\nlink\nUninstall old versions $ sudo apt-get remove docker docker-engine docker.io containerd runc Set up the repository $ sudo apt-get update $ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common $ curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add - or $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/gpg | sudo apt-key add - $ sudo apt-key fingerprint 0EBFCD88 $ sudo add-apt-repository \\ \u0026quot;deb [arch=amd64] https://download.docker.com/linux/debian \\ $(lsb_release -cs) \\ stable\u0026quot; or sudo add-apt-repository \\ \u0026quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ focal \\ stable\u0026quot; or $ sudo add-apt-repository \\ \u0026quot;deb [arch=amd64] https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/ \\ $(lsb_release -cs) \\ stable\u0026quot; Install Docker Engine $ sudo apt-get update $ sudo apt-get install docker-ce docker-ce-cli containerd.io $ sudo docker run --rm hello-world $ sudo apt install docker-compose -y Without sudo to use docker $ sudo usermod -aG docker $USER $ sudo systemctl restart docker $ sudo systemctl enable docker Speed up https://YOURS.mirror.aliyuncs.com\nsudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-'EOF' { \u0026quot;registry-mirrors\u0026quot;: [ \u0026quot;https://registry.docker-cn.com\u0026quot;, \u0026quot;http://hub-mirror.c.163.com\u0026quot;, \u0026quot;https://docker.mirrors.ustc.edu.cn\u0026quot; ] } EOF sudo systemctl daemon-reload sudo systemctl restart docker ","permalink":"http://localhost:8000/posts/docker/debian-docker-install/","summary":"docker install install docker on Debian/Ubuntu\nlink\nUninstall old versions $ sudo apt-get remove docker docker-engine docker.io containerd runc Set up the repository $ sudo apt-get update $ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common $ curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add - or $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/gpg | sudo apt-key add - $ sudo apt-key fingerprint 0EBFCD88 $ sudo add-apt-repository \\ \u0026quot;deb [arch=amd64] https://download.","title":"docker install"},{"content":"Docker Private Registry 简单使用，官方 官方提供的 https://hub.docker.com/_/registry\nRun a local registry: Quick Version\n$ docker run -d -p 5000:5000 --restart always --name registry registry:2  Now, use it from within Docker:\n$ docker pull ubuntu $ docker tag ubuntu localhost:5000/ubuntu $ docker push localhost:5000/ubuntu  更复杂的需求，harbor https://goharbor.io/\nOur mission is to be the trusted cloud native repository for Kubernetes\n","permalink":"http://localhost:8000/posts/docker/%E7%A7%81%E6%9C%89registry/","summary":"Docker Private Registry 简单使用，官方 官方提供的 https://hub.docker.com/_/registry\nRun a local registry: Quick Version\n$ docker run -d -p 5000:5000 --restart always --name registry registry:2  Now, use it from within Docker:\n$ docker pull ubuntu $ docker tag ubuntu localhost:5000/ubuntu $ docker push localhost:5000/ubuntu  更复杂的需求，harbor https://goharbor.io/\nOur mission is to be the trusted cloud native repository for Kubernetes","title":"Docker Private Registry"},{"content":"etcd 尝试 vagrant # -*- mode: ruby -*- # vi: set ft=ruby : servers = { :etcd1 =\u0026gt; '192.168.1.21', :etcd2 =\u0026gt; '192.168.1.22', :etcd3 =\u0026gt; '192.168.1.23' } Vagrant.configure(\u0026quot;2\u0026quot;) do |config| config.vm.box = \u0026quot;ubuntu/focal64\u0026quot; servers.each do |server_name, server_ip| config.vm.define server_name do |server_config| server_config.vm.hostname = \u0026quot;#{server_name.to_s}\u0026quot; server_config.vm.network :private_network, ip: server_ip server_config.vm.provider \u0026quot;virtualbox\u0026quot; do |vb| vb.name = server_name.to_s if vb.name == \u0026quot;etcd1\u0026quot; vb.memory = 1024 vb.cpus = 1 else vb.memory = 1024 vb.cpus = 1 end end end end end install install.sh\nETCD_VER=v3.4.9 # choose either URL GOOGLE_URL=https://storage.googleapis.com/etcd GITHUB_URL=https://github.com/etcd-io/etcd/releases/download DOWNLOAD_URL=${GOOGLE_URL} rm -f /tmp/etcd-${ETCD_VER}-linux-amd64.tar.gz rm -rf /tmp/etcd-download-test \u0026amp;\u0026amp; mkdir -p /tmp/etcd-download-test curl -L ${DOWNLOAD_URL}/${ETCD_VER}/etcd-${ETCD_VER}-linux-amd64.tar.gz -o /tmp/etcd-${ETCD_VER}-linux-amd64.tar.gz tar xzvf /tmp/etcd-${ETCD_VER}-linux-amd64.tar.gz -C /tmp/etcd-download-test --strip-components=1 rm -f /tmp/etcd-${ETCD_VER}-linux-amd64.tar.gz /tmp/etcd-download-test/etcd --version /tmp/etcd-download-test/etcdctl version cluster.sh\n infra0/1/2 192.168.1.21-23  /tmp/etcd-download-test/etcd --name infra1 --initial-advertise-peer-urls http://192.168.1.22:2380 \\  --listen-peer-urls http://192.168.1.22:2380 \\  --listen-client-urls http://192.168.1.22:2379,http://127.0.0.1:2379 \\  --advertise-client-urls http://192.168.1.22:2379 \\  --initial-cluster-token etcd-cluster-1 \\  --initial-cluster infra0=http://192.168.1.21:2380,infra1=http://192.168.1.22:2380,infra2=http://192.168.1.23:2380 \\  --initial-cluster-state new /tmp/etcd-download-test/etcdctl put mykey \u0026ldquo;this is awesome\u0026rdquo; /tmp/etcd-download-test/etcdctl get mykey\n","permalink":"http://localhost:8000/posts/etcd/readme/","summary":"etcd 尝试 vagrant # -*- mode: ruby -*- # vi: set ft=ruby : servers = { :etcd1 =\u0026gt; '192.168.1.21', :etcd2 =\u0026gt; '192.168.1.22', :etcd3 =\u0026gt; '192.168.1.23' } Vagrant.configure(\u0026quot;2\u0026quot;) do |config| config.vm.box = \u0026quot;ubuntu/focal64\u0026quot; servers.each do |server_name, server_ip| config.vm.define server_name do |server_config| server_config.vm.hostname = \u0026quot;#{server_name.to_s}\u0026quot; server_config.vm.network :private_network, ip: server_ip server_config.vm.provider \u0026quot;virtualbox\u0026quot; do |vb| vb.name = server_name.to_s if vb.name == \u0026quot;etcd1\u0026quot; vb.memory = 1024 vb.cpus = 1 else vb.memory = 1024 vb.cpus = 1 end end end end end install install.","title":"etcd 尝试"},{"content":"pip 离线安装 打包 注意，要在同平台打包，否则有些包不能正确安装。\n在已有的环境中，一般是一个虚拟环境：\n pip freeze \u0026gt; pip-requirements.txt pip download -d pip-packages -r pip-requirements.txt，将提取的包下载到pip-packages文件夹中  安装  将pip-requirements.txt和pip-packages文件夹，拷贝到目标环境的同目录下 pip install \u0026ndash;no-index \u0026ndash;find-links=pip-packages -r pip-requirements.txt  参考  断网环境下一键安装 python3 离线安装包及其依赖  ","permalink":"http://localhost:8000/posts/python/pip/%E6%89%93%E5%8C%85%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/","summary":"pip 离线安装 打包 注意，要在同平台打包，否则有些包不能正确安装。\n在已有的环境中，一般是一个虚拟环境：\n pip freeze \u0026gt; pip-requirements.txt pip download -d pip-packages -r pip-requirements.txt，将提取的包下载到pip-packages文件夹中  安装  将pip-requirements.txt和pip-packages文件夹，拷贝到目标环境的同目录下 pip install \u0026ndash;no-index \u0026ndash;find-links=pip-packages -r pip-requirements.txt  参考  断网环境下一键安装 python3 离线安装包及其依赖  ","title":"pip 离线安装"},{"content":"pipenv pip和virtualenv的组合，使用Pipfile来替换旧的requirements.txt方式。\n documentation zhihu 参考 segmentfault 参考  安装 安装到系统常用的python版本下，mac可以使用brew安装\n$ pip install pipenv  创建虚拟环境 $ pipenv install --three django  创建一个python3的虚拟环境并安装django，随机生成一个和当前文件夹名有关的虚拟环境。也可以用过--python 3.7指定python版本。\n TODO， 不能指定名称吗？  进入虚拟环境 $ pipenv shell  不过就算不进入环境，pipenv install依然可以正确安装包到对应的环境。\n新环境依赖 自动识别Pipfile，然后安装。\n$ pipenv install  一并安装开发环境的包：\n$ pipenv install --dev  区别开发环境 在安装包的时候添加一个--dev选项，会分类到开发依赖。\n更换源 更换Pipfile中的source-url\n[[source]] url = \u0026quot;https://mirrors.aliyun.com/pypi/simple\u0026quot; verify_ssl = true name = \u0026quot;pypi\u0026quot;  设置环境变量 PIPENV_PYPI_MIRROR 效果相同。类似指定\u0026ndash;pypi-mirror选项：\n$ pipenv install --pypi-mirror https://mirrors.aliyun.com/pypi/simple  查看安装的包 $ pipenv graph  不仅可以看到安装包，还可以看到依赖关系。\nDjango==2.1.7 - pytz [required: Any, installed: 2018.9] psutil==5.5.1  Pipfile  替换了源 有开发环境的包 dev-packages python 版本3.6  [[source]] name = \u0026quot;pypi\u0026quot; url = \u0026quot;https://mirrors.aliyun.com/pypi/simple\u0026quot; verify_ssl = true [dev-packages] pytest = \u0026quot;*\u0026quot; [packages] psutil = \u0026quot;*\u0026quot; django = \u0026quot;*\u0026quot; [requires] python_version = \u0026quot;3.6\u0026quot; ","permalink":"http://localhost:8000/posts/python/pip/pipenv/","summary":"pipenv pip和virtualenv的组合，使用Pipfile来替换旧的requirements.txt方式。\n documentation zhihu 参考 segmentfault 参考  安装 安装到系统常用的python版本下，mac可以使用brew安装\n$ pip install pipenv  创建虚拟环境 $ pipenv install --three django  创建一个python3的虚拟环境并安装django，随机生成一个和当前文件夹名有关的虚拟环境。也可以用过--python 3.7指定python版本。\n TODO， 不能指定名称吗？  进入虚拟环境 $ pipenv shell  不过就算不进入环境，pipenv install依然可以正确安装包到对应的环境。\n新环境依赖 自动识别Pipfile，然后安装。\n$ pipenv install  一并安装开发环境的包：\n$ pipenv install --dev  区别开发环境 在安装包的时候添加一个--dev选项，会分类到开发依赖。\n更换源 更换Pipfile中的source-url\n[[source]] url = \u0026quot;https://mirrors.aliyun.com/pypi/simple\u0026quot; verify_ssl = true name = \u0026quot;pypi\u0026quot;  设置环境变量 PIPENV_PYPI_MIRROR 效果相同。类似指定\u0026ndash;pypi-mirror选项：\n$ pipenv install --pypi-mirror https://mirrors.","title":"pipenv"},{"content":"PostgreSQL 分表 继承实现更灵活，可以直接在已有数据的表上实现，不用重新迁移。\n-- https://www.postgresql.org/docs/current/ddl-partitioning.html -- zh -- http://postgres.cn/docs/11/ddl-partitioning.html -- keyword: further redirect  -- 已有数据分表，因为主表不能有数据，所以需要先备份，创建分表和规则完毕后重新插入 -- 或者用新的表名，之后再分批读取插入  -- 创建主表 CREATE TABLE measurement ( city_id int not null, logdate date not null, peaktemp int, unitsales int ) PARTITION BY RANGE (logdate); -- 创建分表及规则 -- 还可以通过partition by 再次创建sub-partitioning，对插入measurement_y2006m02的数据再次重定向 -- CREATE TABLE measurement_y2006m02 PARTITION OF measurement -- FOR VALUES FROM (\u0026#39;2006-02-01\u0026#39;) TO (\u0026#39;2006-03-01\u0026#39;) -- PARTITION BY RANGE (peaktemp); CREATE TABLE measurement_y2006m02 PARTITION OF measurement FOR VALUES FROM (\u0026#39;2006-02-01\u0026#39;) TO (\u0026#39;2006-03-01\u0026#39;); CREATE TABLE measurement_y2006m03 PARTITION OF measurement FOR VALUES FROM (\u0026#39;2006-03-01\u0026#39;) TO (\u0026#39;2006-04-01\u0026#39;); -- 创建索引，自动再每个分区上创建索引 CREATE INDEX ON measurement (logdate); -- Ensure that the enable_partition_pruning configuration parameter is not disabled in postgresql.conf. If it is, queries will not be optimized as desired.  -- test INSERT INTO measurement (city_id, logdate, peaktemp, unitsales) VALUES (1, \u0026#39;2008-2-1\u0026#39;, 1, 1); INSERT INTO measurement (city_id, logdate, peaktemp, unitsales) VALUES (1, \u0026#39;2006-2-1\u0026#39;, 1, 1); ---- 维护 ----  -- 删除分表，可以快速删除百万数据，但是需要父表的 ACCESS EXCLUSIVE 锁 DROP TABLE measurement_y2006m02; -- 更好的处理方式，将分表从主表中分离，以单独的形式存在 -- This allows further operations to be performed on the data before it is dropped. For example, this is often a useful time to back up the data using COPY, pg_dump, or similar tools. It might also be a useful time to aggregate data into smaller formats, perform other data manipulations, or run reports. ALTER TABLE measurement DETACH PARTITION measurement_y2006m02; -- 在新的自盘空间申明，一般是用于把重要数据放在可靠快速磁盘，将日志型等数据放于普通磁盘 -- CREATE TABLE measurement_y2008m02 PARTITION OF measurement -- FOR VALUES FROM (\u0026#39;2008-02-01\u0026#39;) TO (\u0026#39;2008-03-01\u0026#39;) -- TABLESPACE fasttablespace;  -- 分区表有下列限制： -- -- 没有办法创建跨越所有分区的排除约束，只可能单个约束每个叶子分区。 -- -- 虽然在分区表上支持主键，但引用分区表的外键不受支持（但支持从分区表到某个其他表的外键引用）。 -- -- 当一个UPDATE导致一行从一个分区移动到另一个分区时，另一个并发的UPDATE或DELETE可能会产生一个串行化错误。假设会话1正在执行一个分区键上的UPDATE，同时一个并发的能看见这个行的会话2执行了对该行的UPDATE或者DELETE操作。在这种情况下，会话2的UPDATE或者DELETE会检测到行的移动，并抛出一个串行化的错误(将总是会返回一个SQLSTATE \u0026#39;40001\u0026#39;)。 如果发生这种情况，应用程序可能希望重试该事务。 在没有分区表或没有行移动的通常情况下， 会话2将识别新更新的行并在新行上执行UPDATE/DELETE。 -- -- 如果必要，必须在个体分区上定义BEFORE ROW触发器，分区表上不需要。 -- -- 不允许在同一个分区树中混杂临时关系和持久关系。因此，如果分区表是持久的，则其分区也必须是持久的，反之亦然。在使用临时关系时，分区数的所有成员都必须来自于同一个会话。  -- 使用继承实现  -- 虽然内建的声明式分区适合于大部分常见的用例，但还是有一些场景需要更加灵活的方法。分区可以使用表继承来实现，这能够带来一些声明式分区不支持的特性，例如： -- -- 对声明式分区来说，分区必须具有和分区表正好相同的列集合，而在表继承中，子表可以有父表中没有出现过的额外列。 -- -- 表继承允许多继承。 -- -- 声明式分区仅支持范围、列表以及哈希分区，而表继承允许数据按照用户的选择来划分（不过注意，如果约束排除不能有效地剪枝子表，查询性能可能会很差）。 -- -- 在使用声明式分区时，一些操作比使用表继承时要求更长的持锁时间。例如，向分区表中增加分区或者从分区表移除分区要求在父表上取得一个ACCESS EXCLUSIVE锁，而在常规继承的情况下一个SHARE UPDATE EXCLUSIVE锁就足够了。  --继承实现可以在已有数据中实现吗？ create table measurement3 ( id int not null, name char not null ); insert into measurement3 (id, name) values (1, \u0026#39;a\u0026#39;); insert into measurement3 (id, name) values (2, \u0026#39;b\u0026#39;); insert into measurement3 (id, name) values (3, \u0026#39;c\u0026#39;); insert into measurement3 (id, name) values (4, \u0026#39;d\u0026#39;); create table measurement3_y1 (check ( id \u0026gt;= 10 and id \u0026lt; 20 )) inherits (measurement3); create table measurement3_y2 (check ( id \u0026gt;= 20 and id \u0026lt; 30 )) inherits (measurement3); create function measurement_insert_trigger() returns trigger language plpgsql as $$ BEGIN IF (NEW.id \u0026gt;= 10 and NEW.id \u0026lt; 20) then INSERT INTO measurement3_y1 VALUES (NEW.*); ELSIF (NEW.id \u0026gt;= 20 and NEW.id \u0026lt; 30) then INSERT INTO measurement3_y2 VALUES (NEW.*); ELSE RAISE EXCEPTION \u0026#39;id out of range. Fix the measurement_insert_trigger function!\u0026#39;; END IF; RETURN NULL; END; $$; alter function measurement_insert_trigger() owner to develop; CREATE TRIGGER insert_measurement_trigger BEFORE INSERT ON measurement3 FOR EACH ROW EXECUTE FUNCTION measurement_insert_trigger(); insert into measurement3 (id, name) values (100, \u0026#39;d\u0026#39;); ","permalink":"http://localhost:8000/posts/postgresql/partition/","summary":"PostgreSQL 分表 继承实现更灵活，可以直接在已有数据的表上实现，不用重新迁移。\n-- https://www.postgresql.org/docs/current/ddl-partitioning.html -- zh -- http://postgres.cn/docs/11/ddl-partitioning.html -- keyword: further redirect  -- 已有数据分表，因为主表不能有数据，所以需要先备份，创建分表和规则完毕后重新插入 -- 或者用新的表名，之后再分批读取插入  -- 创建主表 CREATE TABLE measurement ( city_id int not null, logdate date not null, peaktemp int, unitsales int ) PARTITION BY RANGE (logdate); -- 创建分表及规则 -- 还可以通过partition by 再次创建sub-partitioning，对插入measurement_y2006m02的数据再次重定向 -- CREATE TABLE measurement_y2006m02 PARTITION OF measurement -- FOR VALUES FROM (\u0026#39;2006-02-01\u0026#39;) TO (\u0026#39;2006-03-01\u0026#39;) -- PARTITION BY RANGE (peaktemp); CREATE TABLE measurement_y2006m02 PARTITION OF measurement FOR VALUES FROM (\u0026#39;2006-02-01\u0026#39;) TO (\u0026#39;2006-03-01\u0026#39;); CREATE TABLE measurement_y2006m03 PARTITION OF measurement FOR VALUES FROM (\u0026#39;2006-03-01\u0026#39;) TO (\u0026#39;2006-04-01\u0026#39;); -- 创建索引，自动再每个分区上创建索引 CREATE INDEX ON measurement (logdate); -- Ensure that the enable_partition_pruning configuration parameter is not disabled in postgresql.","title":"PostgreSQL 分表"},{"content":"Teamcity 搭建CI/CD install server\nmkdir teamcity_server docker run -it --name teamcity-server-instance \\  -v /home/ubuntu/teamcity_server/datadir:/data/teamcity_server/datadir \\  -v /home/ubuntu/teamcity_server/logs:/opt/teamcity/logs \\  -p 8111:8111 \\  jetbrains/teamcity-server  agent, conf 有权限问题，最好在root运行 如果要使用docker-in-docker特性（sudo command not found），请使用linux-sudo tag的image  sudo docker run -it -e SERVER_URL=\u0026#34;http://10.200.160.4:8111\u0026#34; \\  -u 0 \\  -v docker_volumes:/var/lib/docker \\  -v /var/run/docker.sock:/var/run/docker.sock \\  -v /opt/buildagent/work:/opt/buildagent/work \\  -v /opt/buildagent/temp:/opt/buildagent/temp \\  -v /opt/buildagent/tools:/opt/buildagent/tools \\  -v /opt/buildagent/plugins:/opt/buildagent/plugins \\  -v /opt/buildagent/system:/opt/buildagent/system \\  --privileged -e DOCKER_IN_DOCKER=start \\  -v /home/ubuntu/teamcity_agent/conf:/data/teamcity_agent/conf \\  jetbrains/teamcity-agent register agent agent 安装好后，在server UI/Agents 中进行认证授权。待agent就绪后，可以添加需要的项目和操作等。\n项目 我使用的是gitlab，teamcity默认是支持的\n 右上角 Administration 在root project/connections 中添加 gitlab ce/ee，按照指示即可，会有个oauth认证的过程 之后就可以在root project 下创建项目的时候，就可以直接导入gitlab的项目了  Build  创建了项目后，在Build Configurations中创建新的configuration，这个配置可以包含多个steps 每个配置可以配置trigger和branch，还有参数 这里可以用配置隔离不同环境的测试，我这里只有一个单元测试的环境，branch是我自己仓库的dev，在Version Control Settings中设置，可以多个 Build Step，我选用的Command Line，在docker中运行  配置 docker settings python:3.7    echo \u0026#39;Webserver CI start ...\u0026#39; pip install --default-timeout=60 --no-cache-dir -r requirements/ci.txt -i https://mirrors.aliyun.com/pypi/simple/ \u0026amp;\u0026amp; \\ cp generalapps/settings/ci.py generalapps/settings/settings.py \u0026amp;\u0026amp; \\ python manage.py test --keepdb notification rules 可以配置 Email/Browser/IDE/Jabber/Slack\n 我使用Pycharm，在插件中安装teamcity插件，然后使用server url/username/password登录即可 在个人配置中选择关注的项目和事件 之后在ide中即可看到项目CI的动态  ","permalink":"http://localhost:8000/posts/teamcity/teamcity/","summary":"Teamcity 搭建CI/CD install server\nmkdir teamcity_server docker run -it --name teamcity-server-instance \\  -v /home/ubuntu/teamcity_server/datadir:/data/teamcity_server/datadir \\  -v /home/ubuntu/teamcity_server/logs:/opt/teamcity/logs \\  -p 8111:8111 \\  jetbrains/teamcity-server  agent, conf 有权限问题，最好在root运行 如果要使用docker-in-docker特性（sudo command not found），请使用linux-sudo tag的image  sudo docker run -it -e SERVER_URL=\u0026#34;http://10.200.160.4:8111\u0026#34; \\  -u 0 \\  -v docker_volumes:/var/lib/docker \\  -v /var/run/docker.sock:/var/run/docker.sock \\  -v /opt/buildagent/work:/opt/buildagent/work \\  -v /opt/buildagent/temp:/opt/buildagent/temp \\  -v /opt/buildagent/tools:/opt/buildagent/tools \\  -v /opt/buildagent/plugins:/opt/buildagent/plugins \\  -v /opt/buildagent/system:/opt/buildagent/system \\  --privileged -e DOCKER_IN_DOCKER=start \\  -v /home/ubuntu/teamcity_agent/conf:/data/teamcity_agent/conf \\  jetbrains/teamcity-agent register agent agent 安装好后，在server UI/Agents 中进行认证授权。待agent就绪后，可以添加需要的项目和操作等。","title":"TeamCity 搭建CI/CD"},{"content":"如何使用 Vagrant 快速搭建环境 加速 可以直接从国内镜像下载 box格式的文件，然后用 vagrant box add NAME URL添加\n# 自己下载 https://mirrors.tuna.tsinghua.edu.cn/ubuntu-cloud-images/focal/current/  制作自己的box 官方文档\n正常安装镜像，然后安装基础环境\n导出\nvagrant package --base ubuntu20.04 --output ./ubuntu2004.box  添加box\nvagrant box add ubuntu2004 .\\ubuntu2004.box  如果没有Vagrantfile，则初始化\nvagrant box add ubuntu2004 .\\ubuntu2004.box  启动\nvagrant up  VagrantFile # -*- mode: ruby -*- # vi: set ft=ruby : servers = { :k3s1 =\u0026gt; \u0026#39;192.168.1.21\u0026#39;, :k3s2 =\u0026gt; \u0026#39;192.168.1.22\u0026#39;, :k3s3 =\u0026gt; \u0026#39;192.168.1.23\u0026#39; } Vagrant.configure(\u0026#34;2\u0026#34;) do |config| # 可以指定自己导出的box config.vm.box = \u0026#34;ubuntu/focal64\u0026#34; servers.each do |server_name, server_ip| config.vm.define server_name do |server_config| server_config.vm.hostname = \u0026#34;#{server_name.to_s}\u0026#34; server_config.vm.network :private_network, ip: server_ip server_config.vm.provider \u0026#34;virtualbox\u0026#34; do |vb| vb.name = server_name.to_s vb.memory = 1024 vb.cpus = 1 end end end end ","permalink":"http://localhost:8000/posts/vagrant/vagrant/","summary":"如何使用 Vagrant 快速搭建环境 加速 可以直接从国内镜像下载 box格式的文件，然后用 vagrant box add NAME URL添加\n# 自己下载 https://mirrors.tuna.tsinghua.edu.cn/ubuntu-cloud-images/focal/current/  制作自己的box 官方文档\n正常安装镜像，然后安装基础环境\n导出\nvagrant package --base ubuntu20.04 --output ./ubuntu2004.box  添加box\nvagrant box add ubuntu2004 .\\ubuntu2004.box  如果没有Vagrantfile，则初始化\nvagrant box add ubuntu2004 .\\ubuntu2004.box  启动\nvagrant up  VagrantFile # -*- mode: ruby -*- # vi: set ft=ruby : servers = { :k3s1 =\u0026gt; \u0026#39;192.168.1.21\u0026#39;, :k3s2 =\u0026gt; \u0026#39;192.168.1.22\u0026#39;, :k3s3 =\u0026gt; \u0026#39;192.168.1.23\u0026#39; } Vagrant.configure(\u0026#34;2\u0026#34;) do |config| # 可以指定自己导出的box config.","title":"Vagrant"},{"content":"wheel 提供给系统组的wheel包构建，要求none-any\n以oss2包为例\npip download oss2 --platform=any --abi=none --no-deps 查看setup.py中的依赖，分别用上面的命令下载，获得所有的源码包。\n打包wheel，universal选项可以打包忽略平台和架构的包;如果包里面含有c extension是不支持universal的，必须是纯python实现\npython .\\setup.py bdist_wheel --universal 如果遇到打包错误 error: invalid command 'bdist_wheel'，可以修改setup.py使用setuptools的setup方法：\n# from distutils.core import setup from setuptools import setup ","permalink":"http://localhost:8000/posts/python/pip/wheel/","summary":"wheel 提供给系统组的wheel包构建，要求none-any\n以oss2包为例\npip download oss2 --platform=any --abi=none --no-deps 查看setup.py中的依赖，分别用上面的命令下载，获得所有的源码包。\n打包wheel，universal选项可以打包忽略平台和架构的包;如果包里面含有c extension是不支持universal的，必须是纯python实现\npython .\\setup.py bdist_wheel --universal 如果遇到打包错误 error: invalid command 'bdist_wheel'，可以修改setup.py使用setuptools的setup方法：\n# from distutils.core import setup from setuptools import setup ","title":"wheel"}]