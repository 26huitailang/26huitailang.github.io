[{"content":"开发编辑器/IDE vim vscode goland pycharm CI/CD gitlab CI/CD github actions teamcity 部署选择 docker supervisor pm2 systemd 网络工具 wireshark socat tcpdump Go Golang 开发环境准备和工具选择\n参考Alikhll/golang-developer-roadmap。\n更多关于golang的分享，参考Awesome-go\n包管理 加速/私有模块 组件 CLI工具开发 cobra Config viper Web Gin🍺 Echo🍺 Beego go-swagger Iris ORM Gorm🍺 Xorm DB PG🍺 Redis🍺 MongoDB Log Zap🍺 Logrus Websocket gorilla/websocket Task schedule Gron test testify convey, bdd python lint black isort darker ","permalink":"https://26huitailang.github.io/posts/devenv/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/","summary":"开发编辑器/IDE vim vscode goland pycharm CI/CD gitlab CI/CD github actions teamcity 部署选择 docker supervisor pm2 systemd 网络工具 wireshark socat tcpdump Go Golang 开发环境准备和工具选择\n参考Alikhll/golang-developer-roadmap。\n更多关于golang的分享，参考Awesome-go\n包管理 加速/私有模块 组件 CLI工具开发 cobra Config viper Web Gin🍺 Echo🍺 Beego go-swagger Iris ORM Gorm🍺 Xorm DB PG🍺 Redis🍺 MongoDB Log Zap🍺 Logrus Websocket gorilla/websocket Task schedule Gron test testify convey, bdd python lint black isort darker ","title":"开发环境"},{"content":"问题 在Centos上遇到sqlite3版本过低的问题, 3.7., 但是django要求版本不低于3.8., 自己编译升级后, 还是无法解决: 原因是python找寻动态库的位置不对\n# 下载并解压 [root@linux ~]# wget https://www.sqlite.org/2019/sqlite-autoconf-3270200.tar.gz [root@linux ~]# tar xf sqlite-autoconf-3270200.tar.gz # configure 生成makefile并指定安装路径 [root@linux ~]# cd sqlite-autoconf-3270200 [root@linux sqlite-autoconf-3270200]# ./configure --prefix=/usr/local/ [root@linux sqlite-autoconf-3270200]# make \u0026amp;\u0026amp; make install # 备份旧版本 [root@linux ~]# mv /usr/bin/sqlite3 /usr/bin/sqlite3_backupold # 链接新版本 [root@linux ~]# ln -s /usr/local/bin/sqlite3 /usr/bin/sqlite3 # 环境变量设置 [root@linux ~]# vim ~/.bashrc 添加内容如下, LD_LIBRARY_PATH 默认是没有设置的, 如果设置了会优先使用\nexport LD_LIBRARY_PATH=\u0026#34;/usr/local/lib\u0026#34; json1 参考：howto_get_going_with_sqlite_json1\n使用版本3.7.17，最低支持版本3.9.0\n尝试编译json.so 去3.7.17中.load json.so 结论：3.7.17 可以加载，但是运行报错segmentation fault，应该还是有代码不兼容，直接在3.9.0上可加载、可运行 下载：\nwget https://www.sqlite.org/2013/sqlite-autoconf-3071700.tar.gz # sqlite 中查看编译选项 ENABLE_JSON1 pragma compile_options; 使用Makefile生成json1.so，3.38代码已经移动到src/目录\n# Makefile json1.so: json1.lo $(LTCOMPILE) -c -fPIC $(TOP)/ext/misc/json1.c $(TCC) -shared -o json1.so json1.o $ make $ make json1.so python集成 sqlite-autoconf-3420000.tar.gz，默认支持json1 Python-2.7.5.tar.xz Python-3.8.6.tar.xz tar -xf sqlite3-autoconf-3420000.tar.gz tar -xf Python-2.7.5.tar.xz tar -xf Python-3.8.6.tar.xz cd sqlite3-autoconf-3420000 ./configure make make install sqlite3 -version # py2 sudo apt-get install build-essential libsqlite3-dev zlib1g-dev libncurses5-dev libgdbm-dev libbz2-dev libssl-dev libdb-dev ./configure --prefix=/usr --enable-shared --with-ensurepip=install --enable-optimizations make make install # py3 ./configure --prefix=/usr --enable-shared --enable-optimizations make make install sqlalchemy slqite json支持\nnew in version 1.3 pip install sqlalchemy\u0026gt;=1.3 demo\n-- test.sql CREATE table users(id int, data json); INSERT INTO users (id, data) VALUES (1, json(\u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;Alice\u0026#34;, \u0026#34;age\u0026#34;: 25, \u0026#34;email\u0026#34;: \u0026#34;alice@example.com\u0026#34;}\u0026#39;)); INSERT INTO users (id, data) VALUES (2, json(\u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;Bob\u0026#34;, \u0026#34;age\u0026#34;: 35, \u0026#34;email\u0026#34;: \u0026#34;bob@example.com\u0026#34;}\u0026#39;)); INSERT INTO users (id, data) VALUES (3, json(\u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;Chalice\u0026#34;, \u0026#34;age\u0026#34;: 17, \u0026#34;email\u0026#34;: \u0026#34;chalice@example.com\u0026#34;}\u0026#39;)); INSERT INTO users (id, data) VALUES (4, json(\u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;David\u0026#34;, \u0026#34;age\u0026#34;: 80, \u0026#34;email\u0026#34;: \u0026#34;david@example.com\u0026#34;}\u0026#39;)); 创建测试db\nsqlite3 testdb \u0026lt; test.sql import sqlite3 from sqlalchemy import JSON, Column, Integer, Sequence, create_engine from sqlalchemy.ext.declarative import declarative_base from sqlalchemy.orm import sessionmaker print(f\u0026#34;sqlite3.version {sqlite3.version}\u0026#34;) print(f\u0026#34;sqlite3.sqlite_version {sqlite3.sqlite_version}\u0026#34;) c = sqlite3.connect(\u0026#34;testdb\u0026#34;) cur = c.cursor() res = cur.execute( \u0026#34;select * from users, json_each(users.data) where json_each.key=\u0026#39;age\u0026#39; and json_each.value\u0026lt;30;\u0026#34; ) data = res.fetchall() print(\u0026#34;use json_each and raw query: \\n\u0026#34;) print(data) print(data[1], type(data[1])) print(\u0026#34;use sqlalchemy\u0026#34;) engine = create_engine(\u0026#34;sqlite:///testdb\u0026#34;, echo=True) EntityBase = declarative_base() class Item(EntityBase): __tablename__ = \u0026#34;users\u0026#34; id = Column(Integer, primary_key=True, nullable=False) data = Column(JSON, nullable=True) Session = sessionmaker(bind=engine) session = Session() for item in session.query(Item).all(): print(type(item.data)) print(item.id, item.data) (py3) 26huitailang in ~/PycharmProjects/sqlite3-json-demo λ python main.py sqlite3.version 2.6.0 sqlite3.sqlite_version 3.39.5 use json_each and raw query: [(1, \u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;Alice\u0026#34;,\u0026#34;age\u0026#34;:25,\u0026#34;email\u0026#34;:\u0026#34;alice@example.com\u0026#34;}\u0026#39;, \u0026#39;age\u0026#39;, 25, \u0026#39;integer\u0026#39;, 25, 4, None, \u0026#39;$.age\u0026#39;, \u0026#39;$\u0026#39;), (3, \u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;Chalice\u0026#34;,\u0026#34;age\u0026#34;:17,\u0026#34;email\u0026#34;:\u0026#34;chalice@example.com\u0026#34;}\u0026#39;, \u0026#39;age\u0026#39;, 17, \u0026#39;integer\u0026#39;, 17, 4, None, \u0026#39;$.age\u0026#39;, \u0026#39;$\u0026#39;)] (3, \u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;Chalice\u0026#34;,\u0026#34;age\u0026#34;:17,\u0026#34;email\u0026#34;:\u0026#34;chalice@example.com\u0026#34;}\u0026#39;, \u0026#39;age\u0026#39;, 17, \u0026#39;integer\u0026#39;, 17, 4, None, \u0026#39;$.age\u0026#39;, \u0026#39;$\u0026#39;) \u0026lt;class \u0026#39;tuple\u0026#39;\u0026gt; use sqlalchemy 2023-09-13 15:45:14,558 INFO sqlalchemy.engine.base.Engine SELECT CAST(\u0026#39;test plain returns\u0026#39; AS VARCHAR(60)) AS anon_1 2023-09-13 15:45:14,558 INFO sqlalchemy.engine.base.Engine () 2023-09-13 15:45:14,558 INFO sqlalchemy.engine.base.Engine SELECT CAST(\u0026#39;test unicode returns\u0026#39; AS VARCHAR(60)) AS anon_1 2023-09-13 15:45:14,558 INFO sqlalchemy.engine.base.Engine () 2023-09-13 15:45:14,559 INFO sqlalchemy.engine.base.Engine BEGIN (implicit) 2023-09-13 15:45:14,559 INFO sqlalchemy.engine.base.Engine SELECT users.id AS users_id, users.data AS users_data FROM users 2023-09-13 15:45:14,559 INFO sqlalchemy.engine.base.Engine () \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; 1 {\u0026#39;name\u0026#39;: \u0026#39;Alice\u0026#39;, \u0026#39;age\u0026#39;: 25, \u0026#39;email\u0026#39;: \u0026#39;alice@example.com\u0026#39;} \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; 2 {\u0026#39;name\u0026#39;: \u0026#39;Bob\u0026#39;, \u0026#39;age\u0026#39;: 35, \u0026#39;email\u0026#39;: \u0026#39;bob@example.com\u0026#39;} \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; 3 {\u0026#39;name\u0026#39;: \u0026#39;Chalice\u0026#39;, \u0026#39;age\u0026#39;: 17, \u0026#39;email\u0026#39;: \u0026#39;chalice@example.com\u0026#39;} \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; 4 {\u0026#39;name\u0026#39;: \u0026#39;David\u0026#39;, \u0026#39;age\u0026#39;: 80, \u0026#39;email\u0026#39;: \u0026#39;david@example.com\u0026#39;} ","permalink":"https://26huitailang.github.io/posts/database/sqlite/","summary":"问题 在Centos上遇到sqlite3版本过低的问题, 3.7., 但是django要求版本不低于3.8., 自己编译升级后, 还是无法解决: 原因是python找寻动态库的位置不对\n# 下载并解压 [root@linux ~]# wget https://www.sqlite.org/2019/sqlite-autoconf-3270200.tar.gz [root@linux ~]# tar xf sqlite-autoconf-3270200.tar.gz # configure 生成makefile并指定安装路径 [root@linux ~]# cd sqlite-autoconf-3270200 [root@linux sqlite-autoconf-3270200]# ./configure --prefix=/usr/local/ [root@linux sqlite-autoconf-3270200]# make \u0026amp;\u0026amp; make install # 备份旧版本 [root@linux ~]# mv /usr/bin/sqlite3 /usr/bin/sqlite3_backupold # 链接新版本 [root@linux ~]# ln -s /usr/local/bin/sqlite3 /usr/bin/sqlite3 # 环境变量设置 [root@linux ~]# vim ~/.bashrc 添加内容如下, LD_LIBRARY_PATH 默认是没有设置的, 如果设置了会优先使用\nexport LD_LIBRARY_PATH=\u0026#34;/usr/local/lib\u0026#34; json1 参考：howto_get_going_with_sqlite_json1\n使用版本3.7.17，最低支持版本3.9.0\n尝试编译json.so 去3.7.17中.load json.so 结论：3.7.17 可以加载，但是运行报错segmentation fault，应该还是有代码不兼容，直接在3.","title":"sqlite视图"},{"content":"Fabric学习 [toc]\n总结 fabric3 移除了很多实用的功能和装饰器，变得更精简了，另外fab这个cli入口提供的参数能力也变弱了，目前个人实用的方式是typer+fabric3+makefile：\ntyper 作为参数解析入口 makefile 固定一些操作逻辑，可以使用它的并发操作，而不是ThreadingGroup Link Welcome to Fabric! Welcome to Invoke’s documentation! 使用 Fabric 自动化部署 What is Fabric python的一个high level的库，通过ssh执行shell命令。\n基于以下两个包构建的：\nInvoke，subprocess command execution and command-line features Paramiko，SSH protocol implementation 私钥配置 配置ssh的authorized_keys，将本机的id_rsa.pub信息复制到远程的authorized_keys文件中 简要用法 pty(prompt by hand)，如果sudo有密码，那么用pty来手动输入 \u0026gt;\u0026gt;\u0026gt; from fabric import Connection \u0026gt;\u0026gt;\u0026gt; c = Connection(\u0026#39;192.168.9.139\u0026#39;) \u0026gt;\u0026gt;\u0026gt; c.run(\u0026#39;sudo useradd mydbuser\u0026#39;, pty=True) [sudo] password: \u0026lt;Result cmd=\u0026#39;sudo useradd mydbuser\u0026#39; exited=0\u0026gt; \u0026gt;\u0026gt;\u0026gt; c.run(\u0026#39;id -u mydbuser\u0026#39;) 利用Invoke的自动回应来输入sudo密码，注意pattern的正确匹配，以及repsonese的结尾符号 \u0026gt;\u0026gt;\u0026gt; from invoke import Responder \u0026gt;\u0026gt;\u0026gt; from fabric import Connection \u0026gt;\u0026gt;\u0026gt; c = Connection(\u0026#39;host\u0026#39;) \u0026gt;\u0026gt;\u0026gt; sudopass = Responder( ... pattern=r\u0026#39;\\[sudo\\] password:\u0026#39;, ... response=\u0026#39;mypassword\\n\u0026#39;, ... ) \u0026gt;\u0026gt;\u0026gt; c.run(\u0026#39;sudo whoami\u0026#39;, pty=True, watchers=[sudopass]) [sudo] password: root \u0026lt;Result cmd=\u0026#39;sudo whoami\u0026#39; exited=0\u0026gt; watchers虽然提供了自动填充密码的功能，但是代码中多次引用这种配置比较麻烦，所以考虑将sudopass的内容放入配置里面，让Connection.sudo来处理剩下的工作。 \u0026gt;\u0026gt;\u0026gt; import getpass \u0026gt;\u0026gt;\u0026gt; from fabric import Connection, Config \u0026gt;\u0026gt;\u0026gt; sudo_pass = getpass.getpass(\u0026#34;What\u0026#39;s your sudo password?\u0026#34;) What\u0026#39;s your sudo password? \u0026gt;\u0026gt;\u0026gt; config = Config(overrides={\u0026#39;sudo\u0026#39;: {\u0026#39;password\u0026#39;: sudo_pass}}) \u0026gt;\u0026gt;\u0026gt; c = Connection(\u0026#39;db1\u0026#39;, config=config) \u0026gt;\u0026gt;\u0026gt; c.sudo(\u0026#39;whoami\u0026#39;, hide=\u0026#39;stderr\u0026#39;) root \u0026lt;Result cmd=\u0026#34;...whoami\u0026#34; exited=0\u0026gt; \u0026gt;\u0026gt;\u0026gt; c.sudo(\u0026#39;useradd mydbuser\u0026#39;) \u0026lt;Result cmd=\u0026#34;...useradd mydbuser\u0026#34; exited=0\u0026gt; \u0026gt;\u0026gt;\u0026gt; c.run(\u0026#39;id -u mydbuser\u0026#39;) 1001 \u0026lt;Result cmd=\u0026#39;id -u mydbuser\u0026#39; exited=0\u0026gt; 文件传输，transfer files，利用Connection.put和Connection.get。在使用时发现如果像下面这样定义remote的话，会报错OSError，要带上远程的文件重命名就不会报错。 \u0026gt;\u0026gt;\u0026gt; from fabric import Connection \u0026gt;\u0026gt;\u0026gt; result = Connection(\u0026#39;web1\u0026#39;).put(\u0026#39;myfiles.tgz\u0026#39;, remote=\u0026#39;/opt/mydata/\u0026#39;) \u0026gt;\u0026gt;\u0026gt; print(\u0026#34;Uploaded {0.local} to {0.remote}\u0026#34;.format(result)) Uploaded /local/myfiles.tgz to /opt/mydata/ 之前都是单行的操作，实际多半不是这样，多个同时执行，如上传、解压，路径、文件名可以作为参数传入，以便复用函数 from fabric import Connection c = Connection(\u0026#39;web1\u0026#39;) c.put(\u0026#39;myfiles.tgz\u0026#39;, \u0026#39;/opt/mydata\u0026#39;) c.run(\u0026#39;tar -C /opt/mydata -xzvf /opt/mydata/myfiles.tgz\u0026#39;) def upload_and_unpack(c): c.put(\u0026#39;myfiles.tgz\u0026#39;, \u0026#39;/opt/mydata\u0026#39;) c.run(\u0026#39;tar -C /opt/mydata -xzvf /opt/mydata/myfiles.tgz\u0026#39;) 多服务器的情况，这个单列出来 最直观的方法是遍历一个connection列表 \u0026gt;\u0026gt;\u0026gt; from fabric import Connection \u0026gt;\u0026gt;\u0026gt; for host in (\u0026#39;web1\u0026#39;, \u0026#39;web2\u0026#39;, \u0026#39;mac1\u0026#39;): \u0026gt;\u0026gt;\u0026gt; result = Connection(host).run(\u0026#39;uname -s\u0026#39;) ... print(\u0026#34;{}: {}\u0026#34;.format(host, result.stdout.strip())) ... ... web1: Linux web2: Linux mac1: Darwin fabric提供了一个更好的解决办法，把所有的对象放到一个Group里面。 Group和SerialGroup(Subclass of Group which executes in simple, serial fashion. New in version 2.0.) 返回的结果看，Connection返回单个的Result对象，Group返回GroupResult对象，dict-like In [18]: results = Group(\u0026#39;peter@192.168.9.218\u0026#39;, \u0026#39;peter@192.168.9.208\u0026#39;).run(\u0026#39;uname -s\u0026#39;) Linux Linux In [19]: for conn, result in results.items(): ...: print(\u0026#34;{0.host}: {1.stdout}\u0026#34;.format(conn, result)) ...: 192.168.9.218: Linux 192.168.9.208: Linux Group对象来执行的操作会对所有服务器生效，但是这里官方教程的pool.put会得到一个AttributeError: 'SerialGroup' object has no attribute 'put'错误，已在github提交issue from fabric import SerialGroup as Group pool = Group(\u0026#39;web1\u0026#39;, \u0026#39;web2\u0026#39;, \u0026#39;web3\u0026#39;) pool.put(\u0026#39;myfiles.tgz\u0026#39;, \u0026#39;/opt/mydata\u0026#39;) pool.run(\u0026#39;tar -C /opt/mydata -xzvf /opt/mydata/myfiles.tgz\u0026#39;) fab cli tool 封装了Invoke的CLI功能，能够很快的在多个机器上运行tasks。\n将之前的任务编程一个fab task来运行，要定义一个fabfile.py 实际部署 这里参考的一篇博客，使用的是python2版本的fabric，仅供学习思路。\n流程 远程连接服务器。 进入项目根目录，从远程仓库拉取最新的代码。 如果项目引入了新的依赖，需要执行 pip install -r requirement.txt 安装最新依赖。 如果修改或新增了项目静态文件，需要执行 python manage.py collectstatic 收集静态文件。 如果数据库发生了变化，需要执行 python manage.py migrate 迁移数据库。 重启 Nginx 和 Gunicorn 使改动生效。 fabfile.py 位于项目(真正的代码项目，而非包含各种配置的部署项目)的根目录，\npython2 fabric mac路径问题 pip installation /usr/local/opt/python/bin/python2.7: bad interpreter: No such file or directory I got same problem. If I run brew link --overwrite python2. There was still zsh: /usr/local/bin//fab: bad interpreter: /usr/local/opt/python/bin/python2.7: no such file or directory.\n方案1 如果python本来指向了Celler的python3.6，那么先移除这个链接 然后在用过ln -s python2 python软连接 如果没有python2可以用brew reinstall python2，之后就能查看到 方案2 cd /usr/local/opt/ mv python2 python Solved it! Now we can use python2 version fabric.\n","permalink":"https://26huitailang.github.io/posts/devops/fabric/","summary":"Fabric学习 [toc]\n总结 fabric3 移除了很多实用的功能和装饰器，变得更精简了，另外fab这个cli入口提供的参数能力也变弱了，目前个人实用的方式是typer+fabric3+makefile：\ntyper 作为参数解析入口 makefile 固定一些操作逻辑，可以使用它的并发操作，而不是ThreadingGroup Link Welcome to Fabric! Welcome to Invoke’s documentation! 使用 Fabric 自动化部署 What is Fabric python的一个high level的库，通过ssh执行shell命令。\n基于以下两个包构建的：\nInvoke，subprocess command execution and command-line features Paramiko，SSH protocol implementation 私钥配置 配置ssh的authorized_keys，将本机的id_rsa.pub信息复制到远程的authorized_keys文件中 简要用法 pty(prompt by hand)，如果sudo有密码，那么用pty来手动输入 \u0026gt;\u0026gt;\u0026gt; from fabric import Connection \u0026gt;\u0026gt;\u0026gt; c = Connection(\u0026#39;192.168.9.139\u0026#39;) \u0026gt;\u0026gt;\u0026gt; c.run(\u0026#39;sudo useradd mydbuser\u0026#39;, pty=True) [sudo] password: \u0026lt;Result cmd=\u0026#39;sudo useradd mydbuser\u0026#39; exited=0\u0026gt; \u0026gt;\u0026gt;\u0026gt; c.run(\u0026#39;id -u mydbuser\u0026#39;) 利用Invoke的自动回应来输入sudo密码，注意pattern的正确匹配，以及repsonese的结尾符号 \u0026gt;\u0026gt;\u0026gt; from invoke import Responder \u0026gt;\u0026gt;\u0026gt; from fabric import Connection \u0026gt;\u0026gt;\u0026gt; c = Connection(\u0026#39;host\u0026#39;) \u0026gt;\u0026gt;\u0026gt; sudopass = Responder( .","title":"Fabric"},{"content":"查看依赖 工具 pipdeptree\n支持正向、反向查看依赖 多种格式输出，安装了graphviz还可以输出图形 [root@10-113-57-176 /] pip install pipdeptree [root@10-113-57-176 /] pipdeptree --help usage: pipdeptree [-h] [-v] [-f] [--python PYTHON] [-a] [-l] [-u] [-w [{silence,suppress,fail}]] [-r] [-p PACKAGES] [-e PACKAGES] [-j] [--json-tree] [--graph-output OUTPUT_FORMAT] Dependency tree of the installed python packages optional arguments: -h, --help show this help message and exit -v, --version show program\u0026#39;s version number and exit -f, --freeze Print names so as to write freeze files --python PYTHON Python to use to look for packages in it (default: where installed) -a, --all list all deps at top level -l, --local-only If in a virtualenv that has global access do not show globally installed packages -u, --user-only Only show installations in the user site dir -w [{silence,suppress,fail}], --warn [{silence,suppress,fail}] Warning control. \u0026#34;suppress\u0026#34; will show warnings but return 0 whether or not they are present. \u0026#34;silence\u0026#34; will not show warnings at all and always return 0. \u0026#34;fail\u0026#34; will show warnings and return 1 if any are present. The default is \u0026#34;suppress\u0026#34;. -r, --reverse Shows the dependency tree in the reverse fashion ie. the sub- dependencies are listed with the list of packages that need them under them. -p PACKAGES, --packages PACKAGES Comma separated list of select packages to show in the output. If set, --all will be ignored. -e PACKAGES, --exclude PACKAGES Comma separated list of select packages to exclude from the output. If set, --all will be ignored. -j, --json Display dependency tree as json. This will yield \u0026#34;raw\u0026#34; output that may be used by external tools. This option overrides all other options. --json-tree Display dependency tree as json which is nested the same way as the plain text output printed by default. This option overrides all other options (except --json). --graph-output OUTPUT_FORMAT Print a dependency graph in the specified output format. Available are all formats supported by GraphViz, e.g.: dot, jpeg, pdf, png, svg ","permalink":"https://26huitailang.github.io/posts/python/pip/dependency/","summary":"查看依赖 工具 pipdeptree\n支持正向、反向查看依赖 多种格式输出，安装了graphviz还可以输出图形 [root@10-113-57-176 /] pip install pipdeptree [root@10-113-57-176 /] pipdeptree --help usage: pipdeptree [-h] [-v] [-f] [--python PYTHON] [-a] [-l] [-u] [-w [{silence,suppress,fail}]] [-r] [-p PACKAGES] [-e PACKAGES] [-j] [--json-tree] [--graph-output OUTPUT_FORMAT] Dependency tree of the installed python packages optional arguments: -h, --help show this help message and exit -v, --version show program\u0026#39;s version number and exit -f, --freeze Print names so as to write freeze files --python PYTHON Python to use to look for packages in it (default: where installed) -a, --all list all deps at top level -l, --local-only If in a virtualenv that has global access do not show globally installed packages -u, --user-only Only show installations in the user site dir -w [{silence,suppress,fail}], --warn [{silence,suppress,fail}] Warning control.","title":"pip dependency"},{"content":"参考 https://www.cnblogs.com/zihanxing/articles/6224263.html\n验证 zdump -v /usr/share/zoneinfo/America/Los_Angeles ｜ grep 2022 ln -sf /usr/share/zoneinfo/America/Los_Angeles /etc/localtime service ntpd stop date -s \u0026#34;2022-03-13 01:59:40\u0026#34; for i in `seq 1 1000`;do date;python -c \u0026#39;import time;print(int(time.time()))\u0026#39;;python -c \u0026#39;import datetime;print(datetime.datetime.now())\u0026#39;;sleep 1;done ","permalink":"https://26huitailang.github.io/posts/linux/daylight/","summary":"参考 https://www.cnblogs.com/zihanxing/articles/6224263.html\n验证 zdump -v /usr/share/zoneinfo/America/Los_Angeles ｜ grep 2022 ln -sf /usr/share/zoneinfo/America/Los_Angeles /etc/localtime service ntpd stop date -s \u0026#34;2022-03-13 01:59:40\u0026#34; for i in `seq 1 1000`;do date;python -c \u0026#39;import time;print(int(time.time()))\u0026#39;;python -c \u0026#39;import datetime;print(datetime.datetime.now())\u0026#39;;sleep 1;done ","title":"Daylight Saving Time"},{"content":"工具 hercules go，维护良好，较为复杂，可以尝试\nhttps://github.com/src-d/hercules\ngitinspector Python 但是最后一次维护是Oct 19, 2020，不能在py3下运行，可以尝试\nhttps://github.com/ejwa/gitinspector\ngit-stats 合并程序是二进制，输出是js，不好改造\nhttps://github.com/IonicaBizau/git-stats\ngit-quick-stats written by shell(不太好改造)，持续有维护，可以尝试\nhttps://github.com/arzzen/git-quick-stats#macos-homebrew\nbrew install git-quick-stats\nYou can use the Docker image provided:\nBuild: docker build -t arzzen/git-quick-stats . Run interactive menu: docker run --rm -it -v $(pwd):/git arzzen/git-quick-stats Docker pull command: docker pull arzzen/git-quick-stats docker repository docker run --rm -it -e _GIT_SINCE=\u0026#34;2017-01-20\u0026#34; -v $(pwd):/git arzzen/git-quick-stats -j 统计 代码量 git log \u0026ndash;format=\u0026rsquo;%aN\u0026rsquo; | sort -u | while read name; do echo -en \u0026ldquo;$name\\t\u0026rdquo;; git log \u0026ndash;author=\u0026quot;$name\u0026quot; \u0026ndash;pretty=tformat: \u0026ndash;since=2020-02-03 \u0026ndash;until=2020-03-27 \u0026ndash;numstat | awk \u0026lsquo;{ add += $1; subs += $2; loc += $1 - $2 } END { printf \u0026ldquo;added lines: %s, removed lines: %s, total lines: %s\\n\u0026rdquo;, add, subs, loc }\u0026rsquo; -; done\n","permalink":"https://26huitailang.github.io/posts/git/statistics/","summary":"工具 hercules go，维护良好，较为复杂，可以尝试\nhttps://github.com/src-d/hercules\ngitinspector Python 但是最后一次维护是Oct 19, 2020，不能在py3下运行，可以尝试\nhttps://github.com/ejwa/gitinspector\ngit-stats 合并程序是二进制，输出是js，不好改造\nhttps://github.com/IonicaBizau/git-stats\ngit-quick-stats written by shell(不太好改造)，持续有维护，可以尝试\nhttps://github.com/arzzen/git-quick-stats#macos-homebrew\nbrew install git-quick-stats\nYou can use the Docker image provided:\nBuild: docker build -t arzzen/git-quick-stats . Run interactive menu: docker run --rm -it -v $(pwd):/git arzzen/git-quick-stats Docker pull command: docker pull arzzen/git-quick-stats docker repository docker run --rm -it -e _GIT_SINCE=\u0026#34;2017-01-20\u0026#34; -v $(pwd):/git arzzen/git-quick-stats -j 统计 代码量 git log \u0026ndash;format=\u0026rsquo;%aN\u0026rsquo; | sort -u | while read name; do echo -en \u0026ldquo;$name\\t\u0026rdquo;; git log \u0026ndash;author=\u0026quot;$name\u0026quot; \u0026ndash;pretty=tformat: \u0026ndash;since=2020-02-03 \u0026ndash;until=2020-03-27 \u0026ndash;numstat | awk \u0026lsquo;{ add += $1; subs += $2; loc += $1 - $2 } END { printf \u0026ldquo;added lines: %s, removed lines: %s, total lines: %s\\n\u0026rdquo;, add, subs, loc }\u0026rsquo; -; done","title":"Git Statistics"},{"content":"man page https://man7.org/linux/man-pages/man3/syslog.3.html\ninstall yum install rsyslog systemctl start rsyslog systemctl enable rsyslog systemctl status rsyslog config server\n# for udp #module(load=”imudp”) #input(type=”imudp” port=”514\u0026#34;) # for tcp #module(load=”imtcp”) #input(type=”imtcp” port=”514\u0026#34;) facility: the type of process sending logs, can be kernel, cron, daemon, etc. priority: the security level or type of log, emerg (0), alert (1), crit (2), err-(3), warn (4), notice (5), info (6), debug (7). destination: location to save log messages, local file host (/var/log directory), or remote syslog server identified by @ IP:port. e.g. server with udp opened, for local7.* facility msg:\n... module(load=”imudp”) input(type=”imudp” port=”514\u0026#34;) ... local7.* /var/log/local7 client\n... local7.* @SERVER_IP:514 test\nlogger content ","permalink":"https://26huitailang.github.io/posts/linux/rsyslog/","summary":"man page https://man7.org/linux/man-pages/man3/syslog.3.html\ninstall yum install rsyslog systemctl start rsyslog systemctl enable rsyslog systemctl status rsyslog config server\n# for udp #module(load=”imudp”) #input(type=”imudp” port=”514\u0026#34;) # for tcp #module(load=”imtcp”) #input(type=”imtcp” port=”514\u0026#34;) facility: the type of process sending logs, can be kernel, cron, daemon, etc. priority: the security level or type of log, emerg (0), alert (1), crit (2), err-(3), warn (4), notice (5), info (6), debug (7). destination: location to save log messages, local file host (/var/log directory), or remote syslog server identified by @ IP:port.","title":"rsyslog"},{"content":"msgfmt -c zh_HK.po -o zh_HK.mo ","permalink":"https://26huitailang.github.io/posts/i18n/i18n/","summary":"msgfmt -c zh_HK.po -o zh_HK.mo ","title":"i18n"},{"content":"brew install tesseract pngpaste brew install tesseract-lang # 语言支持 ctrl + shift + command + 4 截图\npngpaste - | tesseract -l chi_sim stdin stdout 加入zsh alias,.zshrc\nalias ocr=\u0026#39;pngpaste - | tesseract -l chi_sim stdin stdout\u0026#39; ","permalink":"https://26huitailang.github.io/posts/tools/ocr/","summary":"brew install tesseract pngpaste brew install tesseract-lang # 语言支持 ctrl + shift + command + 4 截图\npngpaste - | tesseract -l chi_sim stdin stdout 加入zsh alias,.zshrc\nalias ocr=\u0026#39;pngpaste - | tesseract -l chi_sim stdin stdout\u0026#39; ","title":"OCR"},{"content":"socks5 # 监听1080为代理地址 ssh -f -N -D 0.0.0.0:1080 root@127.0.0.1 # test curl -v -k -x \u0026#34;socks5://USER:PASSWORD@HOSTIP:1080\u0026#34; https://baidu.com socat # forward 访问目标服务 socat TCP4-LISTEN:\u0026lt;本地端口\u0026gt;,bind=\u0026lt;监听本机的地址\u0026gt;,reuseaddr,fork TCP:\u0026lt;目标地址\u0026gt;:\u0026lt;目标端口\u0026gt; 3proxy 三方容器： 3128 http, 1080 socks5\n$ docker run --rm -d \\ -p \u0026#34;3128:3128/tcp\u0026#34; \\ -p \u0026#34;1080:1080/tcp\u0026#34; \\ tarampampam/3proxy:latest ","permalink":"https://26huitailang.github.io/posts/test/proxy-test/","summary":"socks5 # 监听1080为代理地址 ssh -f -N -D 0.0.0.0:1080 root@127.0.0.1 # test curl -v -k -x \u0026#34;socks5://USER:PASSWORD@HOSTIP:1080\u0026#34; https://baidu.com socat # forward 访问目标服务 socat TCP4-LISTEN:\u0026lt;本地端口\u0026gt;,bind=\u0026lt;监听本机的地址\u0026gt;,reuseaddr,fork TCP:\u0026lt;目标地址\u0026gt;:\u0026lt;目标端口\u0026gt; 3proxy 三方容器： 3128 http, 1080 socks5\n$ docker run --rm -d \\ -p \u0026#34;3128:3128/tcp\u0026#34; \\ -p \u0026#34;1080:1080/tcp\u0026#34; \\ tarampampam/3proxy:latest ","title":"Proxy Test"},{"content":"image docker pull mcr.microsoft.com/playwright/python:v1.20.0-focal\n本地环境 pip install playwright -i https://pypi.tuna.tsinghua.edu.cn/simple playwright install\n","permalink":"https://26huitailang.github.io/posts/test/playwright/","summary":"image docker pull mcr.microsoft.com/playwright/python:v1.20.0-focal\n本地环境 pip install playwright -i https://pypi.tuna.tsinghua.edu.cn/simple playwright install","title":"Playwright"},{"content":"访问宿主机网络 host mode 使用host模式：\ndocker run -d --network=host my-container:latest services: my-service: network_mode: host 添加hosts 使用--add-host选项添加映射到/etc/hosts文件，添加host.docker.internal到hosts\ndocker run --rm -it --add-host host.docker.internal:host-gateway goexpect bash hosts in container\nroot@00e0febe04e2:/app# cat /etc/hosts 127.0.0.1 localhost ::1 localhost ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters 192.168.65.2 host.docker.internal 172.17.0.2 00e0febe04e2 访问宿主机网络\nssh root@host.docker.internal -p 2222 ","permalink":"https://26huitailang.github.io/posts/docker/docker-network/","summary":"访问宿主机网络 host mode 使用host模式：\ndocker run -d --network=host my-container:latest services: my-service: network_mode: host 添加hosts 使用--add-host选项添加映射到/etc/hosts文件，添加host.docker.internal到hosts\ndocker run --rm -it --add-host host.docker.internal:host-gateway goexpect bash hosts in container\nroot@00e0febe04e2:/app# cat /etc/hosts 127.0.0.1 localhost ::1 localhost ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters 192.168.65.2 host.docker.internal 172.17.0.2 00e0febe04e2 访问宿主机网络\nssh root@host.docker.internal -p 2222 ","title":"Docker Network"},{"content":" 了解 vim text object概念 installation brew install neovim brew install font-hack-nerd-font # 检索 brew install ripgrep fzf # lsp format brew install efm-langserver lazy-nvim tokyonight lualine barbecue bufferline indent_blankline gitsigns.nvim alpha-nvim nvim-telescope https://github.com/nvim-treesitter/nvim-treesitter https://github.com/nvim-treesitter/nvim-treesitter-textobjects https://github.com/neovim/nvim-lspconfig https://github.com/williamboman/mason.nvim https://github.com/hrsh7th/nvim-cmp lsp-format 参考 lazyvim kickstart nvim 整理中 my lazyvim config\nplugin use https://github.com/junegunn/vim-plug, install this first：\nsh -c \u0026#39;curl -fLo \u0026#34;${XDG_DATA_HOME:-$HOME/.local/share}\u0026#34;/nvim/site/autoload/plug.vim --create-dirs \\ https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim\u0026#39; mkdir ~/.config/nvim/ nvim ~/.config/nvim/init.vim cat \u0026lt;\u0026lt; EOF \u0026gt; ~/.config/nvim/init.vim call plug#begin(\u0026#39;~/.vim/plugged\u0026#39;) call plug#end() EOF write Plug 'fatih/vim-go' between call run :PlugInstall vim config is .vimrc language support use coc.nvim\nPlug \u0026#39;neoclide/coc.nvim\u0026#39;, {\u0026#39;branch\u0026#39;: \u0026#39;release\u0026#39;} :PlugInstall coc-settings.json\n{ \u0026#34;languageserver\u0026#34;: { \u0026#34;go\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;gopls\u0026#34;, \u0026#34;rootPatterns\u0026#34;: [\u0026#34;go.mod\u0026#34;], \u0026#34;trace.server\u0026#34;: \u0026#34;verbose\u0026#34;, \u0026#34;filetypes\u0026#34;: [\u0026#34;go\u0026#34;] } } } problem:\nbuild/index.js not found, please install dependencies and compile coc.nvim by: yarn install\ncd ~/.vim/plugged/coc.nvim yarn install yarn build ctags plugin: \u0026lsquo;preservim/tagbar\u0026rsquo; need ctags installation\nbrew install universal-ctags config init.vim\nnmap \u0026lt;F8\u0026gt; :TagbarToggle\u0026lt;CR\u0026gt; python 使用 python language server，neovim内置支持\npip install \u0026#39;python-language-server[all]\u0026#39; config coc-settings.json，设置为全局安装python-language-server的python路径\n输入法切换问题 参考 https://github.com/laishulu/macism/issues/4\nim-select brew tap daipeihust/tap brew install im-select 设置离开insert模式的配置 autocmd InsertLeave * :silent !/usr/local/bin/im-select com.apple.keylayout.ABC -- imselect.lua --- 都是粉色的手动发送地方定义一个函数来切换输入法 local M = {} function M.setInputMethod() vim.fn.system(\u0026#39;/usr/local/bin/im-select com.apple.keylayout.ABC\u0026#39;) end return M --essentials.lua -- 在退出插入模式时触发 setInputMethod 函数 local imselect = require(\u0026#39;imselect\u0026#39;) vim.cmd([[ augroup SetInputMethod autocmd! autocmd InsertLeave * lua require(\u0026#39;imselect\u0026#39;).setInputMethod() augroup END ]]) ","permalink":"https://26huitailang.github.io/posts/tools/neovim/","summary":"了解 vim text object概念 installation brew install neovim brew install font-hack-nerd-font # 检索 brew install ripgrep fzf # lsp format brew install efm-langserver lazy-nvim tokyonight lualine barbecue bufferline indent_blankline gitsigns.nvim alpha-nvim nvim-telescope https://github.com/nvim-treesitter/nvim-treesitter https://github.com/nvim-treesitter/nvim-treesitter-textobjects https://github.com/neovim/nvim-lspconfig https://github.com/williamboman/mason.nvim https://github.com/hrsh7th/nvim-cmp lsp-format 参考 lazyvim kickstart nvim 整理中 my lazyvim config\nplugin use https://github.com/junegunn/vim-plug, install this first：\nsh -c \u0026#39;curl -fLo \u0026#34;${XDG_DATA_HOME:-$HOME/.local/share}\u0026#34;/nvim/site/autoload/plug.vim --create-dirs \\ https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim\u0026#39; mkdir ~/.config/nvim/ nvim ~/.config/nvim/init.vim cat \u0026lt;\u0026lt; EOF \u0026gt; ~/.config/nvim/init.vim call plug#begin(\u0026#39;~/.","title":"Neovim"},{"content":"复制内容到剪贴板 +可以把内容复制到剪贴板寄存器，就能在其他应用中贴。 :reg [register_name] 查看指定寄存器的内容 \u0026#34;+yy // 复制当前行到剪切板 \u0026#34;+p // 将剪切板内容粘贴到光标后面 \u0026#34;ayy // 复制当前行到寄存器 a \u0026#34;ap // 将寄存器 a 中的内容粘贴到光标后面 Vim 有 12 个粘贴板依次编号为：0、1、2、\u0026hellip;、9、a、\u0026quot;、+，其中 + 号为系统粘贴板，” 为临时粘贴板。系统剪切板中的内容可在其他程序中使用。上面的复制指令都可以配合剪切板进行操作。\u0026ldquo;nyw 复制当前单词到 n 号剪切板（双引号开始） \u0026ldquo;np 粘贴 n 号剪切板内容到当前位置后 \u0026ldquo;+Y 复制当前行到系统剪切板\u0026rdquo;+nY 复制当前行往下 n 行到系统剪切板\u0026rdquo;+p 粘贴系统剪切板内容到当前位置后\n标记，mark 一下 mc标记一个位置c，当在本页其他地方完成代码之后，有时因为不是用的 vim 的G或g位移操作，所以两个点号不一定能回来，但是如果在离开前就 mark 了它，`c 一下就能会到 c 标记的地方，这里用其他字母也行，只要自己能记住，我从别的地方学的是 e - end，c - current，s - start，比如代码开头的 import 内容或者常量不对调整，则标记一个 s，当前的代码工作地方标记为 c，这样可以在开头和当前不断跳转。\nreplace Search and replace :%s/foo/bar/g, Find each occurrence of \u0026lsquo;foo\u0026rsquo; (in all lines), and replace it with \u0026lsquo;bar\u0026rsquo;. 插件 Youcompleteme 文章\n通过 vundle 添加插件\ncall vundle#begin() . . . Plugin \u0026lsquo;Valloric/YouCompleteMe ’ . . . call vundle#end()\nvim 里面通过:PluginInstall安装\n如果不是自己想要的依赖，可以自己编译，最近在看 c，所以就试着配置了一下：\ncd ~/.vim/bundle/YouCompleteMe/ ./install.py --clang-completer --go-completer，包含 c family 这里可能会报 python 路径不对，注意.zshrc 或.bashrc 的路径配置，会影响，最好用系统自带的，是含有 lib 动态文件的 .vimrc 配置 let g:ycm_server_python_interpreter=\u0026lsquo;python\u0026rsquo; # 不指定绝对路径，用了 virtualenv 插件，可以自己识别当前的 venv python(Plugin \u0026lsquo;plytophogy/vim-virtualenv\u0026rsquo;) let g:ycm_global_ycm_extra_conf=\u0026rsquo;~/.vim/.ycm_extra_conf.py\u0026rsquo;，ycm 的配置文件，默认是没有的，cp ~/.vim/bundle/YouCompleteMe/third_party/ycmd/examples/.ycm_extra_conf.py ~/.vim/ mac 下的 vim配置 VIM 配置 说明 vim 神器不必多说，关于它的讨论以及最好编辑器的争论从未停息. 争议的东西就不多说了，主要是自己使用vim的一些个设置和配置，基本原则是尽量少用插件安装，安装插件具有简单复制性，online特性。（ps:以后写个一键安装脚本，原谅我是一个比较懒的coder） 上面说了那么多是不是四个字母就可以了 \u0026ndash;\u0026gt; kiss\n基础配置 基础平台：MacBook Air ，出去装逼的时候用，电池牛逼，不插电coding也有安全感，原生shell支持，全屏terminal ，再开个markdown，逼哥咱逼哥。 mac 自带的是vi，需要安装vim，对Gvim和MACvim都无爱,homebrew 安装so ez:brew install vim 配置文件在用户目录下~/.vimrc ,如果没有，就自己创建一个。\n\u0026#34; 显示行号 set number \u0026#34; 显示标尺 set ruler \u0026#34; 历史纪录 set history=1000 \u0026#34; 输入的命令显示出来，看的清楚些 set showcmd \u0026#34; 状态行显示的内容 set statusline=%F%m%r%h%w\\ [FORMAT=%{\u0026amp;ff}]\\ [TYPE=%Y]\\ [POS=%l,%v][%p%%]\\ %{strftime(\\\u0026#34;%d/%m/%y\\ -\\ %H:%M\\\u0026#34;)} \u0026#34; 启动显示状态行1，总是显示状态行2 set laststatus=2 \u0026#34; 语法高亮显示 syntax on set fileencodings=utf-8,gb2312,gbk,cp936,latin-1 set fileencoding=utf-8 set termencoding=utf-8 set fileformat=unix set encoding=utf-8 \u0026#34; 配色方案 colorscheme desert \u0026#34; 指定配色方案是256色 set t_Co=256 set wildmenu \u0026#34; 去掉有关vi一致性模式，避免以前版本的一些bug和局限，解决backspace不能使用的问题 set nocompatible set backspace=indent,eol,start set backspace=2 \u0026#34; 启用自动对齐功能，把上一行的对齐格式应用到下一行 set autoindent \u0026#34; 依据上面的格式，智能的选择对齐方式，对于类似C语言编写很有用处 set smartindent \u0026#34; vim禁用自动备份 set nobackup set nowritebackup set noswapfile \u0026#34; 用空格代替tab set expandtab \u0026#34; 设置显示制表符的空格字符个数,改进tab缩进值，默认为8，现改为4 set tabstop=4 \u0026#34; 统一缩进为4，方便在开启了et后使用退格(backspace)键，每次退格将删除X个空格 set softtabstop=4 \u0026#34; 设定自动缩进为4个字符，程序中自动缩进所使用的空白长度 set shiftwidth=4 \u0026#34; 设置帮助文件为中文(需要安装vimcdoc文档) set helplang=cn \u0026#34; 显示匹配的括号 set showmatch \u0026#34; 文件缩进及tab个数 au FileType html,python,vim,javascript setl shiftwidth=4 au FileType html,python,vim,javascript setl tabstop=4 au FileType java,php setl shiftwidth=4 au FileType java,php setl tabstop=4 \u0026#34; 高亮搜索的字符串 set hlsearch \u0026#34; 检测文件的类型 filetype on filetype plugin on filetype indent on \u0026#34; C风格缩进 set cindent set completeopt=longest,menu \u0026#34; 功能设置 \u0026#34; 去掉输入错误提示声音 set noeb \u0026#34; 自动保存 set autowrite \u0026#34; 突出显示当前行 set cursorline \u0026#34; 突出显示当前列 set cursorcolumn \u0026#34;设置光标样式为竖线vertical bar \u0026#34; Change cursor shape between insert and normal mode in iTerm2.app \u0026#34;if $TERM_PROGRAM =~ \u0026#34;iTerm\u0026#34; let \u0026amp;t_SI = \u0026#34;\\\u0026lt;Esc\u0026gt;]50;CursorShape=1\\x7\u0026#34; \u0026#34; Vertical bar in insert mode let \u0026amp;t_EI = \u0026#34;\\\u0026lt;Esc\u0026gt;]50;CursorShape=0\\x7\u0026#34; \u0026#34; Block in normal mode \u0026#34;endif \u0026#34; 共享剪贴板 set clipboard+=unnamed \u0026#34; 文件被改动时自动载入 set autoread \u0026#34; 顶部底部保持3行距离 set scrolloff=3 插件安装和配置 首先安装插件管家 Vundle:\ngit clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim .vimrc 中添加配置使管家上任：\nfiletype off set rtp+=~/.vim/bundle/Vundle.vim call vundle#begin() Plugin \u0026#39;VundleVim/Vundle.vim\u0026#39; Plugin \u0026#39;你的插件\u0026#39; call vundle#end() filetype plugin indent on 使用vundle安装插件:\n\u0026#34; let Vundle manage Vundle, required Plugin \u0026#39;VundleVim/Vundle.vim\u0026#39; \u0026#34; Plugin \u0026#39;tpope/vim-surround\u0026#39; \u0026#34; Plugin \u0026#39;scrooloose/nerdtree\u0026#39; Plugin \u0026#39;Lokaltog/vim-powerline\u0026#39; Plugin \u0026#39;valloric/youcompleteme\u0026#39; Plugin \u0026#39;yggdroot/indentline\u0026#39; Plugin \u0026#39;jiangmiao/auto-pairs\u0026#39; 插件相关配置：\n\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;plugin configuration\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34; \u0026#34;NERDTree \u0026#34;F2开启和关闭树\u0026#34; \u0026#34;map \u0026lt;F2\u0026gt; :NERDTreeToggle\u0026lt;CR\u0026gt; \u0026#34;let NERDTreeChDirMode=1 \u0026#34;\u0026#34;显示书签\u0026#34; \u0026#34;let NERDTreeShowBookmarks=1 \u0026#34;设置忽略文件类型\u0026#34; \u0026#34;let NERDTreeIgnore=[\u0026#39;\\~$\u0026#39;, \u0026#39;\\.pyc$\u0026#39;, \u0026#39;\\.swp$\u0026#39;] \u0026#34;\u0026#34;窗口大小\u0026#34; \u0026#34;let NERDTreeWinSize=25 \u0026#34;indentLine \u0026#34;缩进指示线\u0026#34; let g:indentLine_char=\u0026#39;|\u0026#39; let g:indentLine_enabled=1 OK ，everything\u0026rsquo;s ready 打开vim哈皮的coding吧。\n","permalink":"https://26huitailang.github.io/posts/tools/vim/","summary":"复制内容到剪贴板 +可以把内容复制到剪贴板寄存器，就能在其他应用中贴。 :reg [register_name] 查看指定寄存器的内容 \u0026#34;+yy // 复制当前行到剪切板 \u0026#34;+p // 将剪切板内容粘贴到光标后面 \u0026#34;ayy // 复制当前行到寄存器 a \u0026#34;ap // 将寄存器 a 中的内容粘贴到光标后面 Vim 有 12 个粘贴板依次编号为：0、1、2、\u0026hellip;、9、a、\u0026quot;、+，其中 + 号为系统粘贴板，” 为临时粘贴板。系统剪切板中的内容可在其他程序中使用。上面的复制指令都可以配合剪切板进行操作。\u0026ldquo;nyw 复制当前单词到 n 号剪切板（双引号开始） \u0026ldquo;np 粘贴 n 号剪切板内容到当前位置后 \u0026ldquo;+Y 复制当前行到系统剪切板\u0026rdquo;+nY 复制当前行往下 n 行到系统剪切板\u0026rdquo;+p 粘贴系统剪切板内容到当前位置后\n标记，mark 一下 mc标记一个位置c，当在本页其他地方完成代码之后，有时因为不是用的 vim 的G或g位移操作，所以两个点号不一定能回来，但是如果在离开前就 mark 了它，`c 一下就能会到 c 标记的地方，这里用其他字母也行，只要自己能记住，我从别的地方学的是 e - end，c - current，s - start，比如代码开头的 import 内容或者常量不对调整，则标记一个 s，当前的代码工作地方标记为 c，这样可以在开头和当前不断跳转。\nreplace Search and replace :%s/foo/bar/g, Find each occurrence of \u0026lsquo;foo\u0026rsquo; (in all lines), and replace it with \u0026lsquo;bar\u0026rsquo;.","title":"Vim"},{"content":"开发安全的 API 所需要核对的清单\nhttps://github.com/shieldfy/API-Security-Checklist\nhttps://github.com/shieldfy/API-Security-Checklist/blob/master/README-zh.md\n","permalink":"https://26huitailang.github.io/posts/security/api-security-checklist/","summary":"开发安全的 API 所需要核对的清单\nhttps://github.com/shieldfy/API-Security-Checklist\nhttps://github.com/shieldfy/API-Security-Checklist/blob/master/README-zh.md","title":"api security checklist"},{"content":"docker cheatsheet docker\n# 不使用缓存重新build docker build . --no-cache # tag docker build -t peterchen0802/mypandoc:latest . docker tag peterchen0802/mypandoc:latest mypandoc:latest # 查看容器日志 docker logs SERVICE_NAME [-f] # 导出容器 # 注：用户既可以使用 docker load 来导入镜像存储文件到本地镜像库，也可以使用 docker import 来导入一个容器快照到本地镜像库。这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也要大。此外，从容器快照文件导入时可以重新指定标签等元数据信息。 docker export CONTAINER \u0026gt; TARFILENAME docker export CONTAINER -o TARFILENAME # 导入容器 docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]] docker import mypandoc.tar peterchen0802/mypandoc:latest # 指定导入的镜像名称 # -----清理 start----- ## 磁盘容量查看 docker system df ## 清理 docker rmi $(docker images --filter \u0026#34;dangling=true\u0026#34; -q) ## 清理无标签的镜像 docker image prune ## 清理磁盘，删除关闭的容器、无用的数据卷、网络，以及dangling镜像（无tag的镜像）。 docker system prune ## 更彻底的删除，将没有容器使用的镜像删除： docker system prune -a # -----清理 end----- docker-compose\n# 指定启动配置文件，可以用docker-compose.dev.yml 区别开发和生产配置 docker-compose -f YML up # 强制重新build, --build docker-compose -f YML up --build # 扩容，如果要临时增加，可以使用`--scale`参数配合`up`指令，接受多个容器传递： docker-compose up --scale web=2 celery-worker=3 zsh zsh插件支持docker和docker-compose\nDockfile 用于构建image的文件。\ndocker-compose.yml 管理和使用docker服务的工具，可以类似vagrant的配置，可以很快的编排需要的services以及networks并启动。\ndocker-compose -f YML-CONF-FILE up，可以指定配置文件启动，这样可以区别正式环境和开发环境的docker up可以是别没有的服务并重新build，也可以用\u0026ndash;build强制 ","permalink":"https://26huitailang.github.io/posts/docker/cheatsheet/","summary":"docker cheatsheet docker\n# 不使用缓存重新build docker build . --no-cache # tag docker build -t peterchen0802/mypandoc:latest . docker tag peterchen0802/mypandoc:latest mypandoc:latest # 查看容器日志 docker logs SERVICE_NAME [-f] # 导出容器 # 注：用户既可以使用 docker load 来导入镜像存储文件到本地镜像库，也可以使用 docker import 来导入一个容器快照到本地镜像库。这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也要大。此外，从容器快照文件导入时可以重新指定标签等元数据信息。 docker export CONTAINER \u0026gt; TARFILENAME docker export CONTAINER -o TARFILENAME # 导入容器 docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]] docker import mypandoc.tar peterchen0802/mypandoc:latest # 指定导入的镜像名称 # -----清理 start----- ## 磁盘容量查看 docker system df ## 清理 docker rmi $(docker images --filter \u0026#34;dangling=true\u0026#34; -q) ## 清理无标签的镜像 docker image prune ## 清理磁盘，删除关闭的容器、无用的数据卷、网络，以及dangling镜像（无tag的镜像）。 docker system prune ## 更彻底的删除，将没有容器使用的镜像删除： docker system prune -a # -----清理 end----- docker-compose","title":"Docker Cheatsheet"},{"content":"tmux 终端服用软件，session可以保存在tmux server中，就算iterm等终端关闭也可以恢复，远程连接的时候避免掉线（类似的功能的软件还有，screen）。\n参考 十分钟学会 tmux Tmux - Linux从业者必备利器 * cheatsheet 优雅地使用命令行：Tmux 终端复用 Tmux使用手册 本机，cheatsheet-tmux 安装 brew install tmux 基于参考第二篇文章，配置：\n$ cd $ rm -rf .tmux $ git clone https://github.com/gpakosz/.tmux.git $ ln -s -f .tmux/.tmux.conf $ cp .tmux/.tmux.conf.local . 概念 session，不同的会话 window，不同的窗口，物理划分，一个session可以有多个window pane，窗格，一个window可以用过 %/\u0026quot; 划分为多个窗格 tmux操作 tmux ls，查看打开的session tmux a，恢复 tmux a -t SESSION,恢复指定session C-b操作 前缀快捷键，^b % 左右平分出两个pane \u0026quot; 上下平分出两个pane x 关闭当前窗格 { 当前窗格前移 } 当前窗格后移 ; 选择上次使用的窗格 o 选择下一个窗格，也可以使用上下左右方向键来选择 space 切换窗格布局，tmux 内置了五种窗格布局，也可以通过 ⌥1 至 ⌥5来切换 z 最大化当前窗格，再次执行可恢复原来大小 q 显示所有窗格的序号，在序号出现期间按下对应的数字，即可跳转至对应的窗格 resize pane C-b :resize-pane -D/U/R/L 20 修改配置 ~/.tmux.conf.local ~/.tmux.conf source file\nC-b :source-file ~/.tmux.conf.local 修改复制模式为vi模式，.tmux.conf.local\nset-option -g mode-keys vi 复制 修改vi模式后\nC-b + [ 进去复制模式 空格开始选择 Enter 结束 C-b + ] 粘贴 插件 恢复会话 Tmux Resurrect 安装\nmkdir -p ~/.tmux/plugins \u0026amp;\u0026amp; cd ~/.tmux/plugins git clone https://github.com/tmux-plugins/tmux-resurrect.git 修改 ~/.tmux.conf.local run-shell ~/.tmux/plugins/tmux-resurrect/resurrect.tmux prefix + r 重载配置 保存，prefix + Ctrl + s\n保存位置，~/.tmux/resurrect，可以手动清理这里的历史记录 恢复，prefix + Ctrl + r\n自动恢复 Tmux Continuum 先用手动，后续试试这个自动\n","permalink":"https://26huitailang.github.io/posts/devenv/tmux/","summary":"tmux 终端服用软件，session可以保存在tmux server中，就算iterm等终端关闭也可以恢复，远程连接的时候避免掉线（类似的功能的软件还有，screen）。\n参考 十分钟学会 tmux Tmux - Linux从业者必备利器 * cheatsheet 优雅地使用命令行：Tmux 终端复用 Tmux使用手册 本机，cheatsheet-tmux 安装 brew install tmux 基于参考第二篇文章，配置：\n$ cd $ rm -rf .tmux $ git clone https://github.com/gpakosz/.tmux.git $ ln -s -f .tmux/.tmux.conf $ cp .tmux/.tmux.conf.local . 概念 session，不同的会话 window，不同的窗口，物理划分，一个session可以有多个window pane，窗格，一个window可以用过 %/\u0026quot; 划分为多个窗格 tmux操作 tmux ls，查看打开的session tmux a，恢复 tmux a -t SESSION,恢复指定session C-b操作 前缀快捷键，^b % 左右平分出两个pane \u0026quot; 上下平分出两个pane x 关闭当前窗格 { 当前窗格前移 } 当前窗格后移 ; 选择上次使用的窗格 o 选择下一个窗格，也可以使用上下左右方向键来选择 space 切换窗格布局，tmux 内置了五种窗格布局，也可以通过 ⌥1 至 ⌥5来切换 z 最大化当前窗格，再次执行可恢复原来大小 q 显示所有窗格的序号，在序号出现期间按下对应的数字，即可跳转至对应的窗格 resize pane C-b :resize-pane -D/U/R/L 20 修改配置 ~/.","title":"tmux"},{"content":"nginx [toc]\n常用命令 nginx -s stop nginx -s reload 简介 反向代理 一句话：\n什么是正向代理？代理的是客户端 什么是反向代理？代理的是服务器，客户端是无感知的 nginx反向代理配置\n正常情况： client —(send request)—\u0026gt; server 代理情况： client —(send request)—\u0026gt; clinet proxy –(send request)—\u0026gt; server 反向代理： client -(send request)-\u0026gt; server proxy -(send request)-\u0026gt; other server 可以看到反向代理并不是真的反过来，而是代理人的身份由客户端转向了服务端，也因为代理是在服务端，所以客户端是对此无感知的。\n负载均衡 将原先集中请求到单个服务器的请求分发到多个服务器上，目的是为了支持服务横向扩展。\n动静分离 配置 全局 配置文件开始到events之间的内容，主要是设置一些影响nginx运行的配置指令，比如：\n用户（组） worker process数量 进程pid存放路径 日志存放路径和类型 配置文件的引入 events 配置nginx服务器与用户的网络连接，此部分对性能影响较大，应根据实际情况处理，比如：\n是否开启对多worker process下的网络连接进行序列化 是否允许同时接受多个网络连接 选取处理连接的事件驱动模型 每个worker 支持的最大连接数等 http 全局配置 server配置 全局 location配置 server 配置和匹配规则 一个http服务可以有多个server，而对server的路径匹配，反向代理都是在这里配置的。\n在server中最重要的一项配置：server_name的配置。server_name决定了来了一个url，到底是哪个server处理该请求。nginx会依次找和url配置的第一次出现的server。server_name可以使用通配符，也可以使用正则表达式。而且一个server的server_name可以多个，以空格分隔。更详细的关于server_name匹配规则，参看这里\nUnix-domain socket(Unix域套接字) Python实例浅谈之九使用本地socket文件\nUnix domain socket 或者 IPC socket是一种终端，可以使同一台操作系统上的两个或多个进程进行数据通信。与管道相比，Unix domain sockets 既可以使用字节流，又可以使用数据队列，而管道通信则只能使用字节流。Unix domain sockets的接口和Internet socket很像，但它不使用网络底层协议来通信。Unix domain socket 的功能是POSIX操作系统里的一种组件。\nUnix domain sockets 使用系统文件的地址来作为自己的身份。它可以被系统进程引用。所以两个进程可以同时打开一个Unix domain sockets来进行通信。不过这种通信方式是发生在系统内核里而不会在网络里传播。\n部署应用的时候，利用unix domain socket，可以防止端口冲突，启动程序的时候要将这个socket文件绑定到Gunicorn。\n这个是用于进程间通信的方式，那么网络socket是什么？ 文章或文档链接 搭建nginx反向代理用做内网域名转发 WEB请求处理二：Nginx请求反向代理 使用 Nginx 和 Gunicorn 部署 Django 博客 ","permalink":"https://26huitailang.github.io/posts/nginx/nginx/","summary":"nginx [toc]\n常用命令 nginx -s stop nginx -s reload 简介 反向代理 一句话：\n什么是正向代理？代理的是客户端 什么是反向代理？代理的是服务器，客户端是无感知的 nginx反向代理配置\n正常情况： client —(send request)—\u0026gt; server 代理情况： client —(send request)—\u0026gt; clinet proxy –(send request)—\u0026gt; server 反向代理： client -(send request)-\u0026gt; server proxy -(send request)-\u0026gt; other server 可以看到反向代理并不是真的反过来，而是代理人的身份由客户端转向了服务端，也因为代理是在服务端，所以客户端是对此无感知的。\n负载均衡 将原先集中请求到单个服务器的请求分发到多个服务器上，目的是为了支持服务横向扩展。\n动静分离 配置 全局 配置文件开始到events之间的内容，主要是设置一些影响nginx运行的配置指令，比如：\n用户（组） worker process数量 进程pid存放路径 日志存放路径和类型 配置文件的引入 events 配置nginx服务器与用户的网络连接，此部分对性能影响较大，应根据实际情况处理，比如：\n是否开启对多worker process下的网络连接进行序列化 是否允许同时接受多个网络连接 选取处理连接的事件驱动模型 每个worker 支持的最大连接数等 http 全局配置 server配置 全局 location配置 server 配置和匹配规则 一个http服务可以有多个server，而对server的路径匹配，反向代理都是在这里配置的。\n在server中最重要的一项配置：server_name的配置。server_name决定了来了一个url，到底是哪个server处理该请求。nginx会依次找和url配置的第一次出现的server。server_name可以使用通配符，也可以使用正则表达式。而且一个server的server_name可以多个，以空格分隔。更详细的关于server_name匹配规则，参看这里\nUnix-domain socket(Unix域套接字) Python实例浅谈之九使用本地socket文件","title":"Nginx"},{"content":"Pandoc 开始 install pandoc install miktext build 中文要选择合适的字体否则无法成功创建 fc-list mac: brew install fontconfig fc-list :lang-zh \u0026gt; fonts.txt fc-list -f \u0026ldquo;%{family}\\n\u0026rdquo; :lang=zh 参数解释 -o: 输出文件 \u0026ndash;from: 输入文件类型 \u0026ndash;template: 模版文件 \u0026ndash;listings: 列表 \u0026ndash;pdf-engine: pdf生成用的引擎 -V: 参数 CJKmainfont: 中文文字字体 pandoc \u0026#34;README.md\u0026#34; -o \u0026#34;document.pdf\u0026#34; --from markdown --template \u0026#34;./template.latex\u0026#34; --listings --pdf-engine \u0026#34;xelatex\u0026#34; -V CJKmainfont=\u0026#34;PingFang SC\u0026#34; \u0026amp;\u0026amp; open document.pdf data-dir DATADIR\nmacos: ~/.local/share/pandoc\nwindows: C:\\Users\\USERNAME\\AppData\\Roaming\\pandoc\ndefaults $DATADIR/defaults/docker.yaml，可以为不同的文档设置自己的defaults，避免后面重复操作，仅需使用pandoc --defaults docker即可打包文档\nfrom: markdown # reader: may be used instead of from: to: pdf # writer: may be used instead of to: # leave blank for output to stdout: output-file: docker.pdf # leave blank for input from stdin, use [] for no input: input-files: - 阿里云仓库.md - 管理工具.md - 加速.md - 扩容.md - 清理.md - 容器导出和导入.md - 私有registry.md - debian-docker-install.md - env.md - logs.md - usage.md # or you may use input-file: with a single value # pdf-engine: wkhtmltopdf pdf-engine: xelatex self-contained: false standalone: true metadata: author: - Peter titlepage: true toc-own-page: true toc: true number-sections: true # code block wrap listings: true variables: CJKmainfont: KaiTi template: eisvogel verbosity: ERROR log-file: log.json filters: - mermaid-filter.cmd from: markdown # reader: may be used instead of from: to: pdf # writer: may be used instead of to: # leave blank for output to stdout: output-file: docker.pdf # leave blank for input from stdin, use [] for no input: input-files: - 阿里云仓库.md - 管理工具.md - 加速.md - 扩容.md - 清理.md - 容器导出和导入.md - 私有registry.md - debian-docker-install.md - env.md - logs.md - usage.md # or you may use input-file: with a single value # pdf-engine: wkhtmltopdf pdf-engine: xelatex self-contained: false standalone: true metadata: author: - Peter titlepage: true toc-own-page: true toc: true number-sections: true # code block wrap listings: true variables: CJKmainfont: KaiTi template: eisvogel verbosity: ERROR log-file: log.json filters: - mermaid-filter.cmd template 设置为系统配置，eisvogel.latex，github\nmacos: mkdir -p ~/.local/share/pandoc/templates windows: mkdir -p C:\\Users\\USERNAME\\AppData\\Roaming\\pandoc\\templates cp ./eisvogel.latex ~/.local/share/pandoc/templates/ pandoc \u0026#34;README.md\u0026#34; -o \u0026#34;document.pdf\u0026#34; --from markdown --template eisvogel --listings --pdf-engine \u0026#34;xelatex\u0026#34; -V CJKmainfont=\u0026#34;PingFang SC\u0026#34; \u0026amp;\u0026amp; open document.pdf 多个md文件输入 使用系统路径下的模版 eisvogel \u0026ndash;number-sections 为各个标题编码 toc 标题 toc-own-page 标题页之后从新页开始内容 titlepage 封面 ```markdown --- title: 前端组IT手册 date: 2021-11-12 author: 前端组 titlepage: true toc: true toc-own-page: true --- \u0026gt; pandoc *.md -o \u0026#34;前端IT手册.pdf\u0026#34; --from markdown --template eisvogel --listings --number-sections --pdf-engine \u0026#34;xelatex\u0026#34; -V CJKmainfont=\u0026#34;PingFang SC\u0026#34; \u0026amp;\u0026amp; open \u0026#34;前端IT手册.pdf\u0026#34; 支持mermaid 使用filter特性，首先安装对应的filter\nnpm install --global mermaid-filter 设置全局的npm安装位置到$PATH里面，否则无法识别filter。\n在defaults对应的文件中添加filters：\nfilters: - mermaid-filter.cmd (windows) - mermaid-filter.sh 在cli中添加 \u0026ndash;filter参数：\npandoc --defaults docker --filter mermaid-filter 制作一个pandoc镜像 https://github.com/26huitailang/pandoc-demo\n","permalink":"https://26huitailang.github.io/posts/markdown/pandoc/","summary":"Pandoc 开始 install pandoc install miktext build 中文要选择合适的字体否则无法成功创建 fc-list mac: brew install fontconfig fc-list :lang-zh \u0026gt; fonts.txt fc-list -f \u0026ldquo;%{family}\\n\u0026rdquo; :lang=zh 参数解释 -o: 输出文件 \u0026ndash;from: 输入文件类型 \u0026ndash;template: 模版文件 \u0026ndash;listings: 列表 \u0026ndash;pdf-engine: pdf生成用的引擎 -V: 参数 CJKmainfont: 中文文字字体 pandoc \u0026#34;README.md\u0026#34; -o \u0026#34;document.pdf\u0026#34; --from markdown --template \u0026#34;./template.latex\u0026#34; --listings --pdf-engine \u0026#34;xelatex\u0026#34; -V CJKmainfont=\u0026#34;PingFang SC\u0026#34; \u0026amp;\u0026amp; open document.pdf data-dir DATADIR\nmacos: ~/.local/share/pandoc\nwindows: C:\\Users\\USERNAME\\AppData\\Roaming\\pandoc\ndefaults $DATADIR/defaults/docker.yaml，可以为不同的文档设置自己的defaults，避免后面重复操作，仅需使用pandoc --defaults docker即可打包文档\nfrom: markdown # reader: may be used instead of from: to: pdf # writer: may be used instead of to: # leave blank for output to stdout: output-file: docker.","title":"Pandoc"},{"content":"README 初次使用 podman root用户和非root用户的images和container是分开的 非root用户使用podman generate systemd命令生成的文件，拷贝到~/.config/systemd/user/下面，使用systemctl --user执行 流程演示\npodman pull docker.io/nginx:latest podman create --name nginx -p 8080:80 nginx:latest mkdir -p ~/.config/systemd/user cd ~/.config/systemd/user podman generate systemd --files --name nginx systemctl --user enable container-nginx systemctl --user start container-nginx curl http://127.0.0.1:8080 ","permalink":"https://26huitailang.github.io/posts/podman/readme/","summary":"README 初次使用 podman root用户和非root用户的images和container是分开的 非root用户使用podman generate systemd命令生成的文件，拷贝到~/.config/systemd/user/下面，使用systemctl --user执行 流程演示\npodman pull docker.io/nginx:latest podman create --name nginx -p 8080:80 nginx:latest mkdir -p ~/.config/systemd/user cd ~/.config/systemd/user podman generate systemd --files --name nginx systemctl --user enable container-nginx systemctl --user start container-nginx curl http://127.0.0.1:8080 ","title":"Podman"},{"content":"Upgrade debian main version update $ apt-get update \u0026amp;\u0026amp; apt-get upgrade backup sources.list $ cp /etc/apt/sources.list /etc/apt/sources.list.bak replace `stretch` to `buster` of `/etc/apt/sources.list` $ sed -i \u0026#39;s/stretch/buster/g\u0026#39; /etc/apt/sources.list run upgrade $ apt-get update \u0026amp;\u0026amp; apt-get upgrade run dist upgrade $ apt-get dist-upgrade $ reboot $ lsb_release -a clean: $ apt-get autoremove ","permalink":"https://26huitailang.github.io/posts/linux/debian/upgrade/","summary":"Upgrade debian main version update $ apt-get update \u0026amp;\u0026amp; apt-get upgrade backup sources.list $ cp /etc/apt/sources.list /etc/apt/sources.list.bak replace `stretch` to `buster` of `/etc/apt/sources.list` $ sed -i \u0026#39;s/stretch/buster/g\u0026#39; /etc/apt/sources.list run upgrade $ apt-get update \u0026amp;\u0026amp; apt-get upgrade run dist upgrade $ apt-get dist-upgrade $ reboot $ lsb_release -a clean: $ apt-get autoremove ","title":"Upgrade debian main version"},{"content":"Gitlab CI/CD For the development environment.\nInstall with docker Read the official documentation for how to install docker.\nI installed docker on the MacOS.\ngitlab documentation\nsudo docker run --detach \\ --hostname 192.168.8.226 \\ --publish 443:443 --publish 80:80 --publish 8022:22 \\ --name gitlab \\ --restart always \\ --volume ~/gitlab/config:/etc/gitlab \\ --volume ~/gitlab/logs:/var/log/gitlab \\ --volume ~/gitlab/data:/var/opt/gitlab \\ gitlab/gitlab-ce:latest gitlab-runner Order of initialization:\ninstall register custom config documentation\nThere is no difficulty to install gitlab and gitlab-runner in docker.\nsudo docker run -d --name gitlab-runner --restart always \\ -v ~/gitlab-runner/config:/etc/gitlab-runner \\ -v /var/run/docker.sock:/var/run/docker.sock \\ gitlab/gitlab-runner:latest I was confused with the config of gitlab-runner, so I wrote these down.\nregister:\ndocker run --rm -t -i -v ~/gitlab-runner/config:/etc/gitlab-runner gitlab/gitlab-runner register, cmd for register a runner. the register info will record in the ~/gitlab-runner/config/config.toml url is the url of the gitlab token is from your gitlab, the project runner and shared runner is different. You can registe it for shared runner and enable for the specified project. executor choose docker, I use the image python:3.7 for my python project. manual operation to edit the config.toml: pull_policy = \u0026quot;if-not-present\u0026quot; default value is always for every time pull the image. network_mode = \u0026quot;host\u0026quot; default value is bridge that runner cannot connect other machines in the same net. for non-interactive register:\ndocker run --rm -v /srv/gitlab-runner/config:/etc/gitlab-runner gitlab/gitlab-runner register \\ --non-interactive \\ --executor \u0026#34;docker\u0026#34; \\ --docker-image alpine:latest \\ --url \u0026#34;https://gitlab.com/\u0026#34; \\ --registration-token \u0026#34;PROJECT_REGISTRATION_TOKEN\u0026#34; \\ --description \u0026#34;docker-runner\u0026#34; \\ --tag-list \u0026#34;docker,aws\u0026#34; \\ --run-untagged=\u0026#34;true\u0026#34; \\ --locked=\u0026#34;false\u0026#34; \\ --access-level=\u0026#34;not_protected\u0026#34; config.toml privileged 如果遇到mkdir permission denied，设为true，可以解决\n[[runners]] name = \u0026#34;python3.7\u0026#34; url = \u0026#34;http://192.168.8.226/\u0026#34; token = \u0026#34;xxxxxx\u0026#34; executor = \u0026#34;docker\u0026#34; [runners.custom_build_dir] [runners.docker] tls_verify = false image = \u0026#34;python:3.7\u0026#34; privileged = true disable_entrypoint_overwrite = false oom_kill_disable = false disable_cache = false volumes = [\u0026#34;/cache\u0026#34;] shm_size = 0 pull_policy = \u0026#34;if-not-present\u0026#34; network_mode = \u0026#34;host\u0026#34; [runners.cache] [runners.cache.s3] [runners.cache.gcs] [runners.custom] run_exec = \u0026#34;\u0026#34; cache with local files. Npm example:\nvolumes = [\u0026#34;/opt/gitlab-runner/cache:/cache\u0026#34;] ls /opt/gitlab-runner/cache/GROUP/PROJECT_NAME/builds/GROUP/PROJECT_NAME cache.zip cache.zip is the node_modules.zip file.\n.gitlab-ci.yml Use the ssh connect development machine and run the shell command to update the project. cache after the CI. The runner will cache the pip and venv packages. # This file is a template, and might need editing before it works on your project. image: python:3.7 # This folder is cached between builds # http://docs.gitlab.com/ce/ci/yaml/README.html#cache cache: paths: - .cache/pip - venv/ before_script: ## ## Install ssh-agent if not already installed, it is required by Docker. ## (change apt-get to yum if you use an RPM-based image) ## - \u0026#39;which ssh-agent || ( apt-get update -y \u0026amp;\u0026amp; apt-get install openssh-client -y )\u0026#39; ## ## Run ssh-agent (inside the build environment) ## - eval $(ssh-agent -s) ## ## Add the SSH key stored in SSH_PRIVATE_KEY variable to the agent store ## We\u0026#39;re using tr to fix line endings which makes ed25519 keys work ## without extra base64 encoding. ## https://gitlab.com/gitlab-examples/ssh-private-key/issues/1#note_48526556 ## - echo \u0026#34;$SSH_PRIVATE_KEY\u0026#34; \u0026gt; deploy.key - chmod 0600 deploy.key - ssh-add deploy.key - mkdir -p ~/.ssh - chmod 700 ~/.ssh - \u0026#39;[[ -f /.dockerenv ]] \u0026amp;\u0026amp; echo -e \u0026#34;Host *\\n\\tStrictHostKeyChecking no\\n\\n\u0026#34; \u0026gt; ~/.ssh/config\u0026#39; ## ## Optionally, if you will be using any Git commands, set the user name and ## and email. ## #- git config --global user.email \u0026#34;user@example.com\u0026#34; #- git config --global user.name \u0026#34;User name\u0026#34; - python -V # Print out python version for debugging test: script: - python -m venv ./venv - source venv/bin/activate - pip install -U -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple/ - cd lq_end # - cp -f config/ci.py config/config.py # - python manage.py devops drop_and_recreate_ci_database # - flask db upgrade # - flask init-db - python -m pytest --cov=. - ssh root@192.168.8.109 \u0026#34;cd /root/test-project \u0026amp;\u0026amp; ./script.sh\u0026#34; #pep8: # script: # - python -m venv ./venv # - source venv/bin/activate # - pip install -U flake8 # - cd projectpath # - flake8 ","permalink":"https://26huitailang.github.io/posts/devops/gitlab/gitlab-ci-cd/","summary":"Gitlab CI/CD For the development environment.\nInstall with docker Read the official documentation for how to install docker.\nI installed docker on the MacOS.\ngitlab documentation\nsudo docker run --detach \\ --hostname 192.168.8.226 \\ --publish 443:443 --publish 80:80 --publish 8022:22 \\ --name gitlab \\ --restart always \\ --volume ~/gitlab/config:/etc/gitlab \\ --volume ~/gitlab/logs:/var/log/gitlab \\ --volume ~/gitlab/data:/var/opt/gitlab \\ gitlab/gitlab-ce:latest gitlab-runner Order of initialization:\ninstall register custom config documentation\nThere is no difficulty to install gitlab and gitlab-runner in docker.","title":"Gitlab CI/CD"},{"content":"Apache Bench Test GET\nab -c 10 -n 40 http://127.0.0.1:8000/api/v1/mzitu/tags/\nPOST, https://blog.csdn.net/chenggong2dm/article/details/51850923\nab -n 1 -c 1 -p f:/postdata.txt -T application/x-www-form-urlencoded \u0026ldquo;http://127.0.0.1/abpost\u0026rdquo; ab -n 100 -c 10 -p data.json -T application/json http://127.0.0.1/api\n// postdata.txt ","permalink":"https://26huitailang.github.io/posts/test/ab-test/","summary":"Apache Bench Test GET\nab -c 10 -n 40 http://127.0.0.1:8000/api/v1/mzitu/tags/\nPOST, https://blog.csdn.net/chenggong2dm/article/details/51850923\nab -n 1 -c 1 -p f:/postdata.txt -T application/x-www-form-urlencoded \u0026ldquo;http://127.0.0.1/abpost\u0026rdquo; ab -n 100 -c 10 -p data.json -T application/json http://127.0.0.1/api\n// postdata.txt ","title":"Apache Bench Test"},{"content":"Prometheus 简介 概念 prometheus server exporter，用于server采集数据，有官方提供的node-exporter，也可以通过各种SDK自定义导出内容，暴露一个类似/metrics的路径用于采集 注意，exporter在多进程（gunicorn 多进程）模式下使用会有限制，参考文档 数据模型，和influxdb类似，是时序数据库，以metric为名称，多个label（key-value形式）组成：\u0026lt;metric name\u0026gt;{\u0026lt;label name\u0026gt;=\u0026lt;label value\u0026gt;, ...} 重载配置 Yes, sending SIGHUP to the Prometheus process or an HTTP POST request to the /-/reload endpoint will reload and apply the configuration file. The various components attempt to handle failing changes gracefully.\n","permalink":"https://26huitailang.github.io/posts/k3s/prometheus/","summary":"Prometheus 简介 概念 prometheus server exporter，用于server采集数据，有官方提供的node-exporter，也可以通过各种SDK自定义导出内容，暴露一个类似/metrics的路径用于采集 注意，exporter在多进程（gunicorn 多进程）模式下使用会有限制，参考文档 数据模型，和influxdb类似，是时序数据库，以metric为名称，多个label（key-value形式）组成：\u0026lt;metric name\u0026gt;{\u0026lt;label name\u0026gt;=\u0026lt;label value\u0026gt;, ...} 重载配置 Yes, sending SIGHUP to the Prometheus process or an HTTP POST request to the /-/reload endpoint will reload and apply the configuration file. The various components attempt to handle failing changes gracefully.","title":"Prometheus"},{"content":"PyCharm 使用 Docker pycharm use docker for development and stage\nDevelopment 使用windows和virtualbox，没有打开hyper-v所以无法使用docker，在虚拟机中使用docker并打开tcp，但是由于volume只能挂载宿主机，所以要先用pycharmm将文件拷贝到远程的映射目录，再使用。 此方法适合还没有准备开发环境和需要使用docker作为开发环境，但是windows本机没有docker的情况 我已使用虚拟机和pycharm远程同步功能达到同样的效果 在宿主机中开发时，可以很方便的将docker配置集成到configuration中 Stage PyCharm的docker也支持修改registry，如果有远程仓库需要的，也可以方便分发镜像\n","permalink":"https://26huitailang.github.io/posts/pycharm/docker/","summary":"PyCharm 使用 Docker pycharm use docker for development and stage\nDevelopment 使用windows和virtualbox，没有打开hyper-v所以无法使用docker，在虚拟机中使用docker并打开tcp，但是由于volume只能挂载宿主机，所以要先用pycharmm将文件拷贝到远程的映射目录，再使用。 此方法适合还没有准备开发环境和需要使用docker作为开发环境，但是windows本机没有docker的情况 我已使用虚拟机和pycharm远程同步功能达到同样的效果 在宿主机中开发时，可以很方便的将docker配置集成到configuration中 Stage PyCharm的docker也支持修改registry，如果有远程仓库需要的，也可以方便分发镜像","title":"PyCharm Docker"},{"content":"Django打开gzip导致文件流content-length丢失 code GZipMiddleware\nuse gzip middleware will del response['Content-Length'] if response.streaming. nginx gzip is the same problem.\nIf file feature is important. You\u0026rsquo;d better be independent from the api or system.\n","permalink":"https://26huitailang.github.io/posts/django/gzip/","summary":"Django打开gzip导致文件流content-length丢失 code GZipMiddleware\nuse gzip middleware will del response['Content-Length'] if response.streaming. nginx gzip is the same problem.\nIf file feature is important. You\u0026rsquo;d better be independent from the api or system.","title":"Django打开gzip导致文件流content-length丢失"},{"content":"k3s 初次使用 multipass 环境准备 quick-start 参考1 参考2 # k3s1 node for master 192.168.64.5 multipass launch -v --name k3s1 20.04 multipass shell k3s1 curl -sfL https://get.k3s.io | sh - # default config sudo cat /etc/rancher/k3s/k3s.yaml # node-token sudo cat /var/lib/rancher/k3s/server/node-token # Check for Ready node, takes maybe 30 seconds sudo kubectl get nodes # k3s2 node 192.168.64.6 multipass launch -v --name k3s2 20.04 multipass shell k3s2 # add node to cluster # token in master cat /var/lib/rancher/k3s/server/node-token # K3S_NODE_NAME for unique hostname export K3S_TOKEN=x export K3S_URL=https://192.168.1.21:6443 curl -sfL https://get.k3s.io | K3S_URL=${K3S_URL} K3S_TOKEN=${K3S_TOKEN} sh - # if not register successfully, 查看日志可能是因为之前有重复node hostname # 原因：https://github.com/rancher/k3s/issues/802 移除node没有一同移除密码 sudo vim /var/lib/rancher/k3s/server/cred/node-passwd 查看节点状态：\nsudo kubectl get nodes dashboard kube-dashboard\ninstall\nGITHUB_URL=https://github.com/kubernetes/dashboard/releases VERSION_KUBE_DASHBOARD=$(curl -w \u0026#39;%{url_effective}\u0026#39; -I -L -s -S ${GITHUB_URL}/latest -o /dev/null | sed -e \u0026#39;s|.*/||\u0026#39;) sudo k3s kubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/${VERSION_KUBE_DASHBOARD}/aio/deploy/recommended.yaml Dashboard RBAC Configuration\ndashboard.admin-user.yml\napiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kubernetes-dashboard dashboard.admin-user-role.yml\napiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: admin-user roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: admin-user namespace: kubernetes-dashboard sudo k3s kubectl create -f dashboard.admin-user.yml -f dashboard.admin-user-role.yml Obtain the Bearer Token, 用于token登录dashboard\nsudo k3s kubectl -n kubernetes-dashboard describe secret admin-user-token | grep ^token access\nhttp://192.168.64.5:6443/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/ ingress k3s 默认使用的是traefik，k8s推荐的是GCE和ingress-nginx。\n但是traefik默认配置: /var/lib/rancher/k3s/server/manifests/traefik.yaml 没有开启dashboard。尝试打开：\n查看当前配置：\nkubectl describe deploy traefik -n kube-system 得知配置是使用的 /config 的volume：\nkubectl describe configmap traefik -n kube-system 添加set部分内容：\nset: dashboard.enabled: \u0026quot;true\u0026quot; traefik.yml\nroot@k3s1:/var/lib/rancher/k3s/server/manifests# cat traefik.yaml apiVersion: helm.cattle.io/v1 kind: HelmChart metadata: name: traefik namespace: kube-system spec: chart: https://%{KUBERNETES_API}%/static/charts/traefik-1.81.0.tgz set: dashboard.enabled: \u0026#34;true\u0026#34; valuesContent: |- rbac: enabled: true ssl: enabled: true metrics: prometheus: enabled: true kubernetes: ingressEndpoint: useDefaultPublishedService: true image: \u0026#34;rancher/library-traefik\u0026#34; tolerations: - key: \u0026#34;CriticalAddonsOnly\u0026#34; operator: \u0026#34;Exists\u0026#34; - key: \u0026#34;node-role.kubernetes.io/master\u0026#34; operator: \u0026#34;Exists\u0026#34; effect: \u0026#34;NoSchedule\u0026#34; 如何配置ingress，配合一个django的sample\napiVersion: extensions/v1beta1 kind: Ingress metadata: name: my-server spec: rules: - host: my-server.192.168.1.22.xip.io http: paths: - path: /jobs backend: serviceName: web servicePort: 8080 - path: /static backend: serviceName: web servicePort: 8080 cheat sheet cheatsheet\nnginx demo in k3s2 machine\nmkdir ~/controllers cat \u0026gt; nginx-deployment.yaml \u0026lt;\u0026lt;EOL apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment labels: app: nginx spec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80 EOL 问题 vagrant nat 10.0.2.15网络问题，server/agent 选择对应的网络启动，不然默认选中第一个 sudo vim /etc/systemd/system/k3s-agent.service sudo vim /etc/systemd/system/k3s.service ExecStart=/usr/local/bin/k3s \\ server --flannel-iface=enp0s8 \\ 镜像 docker.io 加速，在containerd的config中加入地址，http://www.zzfly.net/k3s-installation-and-containerd-registry/ [plugins.cri.registry.mirrors] [plugins.cri.registry.mirrors.\u0026#34;docker.io\u0026#34;] endpoint = [\u0026#34;https://docker.mirrors.ustc.edu.cn\u0026#34;] root@k3s1:/vagrant/samples-master/django# cd /var/lib/rancher/k3s/agent/etc/containerd/ root@k3s1:/var/lib/rancher/k3s/agent/etc/containerd# ls config.toml root@k3s1:/var/lib/rancher/k3s/agent/etc/containerd# cp config.toml config.toml.tmpl root@k3s1:/var/lib/rancher/k3s/agent/etc/containerd# vim config.toml.tmpl root@k3s1:/var/lib/rancher/k3s/agent/etc/containerd# systemctl restart k3s root@k3s1:/var/lib/rancher/k3s/agent/etc/containerd# crictl info | grep registry -C 10 } }, \u0026#34;noPivot\u0026#34;: false }, \u0026#34;cni\u0026#34;: { \u0026#34;binDir\u0026#34;: \u0026#34;/var/lib/rancher/k3s/data/572dcee7aa63e8f11e61142e4b0fc4f7ce33a0a6fed6a72924c6f6be85781b10/bin\u0026#34;, \u0026#34;confDir\u0026#34;: \u0026#34;/var/lib/rancher/k3s/agent/etc/cni/net.d\u0026#34;, \u0026#34;maxConfNum\u0026#34;: 1, \u0026#34;confTemplate\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;registry\u0026#34;: { \u0026#34;mirrors\u0026#34;: { \u0026#34;docker.io\u0026#34;: { \u0026#34;endpoint\u0026#34;: [ \u0026#34;https://docker.mirrors.ustc.edu.cn\u0026#34; ] } }, \u0026#34;configs\u0026#34;: null, \u0026#34;auths\u0026#34;: null }, ","permalink":"https://26huitailang.github.io/posts/k3s/k3s/","summary":"k3s 初次使用 multipass 环境准备 quick-start 参考1 参考2 # k3s1 node for master 192.168.64.5 multipass launch -v --name k3s1 20.04 multipass shell k3s1 curl -sfL https://get.k3s.io | sh - # default config sudo cat /etc/rancher/k3s/k3s.yaml # node-token sudo cat /var/lib/rancher/k3s/server/node-token # Check for Ready node, takes maybe 30 seconds sudo kubectl get nodes # k3s2 node 192.168.64.6 multipass launch -v --name k3s2 20.04 multipass shell k3s2 # add node to cluster # token in master cat /var/lib/rancher/k3s/server/node-token # K3S_NODE_NAME for unique hostname export K3S_TOKEN=x export K3S_URL=https://192.","title":"k3s"},{"content":"multipass to set development environment 官网\n指定配置 $ multipass launch --name XXX -c 2 -d 20G -m 2G 删除 $ multipass delete --purge XXXXX 问题 macos下面使用virtualbox暂时拿不到ip，只能使用NAT，最好使用hyperkit windows下面也不行，尝试添加第二个网络(gui操作 or vboxmanager)，我这里使用了桥接，之后修改/etc/network/interfaces填写相关信息，重启之后查看网卡能获得ip # ubuntu 18.04 allow-hotplug enp0s8 iface enp0s8 inet static address 10.200.242.200 netmask 255.0.0.0 gateway 10.0.0.3 ubuntu20.04操作: 修改 /etc/netplan/50-cloud-init.yaml 应用 sudo netplan apply 重启 sudo reboot # ubuntu 20.04 /etc/netplan/50-cloud-init.yaml network: ethernets: enp0s3: dhcp4: true match: macaddress: 08:00:27:bc:97:36 set-name: enp0s3 version: 2 # change like following part network: ethernets: enp0s3: dhcp4: false addresses: [10.200.242.200/8] gateway4: 10.0.0.3 nameservers: addresses: [8.8.8.8, 8.8.4.4] match: macaddress: 08:00:27:bc:97:36 set-name: enp0s3 version: 2 ","permalink":"https://26huitailang.github.io/posts/linux/ubuntu/multipass/","summary":"multipass to set development environment 官网\n指定配置 $ multipass launch --name XXX -c 2 -d 20G -m 2G 删除 $ multipass delete --purge XXXXX 问题 macos下面使用virtualbox暂时拿不到ip，只能使用NAT，最好使用hyperkit windows下面也不行，尝试添加第二个网络(gui操作 or vboxmanager)，我这里使用了桥接，之后修改/etc/network/interfaces填写相关信息，重启之后查看网卡能获得ip # ubuntu 18.04 allow-hotplug enp0s8 iface enp0s8 inet static address 10.200.242.200 netmask 255.0.0.0 gateway 10.0.0.3 ubuntu20.04操作: 修改 /etc/netplan/50-cloud-init.yaml 应用 sudo netplan apply 重启 sudo reboot # ubuntu 20.04 /etc/netplan/50-cloud-init.yaml network: ethernets: enp0s3: dhcp4: true match: macaddress: 08:00:27:bc:97:36 set-name: enp0s3 version: 2 # change like following part network: ethernets: enp0s3: dhcp4: false addresses: [10.","title":"Multipass"},{"content":"Tool Hub 各个分类的工具汇总\n开发 代码 nvim vscode jetbrains vim 代码管理 gitea gitlab CI drone jetbrains teamcity gitlab 接口测试 postman httpie jebrains http test curl 接口mock测试 httpretty: a full fake TCP socket module. Inspired by FakeWeb(ruby), 用于模拟http外部访问请求 responses: A utility for mocking out the Python Requests library. 接口性能测试 vegeta pssh + vegeta, pssh并行在多个计算机中执行命令，vegeta接口性能测试工具，支持代码修改、命令模式，输出json、text、gob、html等格式 apache benchmark(ab) 代码性能分析 Python memray pytest-memray py-spy, Never use print for debugging again PySnooper, Never use print for debugging again 文档 markdown：\ntypora，已收费 vscode + markdown + mermaid plugin markdown mermaid plantUML pandoc 构建文档 i18n poedit redis another redis desktop manager redis desktop manager 密码 keepass, windows macpass, macos, keepss的mac实现 输入效率 atext, windows copyQ, windows afred, macos dash, macos ssh/sftp transmit, macos xshell, windows mobaxterm, windows 作图 工具 功能 价格 地址 draw.io 支持在线/离线绘图，类似visio 免费 https://www.draw.io/ excalidraw 支持在线/离线，手绘风格白板 免费 https://github.com/excalidraw/excalidraw figma 在线，各种设计绘图 有限功能免费 https://www.figma.com/ whimsical 在线，docs/flowcharts/wireframes/mindmaps/projects 有限功能免费 https://www.whimsical.com/ 文件比对 beyondcompare diff 文件同步 rsync FreeFileSync， windows/macos ","permalink":"https://26huitailang.github.io/posts/tools/toolbox/","summary":"Tool Hub 各个分类的工具汇总\n开发 代码 nvim vscode jetbrains vim 代码管理 gitea gitlab CI drone jetbrains teamcity gitlab 接口测试 postman httpie jebrains http test curl 接口mock测试 httpretty: a full fake TCP socket module. Inspired by FakeWeb(ruby), 用于模拟http外部访问请求 responses: A utility for mocking out the Python Requests library. 接口性能测试 vegeta pssh + vegeta, pssh并行在多个计算机中执行命令，vegeta接口性能测试工具，支持代码修改、命令模式，输出json、text、gob、html等格式 apache benchmark(ab) 代码性能分析 Python memray pytest-memray py-spy, Never use print for debugging again PySnooper, Never use print for debugging again 文档 markdown：","title":"Toolbox"},{"content":"利用proxy 解决 Django Vue 开发环境中的跨域问题 最近使用 Django+Vue的组合快速的做一个项目，前段之前有看过，但是只是👀会了，这次实际操作，在前后端分离后的开发环境中踩了坑。\n环境 Django + DRF Django Channels，主要是websocket vue-admin-template，一个开源的项目，很多东西都有实现，新手可以用来改改就用，还能学习 开发环境：\nwsgi, 8000 asgi, 8001 vue, 9528 问题 想像在使用nginx一样的透明的使用开发环境 django已经配置了corsheaders middleware了 尝试 axios显示指定地址和端口到8000的服务上，解决了axios实例的访问，但是使用 el-upload的表单时，发现就不好使了，localhost和其他不同域，拿不到 cookie中的csrftoken，导致被 django拒绝 解决 在查看了各种文档后，最有效的方案是devServer的proxy，这是webpack提供的功能，使用的是http-proxy-middleware这个中间件，文档很详细，可以看看。\n目标：\n代理 /api的请求到8000端口的wsgi server 代理 /ws的请求到8001的asgi server /api ---\u0026gt; localhost:8000/api localhost:9528 (cookie) -- /ws ---\u0026gt; localhost:8001/ws vue.conf.js\ndevServer: { ... proxy: { [process.env.VUE_APP_BASE_API]: { target: \u0026#39;http://127.0.0.1:8000\u0026#39;, changeOrigin: true, ws: false, pathRewrite: { [\u0026#39;^\u0026#39; + process.env.VUE_APP_BASE_API]: \u0026#39;\u0026#39; }, cookieDomainRewrite: { \u0026#39;*\u0026#39;: \u0026#39;localhost\u0026#39; } }, \u0026#39;/ws\u0026#39;: { target: \u0026#39;ws://127.0.0.1:8001\u0026#39;, // changeOrigin: true, secure: false, ws: true } } ... } 说明：\nproxy里面的key表示要代理的path，我这里写的是变量代表的值，是从其他地方看到的，可以根据这个值来判断，比如 /api-prod /api-dev等，这里可以根据自己项目实际的命名规则，一般是/api即可 target：表示要代理的请求目标 changeOrigin：表示修改请求header中的origin ws：表示是否代理websockets pathRewrite：根据正则匹配来重写url，根据实际需要来写 cookieDomainRewrite，{ '*': 'localhost' }表示所有重写到localhost，这样所有的cookie都会同步过来，因为我使用了django session和crsftoken，所以这里得同步一下，不然会有前面说的axios header中有X-CRSFToken，而直接请求的form表单中没有，因为cookie不同，取不到csrftoken的值 ","permalink":"https://26huitailang.github.io/posts/vue/cors/","summary":"利用proxy 解决 Django Vue 开发环境中的跨域问题 最近使用 Django+Vue的组合快速的做一个项目，前段之前有看过，但是只是👀会了，这次实际操作，在前后端分离后的开发环境中踩了坑。\n环境 Django + DRF Django Channels，主要是websocket vue-admin-template，一个开源的项目，很多东西都有实现，新手可以用来改改就用，还能学习 开发环境：\nwsgi, 8000 asgi, 8001 vue, 9528 问题 想像在使用nginx一样的透明的使用开发环境 django已经配置了corsheaders middleware了 尝试 axios显示指定地址和端口到8000的服务上，解决了axios实例的访问，但是使用 el-upload的表单时，发现就不好使了，localhost和其他不同域，拿不到 cookie中的csrftoken，导致被 django拒绝 解决 在查看了各种文档后，最有效的方案是devServer的proxy，这是webpack提供的功能，使用的是http-proxy-middleware这个中间件，文档很详细，可以看看。\n目标：\n代理 /api的请求到8000端口的wsgi server 代理 /ws的请求到8001的asgi server /api ---\u0026gt; localhost:8000/api localhost:9528 (cookie) -- /ws ---\u0026gt; localhost:8001/ws vue.conf.js\ndevServer: { ... proxy: { [process.env.VUE_APP_BASE_API]: { target: \u0026#39;http://127.0.0.1:8000\u0026#39;, changeOrigin: true, ws: false, pathRewrite: { [\u0026#39;^\u0026#39; + process.env.VUE_APP_BASE_API]: \u0026#39;\u0026#39; }, cookieDomainRewrite: { \u0026#39;*\u0026#39;: \u0026#39;localhost\u0026#39; } }, \u0026#39;/ws\u0026#39;: { target: \u0026#39;ws://127.","title":"vue cors"},{"content":"docker env file 在docker-compose 中使用以下方式导入.envfile。\nweb: build: . restart: always working_dir: /deploy/mysite command: ./service_web.sh env_file: - .env # environments .env\nDOCKER=1 HOME=/deploy 想用shell script动态获取环境的CPU count 如果直接在.env 中写如下的内容，会报语法错误：\nCPU_NUM=$(cat /proc/cpuinfo |grep processor|wc -l) 所以，在web服务的command: ./service_web.sh脚本中export一个变量，并在gunicorn中使用：\n#!/bin/bash sleep 5 export CPU_NUM=$(cat /proc/cpuinfo |grep processor|wc -l) python manage.py collectstatic -v0 --noinput python manage.py migrate --noinput /usr/local/bin/gunicorn -w $((2*$CPU_NUM+1)) -b unix:/deploy/running/handle/django-tutorial-server.sock mysite.wsgi:application --log-level info ","permalink":"https://26huitailang.github.io/posts/docker/env/","summary":"docker env file 在docker-compose 中使用以下方式导入.envfile。\nweb: build: . restart: always working_dir: /deploy/mysite command: ./service_web.sh env_file: - .env # environments .env\nDOCKER=1 HOME=/deploy 想用shell script动态获取环境的CPU count 如果直接在.env 中写如下的内容，会报语法错误：\nCPU_NUM=$(cat /proc/cpuinfo |grep processor|wc -l) 所以，在web服务的command: ./service_web.sh脚本中export一个变量，并在gunicorn中使用：\n#!/bin/bash sleep 5 export CPU_NUM=$(cat /proc/cpuinfo |grep processor|wc -l) python manage.py collectstatic -v0 --noinput python manage.py migrate --noinput /usr/local/bin/gunicorn -w $((2*$CPU_NUM+1)) -b unix:/deploy/running/handle/django-tutorial-server.sock mysite.wsgi:application --log-level info ","title":"docker env file"},{"content":"docker 加速 mac ~/.docker/daemon.json 添加如下配置 { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://registry.docker-cn.com\u0026#34;] } ","permalink":"https://26huitailang.github.io/posts/docker/%E5%8A%A0%E9%80%9F/","summary":"docker 加速 mac ~/.docker/daemon.json 添加如下配置 { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://registry.docker-cn.com\u0026#34;] } ","title":"docker 加速"},{"content":"docker 管理工具 Portainer web服务\ndocker volume create portainer_data docker run -d -p 9000:9000 --name portainer --restart always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer ","permalink":"https://26huitailang.github.io/posts/docker/%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/","summary":"docker 管理工具 Portainer web服务\ndocker volume create portainer_data docker run -d -p 9000:9000 --name portainer --restart always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer ","title":"docker 管理工具"},{"content":"docker 阿里云仓库 登录阿里云Docker Registry $ sudo docker login --username=26huitailang@gmail.com registry.cn-hangzhou.aliyuncs.com 用于登录的用户名为阿里云账号全名，密码为开通服务时设置的密码。\n您可以在产品控制台首页修改登录密码。\n遇到无法登录问题：\nError saving credentials: error storing credentials - err: exit status 1, out: `The name org.freedesktop.secrets was not provided by any .service files sudo apt install gnupg2 pass 从Registry中拉取镜像 $ sudo docker pull registry.cn-hangzhou.aliyuncs.com/26huitailang/golang-web:[镜像版本号]\n将镜像推送到Registry $ sudo docker login --username=26huitailang@gmail.com registry.cn-hangzhou.aliyuncs.com $ sudo docker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/26huitailang/golang-web:[镜像版本号] $ sudo docker push registry.cn-hangzhou.aliyuncs.com/26huitailang/golang-web:[镜像版本号] 请根据实际镜像信息替换示例中的[ImageId]和[镜像版本号]参数。\n选择合适的镜像仓库地址 从ECS推送镜像时，可以选择使用镜像仓库内网地址。推送速度将得到提升并且将不会损耗您的公网流量。\n如果您使用的机器位于VPC网络，请使用 registry-vpc.cn-hangzhou.aliyuncs.com 作为Registry的域名登录，并作为镜像命名空间前缀。\n示例 使用\u0026quot;docker tag\u0026quot;命令重命名镜像，并将它通过专有网络地址推送至Registry。\n$ sudo docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE registry.aliyuncs.com/acs/agent 0.7-dfb6816 37bb9c63c8b2 7 days ago 37.89 MB $ sudo docker tag 37bb9c63c8b2 registry-vpc.cn-hangzhou.aliyuncs.com/acs/agent:0.7-dfb6816 使用\u0026quot;docker images\u0026quot;命令找到镜像，将该镜像名称中的域名部分变更为Registry专有网络地址。\n$ sudo docker push registry-vpc.cn-hangzhou.aliyuncs.com/acs/agent:0.7-dfb6816 ","permalink":"https://26huitailang.github.io/posts/docker/%E9%98%BF%E9%87%8C%E4%BA%91%E4%BB%93%E5%BA%93/","summary":"docker 阿里云仓库 登录阿里云Docker Registry $ sudo docker login --username=26huitailang@gmail.com registry.cn-hangzhou.aliyuncs.com 用于登录的用户名为阿里云账号全名，密码为开通服务时设置的密码。\n您可以在产品控制台首页修改登录密码。\n遇到无法登录问题：\nError saving credentials: error storing credentials - err: exit status 1, out: `The name org.freedesktop.secrets was not provided by any .service files sudo apt install gnupg2 pass 从Registry中拉取镜像 $ sudo docker pull registry.cn-hangzhou.aliyuncs.com/26huitailang/golang-web:[镜像版本号]\n将镜像推送到Registry $ sudo docker login --username=26huitailang@gmail.com registry.cn-hangzhou.aliyuncs.com $ sudo docker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/26huitailang/golang-web:[镜像版本号] $ sudo docker push registry.cn-hangzhou.aliyuncs.com/26huitailang/golang-web:[镜像版本号] 请根据实际镜像信息替换示例中的[ImageId]和[镜像版本号]参数。\n选择合适的镜像仓库地址 从ECS推送镜像时，可以选择使用镜像仓库内网地址。推送速度将得到提升并且将不会损耗您的公网流量。\n如果您使用的机器位于VPC网络，请使用 registry-vpc.cn-hangzhou.aliyuncs.com 作为Registry的域名登录，并作为镜像命名空间前缀。","title":"docker 阿里云仓库"},{"content":"ansible ref quick-start 流程 环境准备 创建三个虚拟机, ansible(安装 ansible 的机器), vm1, vm2\n使用 ssh-keygen 生成公私钥\nssh-copy-id name@host 配置免密登陆\n安装 ansible\n$ apt install -y ansible\n配置 ➜ ~ pwd /root ➜ ~ cat ansible.cfg [defaults] inventory = $HOME/hosts ➜ ~ cat hosts [webservers] vm1 [dbservers] vm2 ➜ ~ cat /etc/hosts 127.0.0.1\tlocalhost 127.0.1.1\tansible.ansible\tansible # The following lines are desirable for IPv6 capable hosts ::1 localhost ip6-localhost ip6-loopback ff02::1 ip6-allnodes ff02::2 ip6-allrouters # ansible 10.200.233.81 vm1 vm1.ansible.host 10.200.233.82 vm2 vm2.ansible.host 查看 hosts\n$ ansible all \u0026ndash;list-hosts\nping hosts\n$ ansible all -m ping\nmodules 各个 module 文档\n查看 modules\n$ ansible-doc -l | wc -l 2078\ncopy module 使用\n$ ansible all -m copy -a \u0026lsquo;src=test.txt dest=/opt/test.txt owner=root group=root mode=0644\u0026rsquo; -b\n查看文档\n$ ansible-doc copy\nplaybooks 可重复对多个 hosts 使用的操作.\n执行一个 playbook\n$ ansible-playbook myplaybook.yml\n语法检查\n$ ansible-playbook \u0026ndash;syntax-check myplaybook.yml\n测试但不实际运行(dryrun)\n$ ansible-playbook \u0026ndash;check myplaybook.yml\n逐步执行,交互式的确认\n$ ansible-playbook \u0026ndash;step myplaybook.yml\ngalaxy ansible-galaxy collection install community.docker # offline ansible-galaxy collection download community.docker ansible-galaxy collection install \u0026lt;下载的文件\u0026gt; python3 支持 docs 和 vagrant 一起使用 需要 vagrant 的 host 安装了 ansible ","permalink":"https://26huitailang.github.io/posts/ansible/ansible/","summary":"ansible ref quick-start 流程 环境准备 创建三个虚拟机, ansible(安装 ansible 的机器), vm1, vm2\n使用 ssh-keygen 生成公私钥\nssh-copy-id name@host 配置免密登陆\n安装 ansible\n$ apt install -y ansible\n配置 ➜ ~ pwd /root ➜ ~ cat ansible.cfg [defaults] inventory = $HOME/hosts ➜ ~ cat hosts [webservers] vm1 [dbservers] vm2 ➜ ~ cat /etc/hosts 127.0.0.1\tlocalhost 127.0.1.1\tansible.ansible\tansible # The following lines are desirable for IPv6 capable hosts ::1 localhost ip6-localhost ip6-loopback ff02::1 ip6-allnodes ff02::2 ip6-allrouters # ansible 10.","title":""},{"content":"https://docs.docker.com/develop/develop-images/dockerfile_best-practices/\n","permalink":"https://26huitailang.github.io/posts/docker/dockerfile-best-practice/","summary":"https://docs.docker.com/develop/develop-images/dockerfile_best-practices/","title":""},{"content":"Cheatsheet for package manager go mod pip apt ubuntu 20.04 pip pip install -i https://pypi.tuna.tsinghua.edu.cn/simple some-package\n升级 pip 到最新的版本 (\u0026gt;=10.0.0) 后进行配置：\npip install pip -U pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n如果您到 pip 默认源的网络连接较差，临时使用本镜像站来升级 pip：\npip install -i https://pypi.tuna.tsinghua.edu.cn/simple pip -U\napt ubuntu 20.04\n# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse # 预发布软件源，不建议启用 # deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse go mod GOPROXY=https://goproxy.io,direct\ngo mod init github.com/26huitailang/\u0026lt;PROJECTNAME\u0026gt; go mod vendor ","permalink":"https://26huitailang.github.io/posts/cheatsheet/pkg-manager/","summary":"Cheatsheet for package manager go mod pip apt ubuntu 20.04 pip pip install -i https://pypi.tuna.tsinghua.edu.cn/simple some-package\n升级 pip 到最新的版本 (\u0026gt;=10.0.0) 后进行配置：\npip install pip -U pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n如果您到 pip 默认源的网络连接较差，临时使用本镜像站来升级 pip：\npip install -i https://pypi.tuna.tsinghua.edu.cn/simple pip -U\napt ubuntu 20.04\n# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse # deb-src https://mirrors.","title":"Cheatsheet for pkg manager"},{"content":"Cobra 命令行 因为之前写 Django，python manage.py这个命令非常好用，想看看能不能实现类似的效果。搜索之后发现了更强的cobra，看简介中使用的项目就知道非常不错。代码组织参考的frp的。\nPATH/frp/cmd，frpc和fprs分别是客户端和服务端\n├───frpc │ │ main.go │ │ │ └───sub │ http.go │ https.go │ reload.go │ root.go │ status.go │ stcp.go │ sudp.go │ tcp.go │ tcpmux.go │ udp.go │ xtcp.go │ └───frps main.go root.go 添加 go get -u github.com/spf13/cobra/cobra 在项目目录中执行，appname mycli，其中cmd中 rootCmd 的名称是mycli，这里建议和appname一样，后面可以直接go install之后使用mycli即可。\nmkdir cmd \u0026amp;\u0026amp; cd cmd cobra init mycli --pkg-name mycli cmd └───mycli │ LICENSE │ main.go │ └───cmd root.go 模板代码 import错误，重新按照自己项目的组织方式重写 import即可。\npackage main import \u0026#34;mycli/cmd\u0026#34; func main() { cmd.Execute() } 测试使用：\ngo run main.go 测试完后，可以go install到系统的路径里，然后使用即可，单个二进制文件发布也非常方便。\n嵌套命令行 mycli CMD SUBCMD 增加第一级命令\n\u0026gt; cobra add user \u0026gt; go run . user user called 增加user下的其他指令\n\u0026gt; cobra add userAdd --parent userCmd \u0026gt; go run . user userAdd userAdd called 现在代码的结构\nmycli │ LICENSE │ main.go │ └───cmd root.go user.go userAdd.go 每一次cobra add都会生成一个文件，--parent指定命令属于哪一个，默认是添加到rootCmd：\n可以将cobra生成的文件自己重构，移动到对应文件中 userAdd这个是文件名，也是命令名，在cmd的Use属性中可以修改为add，这样使用时mycli user add [flags] 结合到已有系统中 以web server为例，都会设计一个NewServer方法，然后封装一个执行方法，以命令为入口执行即可：\nmycli server // serverCmd represents the server command var serverCmd = \u0026amp;cobra.Command{ Use: \u0026#34;server\u0026#34;, Short: \u0026#34;A brief description of your command\u0026#34;, Long: `A longer description that spans multiple lines and likely contains examples and usage of using your command. For example: Cobra is a CLI library for Go that empowers applications. This application is a tool to generate the needed files to quickly create a Cobra application.`, Run: func(cmd *cobra.Command, args []string) { runServer() fmt.Println(\u0026#34;server called\u0026#34;) }, } func init() { rootCmd.AddCommand(serverCmd) // Here you will define your flags and configuration settings. // Cobra supports Persistent Flags which will work for this command // and all subcommands, e.g.: // serverCmd.PersistentFlags().String(\u0026#34;foo\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;A help for foo\u0026#34;) // Cobra supports local flags which will only run when this command // is called directly, e.g.: // serverCmd.Flags().BoolP(\u0026#34;toggle\u0026#34;, \u0026#34;t\u0026#34;, false, \u0026#34;Help message for toggle\u0026#34;) } func runServer() { e := server.NewServer() e.Logger.Fatal(e.Start(config.Config.Port)) } ","permalink":"https://26huitailang.github.io/posts/golang/cobra/","summary":"Cobra 命令行 因为之前写 Django，python manage.py这个命令非常好用，想看看能不能实现类似的效果。搜索之后发现了更强的cobra，看简介中使用的项目就知道非常不错。代码组织参考的frp的。\nPATH/frp/cmd，frpc和fprs分别是客户端和服务端\n├───frpc │ │ main.go │ │ │ └───sub │ http.go │ https.go │ reload.go │ root.go │ status.go │ stcp.go │ sudp.go │ tcp.go │ tcpmux.go │ udp.go │ xtcp.go │ └───frps main.go root.go 添加 go get -u github.com/spf13/cobra/cobra 在项目目录中执行，appname mycli，其中cmd中 rootCmd 的名称是mycli，这里建议和appname一样，后面可以直接go install之后使用mycli即可。\nmkdir cmd \u0026amp;\u0026amp; cd cmd cobra init mycli --pkg-name mycli cmd └───mycli │ LICENSE │ main.go │ └───cmd root.go 模板代码 import错误，重新按照自己项目的组织方式重写 import即可。","title":"Cobra 命令行"},{"content":"docker install install docker on Debian/Ubuntu\nlink\nUninstall old versions $ sudo apt-get remove docker docker-engine docker.io containerd runc Set up the repository $ sudo apt-get update $ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common $ curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add - or $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/gpg | sudo apt-key add - $ sudo apt-key fingerprint 0EBFCD88 $ sudo add-apt-repository \\ \u0026#34;deb [arch=amd64] https://download.docker.com/linux/debian \\ $(lsb_release -cs) \\ stable\u0026#34; or sudo add-apt-repository \\ \u0026#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ focal \\ stable\u0026#34; or $ sudo add-apt-repository \\ \u0026#34;deb [arch=amd64] https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/ \\ $(lsb_release -cs) \\ stable\u0026#34; Install Docker Engine $ sudo apt-get update $ sudo apt-get install docker-ce docker-ce-cli containerd.io $ sudo docker run --rm hello-world $ sudo apt install docker-compose -y Without sudo to use docker $ sudo usermod -aG docker $USER $ sudo systemctl restart docker $ sudo systemctl enable docker Speed up https://YOURS.mirror.aliyuncs.com\nsudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://registry.docker-cn.com\u0026#34;, \u0026#34;http://hub-mirror.c.163.com\u0026#34;, \u0026#34;https://docker.mirrors.ustc.edu.cn\u0026#34; ] } EOF sudo systemctl daemon-reload sudo systemctl restart docker ","permalink":"https://26huitailang.github.io/posts/docker/debian-docker-install/","summary":"docker install install docker on Debian/Ubuntu\nlink\nUninstall old versions $ sudo apt-get remove docker docker-engine docker.io containerd runc Set up the repository $ sudo apt-get update $ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common $ curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add - or $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/gpg | sudo apt-key add - $ sudo apt-key fingerprint 0EBFCD88 $ sudo add-apt-repository \\ \u0026#34;deb [arch=amd64] https://download.","title":"docker install"},{"content":"Docker Private Registry 简单使用，官方 官方提供的 https://hub.docker.com/_/registry\nRun a local registry: Quick Version\n$ docker run -d -p 5000:5000 --restart always --name registry registry:2 Now, use it from within Docker:\n$ docker pull ubuntu $ docker tag ubuntu localhost:5000/ubuntu $ docker push localhost:5000/ubuntu 更复杂的需求，harbor https://goharbor.io/\nOur mission is to be the trusted cloud native repository for Kubernetes\n","permalink":"https://26huitailang.github.io/posts/docker/%E7%A7%81%E6%9C%89registry/","summary":"Docker Private Registry 简单使用，官方 官方提供的 https://hub.docker.com/_/registry\nRun a local registry: Quick Version\n$ docker run -d -p 5000:5000 --restart always --name registry registry:2 Now, use it from within Docker:\n$ docker pull ubuntu $ docker tag ubuntu localhost:5000/ubuntu $ docker push localhost:5000/ubuntu 更复杂的需求，harbor https://goharbor.io/\nOur mission is to be the trusted cloud native repository for Kubernetes","title":"Docker Private Registry"},{"content":"etcd 尝试 vagrant # -*- mode: ruby -*- # vi: set ft=ruby : servers = { :etcd1 =\u0026gt; \u0026#39;192.168.1.21\u0026#39;, :etcd2 =\u0026gt; \u0026#39;192.168.1.22\u0026#39;, :etcd3 =\u0026gt; \u0026#39;192.168.1.23\u0026#39; } Vagrant.configure(\u0026#34;2\u0026#34;) do |config| config.vm.box = \u0026#34;ubuntu/focal64\u0026#34; servers.each do |server_name, server_ip| config.vm.define server_name do |server_config| server_config.vm.hostname = \u0026#34;#{server_name.to_s}\u0026#34; server_config.vm.network :private_network, ip: server_ip server_config.vm.provider \u0026#34;virtualbox\u0026#34; do |vb| vb.name = server_name.to_s if vb.name == \u0026#34;etcd1\u0026#34; vb.memory = 1024 vb.cpus = 1 else vb.memory = 1024 vb.cpus = 1 end end end end end install install.sh\nETCD_VER=v3.4.9 # choose either URL GOOGLE_URL=https://storage.googleapis.com/etcd GITHUB_URL=https://github.com/etcd-io/etcd/releases/download DOWNLOAD_URL=${GOOGLE_URL} rm -f /tmp/etcd-${ETCD_VER}-linux-amd64.tar.gz rm -rf /tmp/etcd-download-test \u0026amp;\u0026amp; mkdir -p /tmp/etcd-download-test curl -L ${DOWNLOAD_URL}/${ETCD_VER}/etcd-${ETCD_VER}-linux-amd64.tar.gz -o /tmp/etcd-${ETCD_VER}-linux-amd64.tar.gz tar xzvf /tmp/etcd-${ETCD_VER}-linux-amd64.tar.gz -C /tmp/etcd-download-test --strip-components=1 rm -f /tmp/etcd-${ETCD_VER}-linux-amd64.tar.gz /tmp/etcd-download-test/etcd --version /tmp/etcd-download-test/etcdctl version cluster.sh\ninfra0/1/2 192.168.1.21-23 /tmp/etcd-download-test/etcd --name infra1 --initial-advertise-peer-urls http://192.168.1.22:2380 \\ --listen-peer-urls http://192.168.1.22:2380 \\ --listen-client-urls http://192.168.1.22:2379,http://127.0.0.1:2379 \\ --advertise-client-urls http://192.168.1.22:2379 \\ --initial-cluster-token etcd-cluster-1 \\ --initial-cluster infra0=http://192.168.1.21:2380,infra1=http://192.168.1.22:2380,infra2=http://192.168.1.23:2380 \\ --initial-cluster-state new /tmp/etcd-download-test/etcdctl put mykey \u0026ldquo;this is awesome\u0026rdquo; /tmp/etcd-download-test/etcdctl get mykey\n","permalink":"https://26huitailang.github.io/posts/etcd/readme/","summary":"etcd 尝试 vagrant # -*- mode: ruby -*- # vi: set ft=ruby : servers = { :etcd1 =\u0026gt; \u0026#39;192.168.1.21\u0026#39;, :etcd2 =\u0026gt; \u0026#39;192.168.1.22\u0026#39;, :etcd3 =\u0026gt; \u0026#39;192.168.1.23\u0026#39; } Vagrant.configure(\u0026#34;2\u0026#34;) do |config| config.vm.box = \u0026#34;ubuntu/focal64\u0026#34; servers.each do |server_name, server_ip| config.vm.define server_name do |server_config| server_config.vm.hostname = \u0026#34;#{server_name.to_s}\u0026#34; server_config.vm.network :private_network, ip: server_ip server_config.vm.provider \u0026#34;virtualbox\u0026#34; do |vb| vb.name = server_name.to_s if vb.name == \u0026#34;etcd1\u0026#34; vb.memory = 1024 vb.cpus = 1 else vb.memory = 1024 vb.cpus = 1 end end end end end install install.","title":"etcd 尝试"},{"content":"github, A modern Python package manager with PEP 582 support.\n仅在__pypackages__/\u0026lt;major.minor\u0026gt;包含必要的依赖和bin文件，没有解释器相关文件 就算python解释器被删除了，但是只要有其他符合pyproject.yoml规定版本的解释器即可，项目目录下的__pypackages__不包含解释器相关的内容，venv则必须重新关联或者重新创建 $ tree -L 3 __pypackages__ __pypackages__ └── 3.10 ├── bin │ ├── django-admin │ └── sqlformat ├── include └── lib ├── Django-4.0.1.dist-info ├── anyio ├── anyio-3.5.0.dist-info ├── asgiref ├── asgiref-3.4.1.dist-info ├── django ... install brew install pdm demo mkdir pdm-demo cd pdm-demo pdm init Creating a pyproject.toml for PDM... Please enter the Python interpreter to use ... 12. /usr/local/Cellar/pdm/1.12.2/libexec/bin/python3.10 (3.10) Please select: [0]: 12 Using Python interpreter: /usr/local/Cellar/pdm/1.12.2/libexec/bin/python3.10 (3.10) Is the project a library that will be uploaded to PyPI? [y/N]: N License(SPDX name) [MIT]: Author name [26huitailang]: Author email [26huitailang@gmail.com]: Python requires(\u0026#39;*\u0026#39; to allow any) [\u0026gt;=3.10]: Changes are written to pyproject.toml. PDM 1.12.2 is installed, while 1.12.6 is available. Please run $ brew upgrade pdm to upgrade. Run $ pdm config check_update false to disable the check. init files\n~/git-checkout/pdm-demo ⌚ 10:38:57 $ la total 16 -rw-r--r-- 1 26huitailang staff 70B Jan 12 10:37 .pdm.toml -rw-r--r-- 1 26huitailang staff 321B Jan 12 10:38 pyproject.toml .pdm.toml python 路径信息 pyproject.toml project info tool info build-system 添加包，会更新pyproject.toml下面的dependencies\n$ pdm add django Adding packages to default dependencies: django ✔ 🔒 Lock successful Changes are written to pdm.lock. Changes are written to pyproject.toml. Synchronizing working set with lock file: 3 to add, 0 to update, 0 to remove ✔ Install asgiref 3.4.1 successful ✔ Install django 4.0.1 successful ✔ Install sqlparse 0.4.2 successful 🎉 All complete! PDM 1.12.2 is installed, while 1.12.6 is available. Please run $ brew upgrade pdm to upgrade. Run $ pdm config check_update false to disable the check. 使用pdm定义的环境运行\npdm run django-admin -h 配置修改，修改pypi源\npdm config pypi.url https://pypi.tuna.tsinghua.edu.cn/simple use with ide https://pdm.fming.dev/#use-with-ide\npycharm 支持不完善，比如Django，添加了PATH后 run/debug configuration不能正确识别，需要点击continue anyway才能运行django server，但是最新版本默认支持poetry和pipenv，等待后续支持pep582/pdm ","permalink":"https://26huitailang.github.io/posts/python/pdm/","summary":"github, A modern Python package manager with PEP 582 support.\n仅在__pypackages__/\u0026lt;major.minor\u0026gt;包含必要的依赖和bin文件，没有解释器相关文件 就算python解释器被删除了，但是只要有其他符合pyproject.yoml规定版本的解释器即可，项目目录下的__pypackages__不包含解释器相关的内容，venv则必须重新关联或者重新创建 $ tree -L 3 __pypackages__ __pypackages__ └── 3.10 ├── bin │ ├── django-admin │ └── sqlformat ├── include └── lib ├── Django-4.0.1.dist-info ├── anyio ├── anyio-3.5.0.dist-info ├── asgiref ├── asgiref-3.4.1.dist-info ├── django ... install brew install pdm demo mkdir pdm-demo cd pdm-demo pdm init Creating a pyproject.toml for PDM... Please enter the Python interpreter to use ... 12. /usr/local/Cellar/pdm/1.","title":"pdm"},{"content":"pip 离线安装 打包 注意，要在同平台打包，否则有些包不能正确安装。\n在已有的环境中，一般是一个虚拟环境：\npip freeze \u0026gt; pip-requirements.txt pip download -d pip-packages -r pip-requirements.txt，将提取的包下载到pip-packages文件夹中 安装 将pip-requirements.txt和pip-packages文件夹，拷贝到目标环境的同目录下 pip install \u0026ndash;no-index \u0026ndash;find-links=pip-packages -r pip-requirements.txt 参考 断网环境下一键安装 python3 离线安装包及其依赖 下载依赖 pip-download\nexample\npip install pip-download pip-download -p win_amd64 -p none-any fabric ","permalink":"https://26huitailang.github.io/posts/python/pip/%E6%89%93%E5%8C%85%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/","summary":"pip 离线安装 打包 注意，要在同平台打包，否则有些包不能正确安装。\n在已有的环境中，一般是一个虚拟环境：\npip freeze \u0026gt; pip-requirements.txt pip download -d pip-packages -r pip-requirements.txt，将提取的包下载到pip-packages文件夹中 安装 将pip-requirements.txt和pip-packages文件夹，拷贝到目标环境的同目录下 pip install \u0026ndash;no-index \u0026ndash;find-links=pip-packages -r pip-requirements.txt 参考 断网环境下一键安装 python3 离线安装包及其依赖 下载依赖 pip-download\nexample\npip install pip-download pip-download -p win_amd64 -p none-any fabric ","title":"pip 离线安装"},{"content":"pipenv pip和virtualenv的组合，使用Pipfile来替换旧的requirements.txt方式。\ndocumentation zhihu 参考 segmentfault 参考 安装 安装到系统常用的python版本下，mac可以使用brew安装\n$ pip install pipenv 创建虚拟环境 $ pipenv install --three django 创建一个python3的虚拟环境并安装django，随机生成一个和当前文件夹名有关的虚拟环境。也可以用过--python 3.7指定python版本。\nTODO， 不能指定名称吗？ 进入虚拟环境 $ pipenv shell 不过就算不进入环境，pipenv install依然可以正确安装包到对应的环境。\n新环境依赖 自动识别Pipfile，然后安装。\n$ pipenv install 一并安装开发环境的包：\n$ pipenv install --dev 区别开发环境 在安装包的时候添加一个--dev选项，会分类到开发依赖。\n更换源 更换Pipfile中的source-url\n[[source]] url = \u0026quot;https://mirrors.aliyun.com/pypi/simple\u0026quot; verify_ssl = true name = \u0026quot;pypi\u0026quot; 设置环境变量 PIPENV_PYPI_MIRROR 效果相同。类似指定\u0026ndash;pypi-mirror选项：\n$ pipenv install --pypi-mirror https://mirrors.aliyun.com/pypi/simple 查看安装的包 $ pipenv graph 不仅可以看到安装包，还可以看到依赖关系。\nDjango==2.1.7 - pytz [required: Any, installed: 2018.9] psutil==5.5.1 Pipfile 替换了源 有开发环境的包 dev-packages python 版本3.6 [[source]] name = \u0026#34;pypi\u0026#34; url = \u0026#34;https://mirrors.aliyun.com/pypi/simple\u0026#34; verify_ssl = true [dev-packages] pytest = \u0026#34;*\u0026#34; [packages] psutil = \u0026#34;*\u0026#34; django = \u0026#34;*\u0026#34; [requires] python_version = \u0026#34;3.6\u0026#34; ","permalink":"https://26huitailang.github.io/posts/python/pip/pipenv/","summary":"pipenv pip和virtualenv的组合，使用Pipfile来替换旧的requirements.txt方式。\ndocumentation zhihu 参考 segmentfault 参考 安装 安装到系统常用的python版本下，mac可以使用brew安装\n$ pip install pipenv 创建虚拟环境 $ pipenv install --three django 创建一个python3的虚拟环境并安装django，随机生成一个和当前文件夹名有关的虚拟环境。也可以用过--python 3.7指定python版本。\nTODO， 不能指定名称吗？ 进入虚拟环境 $ pipenv shell 不过就算不进入环境，pipenv install依然可以正确安装包到对应的环境。\n新环境依赖 自动识别Pipfile，然后安装。\n$ pipenv install 一并安装开发环境的包：\n$ pipenv install --dev 区别开发环境 在安装包的时候添加一个--dev选项，会分类到开发依赖。\n更换源 更换Pipfile中的source-url\n[[source]] url = \u0026quot;https://mirrors.aliyun.com/pypi/simple\u0026quot; verify_ssl = true name = \u0026quot;pypi\u0026quot; 设置环境变量 PIPENV_PYPI_MIRROR 效果相同。类似指定\u0026ndash;pypi-mirror选项：\n$ pipenv install --pypi-mirror https://mirrors.aliyun.com/pypi/simple 查看安装的包 $ pipenv graph 不仅可以看到安装包，还可以看到依赖关系。\nDjango==2.1.7 - pytz [required: Any, installed: 2018.","title":"pipenv"},{"content":"PostgreSQL 分表 继承实现更灵活，可以直接在已有数据的表上实现，不用重新迁移。\n-- https://www.postgresql.org/docs/current/ddl-partitioning.html -- zh -- http://postgres.cn/docs/11/ddl-partitioning.html -- keyword: further redirect -- 已有数据分表，因为主表不能有数据，所以需要先备份，创建分表和规则完毕后重新插入 -- 或者用新的表名，之后再分批读取插入 -- 创建主表 CREATE TABLE measurement ( city_id int not null, logdate date not null, peaktemp int, unitsales int ) PARTITION BY RANGE (logdate); -- 创建分表及规则 -- 还可以通过partition by 再次创建sub-partitioning，对插入measurement_y2006m02的数据再次重定向 -- CREATE TABLE measurement_y2006m02 PARTITION OF measurement -- FOR VALUES FROM (\u0026#39;2006-02-01\u0026#39;) TO (\u0026#39;2006-03-01\u0026#39;) -- PARTITION BY RANGE (peaktemp); CREATE TABLE measurement_y2006m02 PARTITION OF measurement FOR VALUES FROM (\u0026#39;2006-02-01\u0026#39;) TO (\u0026#39;2006-03-01\u0026#39;); CREATE TABLE measurement_y2006m03 PARTITION OF measurement FOR VALUES FROM (\u0026#39;2006-03-01\u0026#39;) TO (\u0026#39;2006-04-01\u0026#39;); -- 创建索引，自动再每个分区上创建索引 CREATE INDEX ON measurement (logdate); -- Ensure that the enable_partition_pruning configuration parameter is not disabled in postgresql.conf. If it is, queries will not be optimized as desired. -- test INSERT INTO measurement (city_id, logdate, peaktemp, unitsales) VALUES (1, \u0026#39;2008-2-1\u0026#39;, 1, 1); INSERT INTO measurement (city_id, logdate, peaktemp, unitsales) VALUES (1, \u0026#39;2006-2-1\u0026#39;, 1, 1); ---- 维护 ---- -- 删除分表，可以快速删除百万数据，但是需要父表的 ACCESS EXCLUSIVE 锁 DROP TABLE measurement_y2006m02; -- 更好的处理方式，将分表从主表中分离，以单独的形式存在 -- This allows further operations to be performed on the data before it is dropped. For example, this is often a useful time to back up the data using COPY, pg_dump, or similar tools. It might also be a useful time to aggregate data into smaller formats, perform other data manipulations, or run reports. ALTER TABLE measurement DETACH PARTITION measurement_y2006m02; -- 在新的自盘空间申明，一般是用于把重要数据放在可靠快速磁盘，将日志型等数据放于普通磁盘 -- CREATE TABLE measurement_y2008m02 PARTITION OF measurement -- FOR VALUES FROM (\u0026#39;2008-02-01\u0026#39;) TO (\u0026#39;2008-03-01\u0026#39;) -- TABLESPACE fasttablespace; -- 分区表有下列限制： -- -- 没有办法创建跨越所有分区的排除约束，只可能单个约束每个叶子分区。 -- -- 虽然在分区表上支持主键，但引用分区表的外键不受支持（但支持从分区表到某个其他表的外键引用）。 -- -- 当一个UPDATE导致一行从一个分区移动到另一个分区时，另一个并发的UPDATE或DELETE可能会产生一个串行化错误。假设会话1正在执行一个分区键上的UPDATE，同时一个并发的能看见这个行的会话2执行了对该行的UPDATE或者DELETE操作。在这种情况下，会话2的UPDATE或者DELETE会检测到行的移动，并抛出一个串行化的错误(将总是会返回一个SQLSTATE \u0026#39;40001\u0026#39;)。 如果发生这种情况，应用程序可能希望重试该事务。 在没有分区表或没有行移动的通常情况下， 会话2将识别新更新的行并在新行上执行UPDATE/DELETE。 -- -- 如果必要，必须在个体分区上定义BEFORE ROW触发器，分区表上不需要。 -- -- 不允许在同一个分区树中混杂临时关系和持久关系。因此，如果分区表是持久的，则其分区也必须是持久的，反之亦然。在使用临时关系时，分区数的所有成员都必须来自于同一个会话。 -- 使用继承实现 -- 虽然内建的声明式分区适合于大部分常见的用例，但还是有一些场景需要更加灵活的方法。分区可以使用表继承来实现，这能够带来一些声明式分区不支持的特性，例如： -- -- 对声明式分区来说，分区必须具有和分区表正好相同的列集合，而在表继承中，子表可以有父表中没有出现过的额外列。 -- -- 表继承允许多继承。 -- -- 声明式分区仅支持范围、列表以及哈希分区，而表继承允许数据按照用户的选择来划分（不过注意，如果约束排除不能有效地剪枝子表，查询性能可能会很差）。 -- -- 在使用声明式分区时，一些操作比使用表继承时要求更长的持锁时间。例如，向分区表中增加分区或者从分区表移除分区要求在父表上取得一个ACCESS EXCLUSIVE锁，而在常规继承的情况下一个SHARE UPDATE EXCLUSIVE锁就足够了。 --继承实现可以在已有数据中实现吗？ create table measurement3 ( id int not null, name char not null ); insert into measurement3 (id, name) values (1, \u0026#39;a\u0026#39;); insert into measurement3 (id, name) values (2, \u0026#39;b\u0026#39;); insert into measurement3 (id, name) values (3, \u0026#39;c\u0026#39;); insert into measurement3 (id, name) values (4, \u0026#39;d\u0026#39;); create table measurement3_y1 (check ( id \u0026gt;= 10 and id \u0026lt; 20 )) inherits (measurement3); create table measurement3_y2 (check ( id \u0026gt;= 20 and id \u0026lt; 30 )) inherits (measurement3); create function measurement_insert_trigger() returns trigger language plpgsql as $$ BEGIN IF (NEW.id \u0026gt;= 10 and NEW.id \u0026lt; 20) then INSERT INTO measurement3_y1 VALUES (NEW.*); ELSIF (NEW.id \u0026gt;= 20 and NEW.id \u0026lt; 30) then INSERT INTO measurement3_y2 VALUES (NEW.*); ELSE RAISE EXCEPTION \u0026#39;id out of range. Fix the measurement_insert_trigger function!\u0026#39;; END IF; RETURN NULL; END; $$; alter function measurement_insert_trigger() owner to develop; CREATE TRIGGER insert_measurement_trigger BEFORE INSERT ON measurement3 FOR EACH ROW EXECUTE FUNCTION measurement_insert_trigger(); insert into measurement3 (id, name) values (100, \u0026#39;d\u0026#39;); ","permalink":"https://26huitailang.github.io/posts/postgresql/partition/","summary":"PostgreSQL 分表 继承实现更灵活，可以直接在已有数据的表上实现，不用重新迁移。\n-- https://www.postgresql.org/docs/current/ddl-partitioning.html -- zh -- http://postgres.cn/docs/11/ddl-partitioning.html -- keyword: further redirect -- 已有数据分表，因为主表不能有数据，所以需要先备份，创建分表和规则完毕后重新插入 -- 或者用新的表名，之后再分批读取插入 -- 创建主表 CREATE TABLE measurement ( city_id int not null, logdate date not null, peaktemp int, unitsales int ) PARTITION BY RANGE (logdate); -- 创建分表及规则 -- 还可以通过partition by 再次创建sub-partitioning，对插入measurement_y2006m02的数据再次重定向 -- CREATE TABLE measurement_y2006m02 PARTITION OF measurement -- FOR VALUES FROM (\u0026#39;2006-02-01\u0026#39;) TO (\u0026#39;2006-03-01\u0026#39;) -- PARTITION BY RANGE (peaktemp); CREATE TABLE measurement_y2006m02 PARTITION OF measurement FOR VALUES FROM (\u0026#39;2006-02-01\u0026#39;) TO (\u0026#39;2006-03-01\u0026#39;); CREATE TABLE measurement_y2006m03 PARTITION OF measurement FOR VALUES FROM (\u0026#39;2006-03-01\u0026#39;) TO (\u0026#39;2006-04-01\u0026#39;); -- 创建索引，自动再每个分区上创建索引 CREATE INDEX ON measurement (logdate); -- Ensure that the enable_partition_pruning configuration parameter is not disabled in postgresql.","title":"PostgreSQL 分表"},{"content":"Teamcity 搭建CI/CD install server\nmkdir teamcity_server docker run -it --name teamcity-server-instance \\ -v /home/ubuntu/teamcity_server/datadir:/data/teamcity_server/datadir \\ -v /home/ubuntu/teamcity_server/logs:/opt/teamcity/logs \\ -p 8111:8111 \\ jetbrains/teamcity-server agent, conf 有权限问题，最好在root运行 如果要使用docker-in-docker特性（sudo command not found），请使用linux-sudo tag的image sudo docker run -it -e SERVER_URL=\u0026#34;http://10.200.160.4:8111\u0026#34; \\ -u 0 \\ -v docker_volumes:/var/lib/docker \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v /opt/buildagent/work:/opt/buildagent/work \\ -v /opt/buildagent/temp:/opt/buildagent/temp \\ -v /opt/buildagent/tools:/opt/buildagent/tools \\ -v /opt/buildagent/plugins:/opt/buildagent/plugins \\ -v /opt/buildagent/system:/opt/buildagent/system \\ --privileged -e DOCKER_IN_DOCKER=start \\ -v /home/ubuntu/teamcity_agent/conf:/data/teamcity_agent/conf \\ jetbrains/teamcity-agent register agent agent 安装好后，在server UI/Agents 中进行认证授权。待agent就绪后，可以添加需要的项目和操作等。\n项目 我使用的是gitlab，teamcity默认是支持的\n右上角 Administration 在root project/connections 中添加 gitlab ce/ee，按照指示即可，会有个oauth认证的过程 之后就可以在root project 下创建项目的时候，就可以直接导入gitlab的项目了 Build 创建了项目后，在Build Configurations中创建新的configuration，这个配置可以包含多个steps 每个配置可以配置trigger和branch，还有参数 这里可以用配置隔离不同环境的测试，我这里只有一个单元测试的环境，branch是我自己仓库的dev，在Version Control Settings中设置，可以多个 Build Step，我选用的Command Line，在docker中运行 配置 docker settings python:3.7 echo \u0026#39;Webserver CI start ...\u0026#39; pip install --default-timeout=60 --no-cache-dir -r requirements/ci.txt -i https://mirrors.aliyun.com/pypi/simple/ \u0026amp;\u0026amp; \\ cp generalapps/settings/ci.py generalapps/settings/settings.py \u0026amp;\u0026amp; \\ python manage.py test --keepdb notification rules 可以配置 Email/Browser/IDE/Jabber/Slack\n我使用Pycharm，在插件中安装teamcity插件，然后使用server url/username/password登录即可 在个人配置中选择关注的项目和事件 之后在ide中即可看到项目CI的动态 ","permalink":"https://26huitailang.github.io/posts/teamcity/teamcity/","summary":"Teamcity 搭建CI/CD install server\nmkdir teamcity_server docker run -it --name teamcity-server-instance \\ -v /home/ubuntu/teamcity_server/datadir:/data/teamcity_server/datadir \\ -v /home/ubuntu/teamcity_server/logs:/opt/teamcity/logs \\ -p 8111:8111 \\ jetbrains/teamcity-server agent, conf 有权限问题，最好在root运行 如果要使用docker-in-docker特性（sudo command not found），请使用linux-sudo tag的image sudo docker run -it -e SERVER_URL=\u0026#34;http://10.200.160.4:8111\u0026#34; \\ -u 0 \\ -v docker_volumes:/var/lib/docker \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v /opt/buildagent/work:/opt/buildagent/work \\ -v /opt/buildagent/temp:/opt/buildagent/temp \\ -v /opt/buildagent/tools:/opt/buildagent/tools \\ -v /opt/buildagent/plugins:/opt/buildagent/plugins \\ -v /opt/buildagent/system:/opt/buildagent/system \\ --privileged -e DOCKER_IN_DOCKER=start \\ -v /home/ubuntu/teamcity_agent/conf:/data/teamcity_agent/conf \\ jetbrains/teamcity-agent register agent agent 安装好后，在server UI/Agents 中进行认证授权。待agent就绪后，可以添加需要的项目和操作等。","title":"TeamCity 搭建CI/CD"},{"content":"如何使用 Vagrant 快速搭建环境 加速 可以直接从国内镜像下载 box格式的文件，然后用 vagrant box add NAME URL添加\n# 自己下载 https://mirrors.tuna.tsinghua.edu.cn/ubuntu-cloud-images/focal/current/ 制作自己的box 官方文档\n正常安装镜像，然后安装基础环境\n导出\nvagrant package --base ubuntu20.04 --output ./ubuntu2004.box 添加box\nvagrant box add ubuntu2004 .\\ubuntu2004.box 如果没有Vagrantfile，则初始化\nvagrant box add ubuntu2004 .\\ubuntu2004.box 启动\nvagrant up VagrantFile # -*- mode: ruby -*- # vi: set ft=ruby : servers = { :k3s1 =\u0026gt; \u0026#39;192.168.1.21\u0026#39;, :k3s2 =\u0026gt; \u0026#39;192.168.1.22\u0026#39;, :k3s3 =\u0026gt; \u0026#39;192.168.1.23\u0026#39; } Vagrant.configure(\u0026#34;2\u0026#34;) do |config| # 可以指定自己导出的box config.vm.box = \u0026#34;ubuntu/focal64\u0026#34; servers.each do |server_name, server_ip| config.vm.define server_name do |server_config| server_config.vm.hostname = \u0026#34;#{server_name.to_s}\u0026#34; server_config.vm.network :private_network, ip: server_ip server_config.vm.provider \u0026#34;virtualbox\u0026#34; do |vb| vb.name = server_name.to_s vb.memory = 1024 vb.cpus = 1 end end end end ","permalink":"https://26huitailang.github.io/posts/vagrant/vagrant/","summary":"如何使用 Vagrant 快速搭建环境 加速 可以直接从国内镜像下载 box格式的文件，然后用 vagrant box add NAME URL添加\n# 自己下载 https://mirrors.tuna.tsinghua.edu.cn/ubuntu-cloud-images/focal/current/ 制作自己的box 官方文档\n正常安装镜像，然后安装基础环境\n导出\nvagrant package --base ubuntu20.04 --output ./ubuntu2004.box 添加box\nvagrant box add ubuntu2004 .\\ubuntu2004.box 如果没有Vagrantfile，则初始化\nvagrant box add ubuntu2004 .\\ubuntu2004.box 启动\nvagrant up VagrantFile # -*- mode: ruby -*- # vi: set ft=ruby : servers = { :k3s1 =\u0026gt; \u0026#39;192.168.1.21\u0026#39;, :k3s2 =\u0026gt; \u0026#39;192.168.1.22\u0026#39;, :k3s3 =\u0026gt; \u0026#39;192.168.1.23\u0026#39; } Vagrant.configure(\u0026#34;2\u0026#34;) do |config| # 可以指定自己导出的box config.vm.box = \u0026#34;ubuntu/focal64\u0026#34; servers.","title":"Vagrant"},{"content":"wheel 提供给系统组的wheel包构建，要求none-any\n以oss2包为例\npip download oss2 --platform=any --abi=none --no-deps 查看setup.py中的依赖，分别用上面的命令下载，获得所有的源码包。\n打包wheel，universal选项可以打包忽略平台和架构的包;如果包里面含有c extension是不支持universal的，必须是纯python实现\npython .\\setup.py bdist_wheel --universal 如果遇到打包错误 error: invalid command 'bdist_wheel'，可以修改setup.py使用setuptools的setup方法：\n# from distutils.core import setup from setuptools import setup ","permalink":"https://26huitailang.github.io/posts/python/pip/wheel/","summary":"wheel 提供给系统组的wheel包构建，要求none-any\n以oss2包为例\npip download oss2 --platform=any --abi=none --no-deps 查看setup.py中的依赖，分别用上面的命令下载，获得所有的源码包。\n打包wheel，universal选项可以打包忽略平台和架构的包;如果包里面含有c extension是不支持universal的，必须是纯python实现\npython .\\setup.py bdist_wheel --universal 如果遇到打包错误 error: invalid command 'bdist_wheel'，可以修改setup.py使用setuptools的setup方法：\n# from distutils.core import setup from setuptools import setup ","title":"wheel"}]